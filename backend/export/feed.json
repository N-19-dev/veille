{
  "generated_at": "2026-02-02T15:21:22.019629+00:00",
  "config": {
    "articles_limit": 10,
    "videos_limit": 5,
    "days_lookback": 14,
    "rolling_buffer": true
  },
  "articles": [
    {
      "id": "76d2fcbf02e0d44fde0a7e8c81db36986b29961285d67f454ee0fa71867d92ed",
      "url": "https://blog.octo.com/avec-gemini-nano-voyez-l'ia-vie-en-rose-!",
      "title": "Avec Gemini Nano, voyez l'IA vie en rose !",
      "original_title": "Avec Gemini Nano, voyez l'IA vie en rose !",
      "summary": "Avec Gemini Nano, venez d√©couvrir l'IA g√©n√©rative gratuite, qui prot√®ge vos donn√©es et √† disposition (un jour) de tous vos utilisateurs !",
      "source_name": "OCTO Talks!",
      "published_ts": 1770029290,
      "category_key": "news",
      "score": 2.9446,
      "algo_score": 49.4,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "5181373c8d099f2dbfe0e0bbb1bae0e26822d5e61315b90f713a69d9a0e1265b",
      "url": "https://medium.com/whatnot-engineering/lessons-learned-from-scaling-data-scientists-with-ai-e7aa7b3235b4",
      "title": "Lessons learned from scaling data scientists with AI",
      "original_title": "Lessons learned from scaling data scientists with AI",
      "summary": "Lessons learned from scaling data scientists with AI\nAlice Leach, Anthony Sedarous, Evan Hou, Faithful Alabi, Stephen Bailey, Tanisha Kore | Data\n‚ÄúCan you check my SQL?‚Äù\n‚ÄúWhich table has the livestream data?‚Äù\n‚ÄúHow do I calculate GMV again?‚Äù\nAt Whatnot, our data scientists were drowning in these sort",
      "source_name": "Data Engineering Weekly",
      "published_ts": 1769998946,
      "category_key": "python_analytics",
      "score": 0.8743,
      "algo_score": 50.7,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "rex",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "3f906e0b974e851df32013e4af43df897bf92547bbfb8f0956e102f202b07187",
      "url": "https://preset.io/blog/semantic-layer-is-back/",
      "title": "The Semantic Layer Is Back. Here's What We're Doing About It.",
      "original_title": "The Semantic Layer Is Back. Here's What We're Doing About It.",
      "summary": "There's a new wave of enthusiasm around semantic layers, and for once, I think the hype is justified.\nSince the very early days of analytics, self-service has been the holy grail, yet it's still largely unsolved. We built increasingly powerful tools. We democratized SQL. We made dashboards beautiful",
      "source_name": "Data Engineering Weekly",
      "published_ts": 1769998946,
      "category_key": "data_modeling_governance",
      "score": 0.8691,
      "algo_score": 50.4,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "b54a2a6401741af5c0eb779b526544cd3652ae8cc676afb463918dbec262f74b",
      "url": "https://openai.com/index/inside-our-in-house-data-agent/",
      "title": "Inside OpenAI‚Äôs in-house data agent",
      "original_title": "Inside OpenAI‚Äôs in-house data agent",
      "summary": "Data powers how systems learn, products evolve, and how companies make choices. But getting answers quickly, correctly, and with the right context is often harder than it should be. To make this easier as OpenAI scales, we built\nour own bespoke in-house AI data agent\nthat explores and reasons over o",
      "source_name": "Data Engineering Weekly",
      "published_ts": 1769998946,
      "category_key": "ai_data_engineering",
      "score": 0.8656,
      "algo_score": 50.2,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "rex",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "88f3154623cf2ad1af13329678cf58e38891883119e0c588c2495a2ed3508453",
      "url": "https://medium.com/@community_md101/modeling-semantics-how-data-models-and-ontologies-connect-to-build-your-semantic-foundations-3a9a0664e3ff",
      "title": "Modeling Semantics: How Data Models and Ontologies Connect to Build Your Semantic Foundations",
      "original_title": "Modeling Semantics: How Data Models and Ontologies Connect to Build Your Semantic Foundations",
      "summary": "Think of ‚ÄúCustomer‚Äù, ‚ÄúOrder‚Äù, ‚ÄúProduct‚Äù, ‚ÄúDelivery‚Äù, and so on. These are what you have data\nabout\n, no matter how the data is technically stored in database tables or files.\nIn addition to the list of\nthings\n, to fully understand the business context, we need\nrelationships\nbetween the things. How d",
      "source_name": "Data Engineering Weekly",
      "published_ts": 1769998946,
      "category_key": "news",
      "score": 0.8174,
      "algo_score": 47.4,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "22eeacd1461ef4b20d0bb83c29afb9fe114c558ac1af83c591fa2f2ecd884724",
      "url": "https://openai.com/index/unrolling-the-codex-agent-loop/",
      "title": "Unrolling the Codex agent loop",
      "original_title": "Unrolling the Codex agent loop",
      "summary": "Codex CLI\n‚Å†\n(opens in a new window)\nis our cross-platform local software agent, designed to produce high-quality, reliable software changes while operating safely and efficiently on your machine. We‚Äôve learned a tremendous amount about how to build a world-class software agent\nsince we first launche",
      "source_name": "Data Engineering Weekly",
      "published_ts": 1769998946,
      "category_key": "data_modeling_governance",
      "score": 0.7225,
      "algo_score": 41.9,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "11aba42be2ce1d67dcf2c324449cb0e4979504e49e039adac2099d7ab661f5ec",
      "url": "https://juhache.substack.com/p/boring-engineering-manifesto",
      "title": "The Boring Engineer Manifesto",
      "original_title": "The Boring Engineer Manifesto",
      "summary": "Ju Data Engineering Weekly - Ep 92",
      "source_name": "Julien Hurault ¬∑ Ju Data Engineering",
      "published_ts": 1767961881,
      "category_key": "news",
      "score": 0.0044,
      "algo_score": 61.1,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "0112c03d56bfc2a54a1a342b5e1128e63354cd0b1040a486622097790c61483b",
      "url": "https://dagster.io/blog/rise-of-the-data-platform-engineer",
      "title": "The Rise of the Data Platform Engineer",
      "original_title": "The Rise of the Data Platform Engineer",
      "summary": "The evolution of data engineering demands a platform-first mindset. See how Data Platform Engineers are shaping the future of analytics.",
      "source_name": "Dagster Blog",
      "published_ts": 1767731183,
      "category_key": "news",
      "score": 0.0041,
      "algo_score": 66.6,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "57e27a95ba679779db57eadeb6b520a633e06b60d8c713368a301330c11c218b",
      "url": "https://www.databricks.com/blog/securing-grid-practical-guide-cyber-analytics-energy-utilities",
      "title": "Securing the Grid: A Practical Guide to Cyber Analytics for Energy & Utilities",
      "original_title": "Securing the Grid: A Practical Guide to Cyber Analytics for Energy & Utilities",
      "summary": "How Modern Data Platforms Are Transforming Cybersecurity Operations in Critical InfrastructureThe...",
      "source_name": "Databricks Blog",
      "published_ts": 1767831300,
      "category_key": "news",
      "score": 0.0039,
      "algo_score": 60.4,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "article"
    },
    {
      "id": "a39db3829eefda7933ff77260853efa46a493530b0d0e40eea19b4b21e475c31",
      "url": "https://seattledataguy.substack.com/p/common-data-pipeline-patterns-youll",
      "title": "Common Data Pipeline Patterns You‚Äôll See in the Real World",
      "original_title": "Common Data Pipeline Patterns You‚Äôll See in the Real World",
      "summary": "A practical look at the many ways data pipelines show up inside real companies",
      "source_name": "Seattle Data Guy",
      "published_ts": 1767643086,
      "category_key": "etl_orchestration",
      "score": 0.0037,
      "algo_score": 64.3,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "article"
    }
  ],
  "videos": [
    {
      "id": "deae831796d09ca11c9c3cc564e8df553c82d2883f3557e4589e37f9e00250f1",
      "url": "https://roundup.getdbt.com/p/ai-agents-and-the-data-lake-w-lauren",
      "title": "AI agents and the data lake (w/ Lauren Anderson)",
      "original_title": "AI agents and the data lake (w/ Lauren Anderson)",
      "summary": "The head of Okta's enterprise data platform on why central governance and the semantic layer are so essential",
      "source_name": "The Analytics Engineering Podcast (dbt)",
      "published_ts": 1768140185,
      "category_key": "data_modeling_governance",
      "score": 0.0047,
      "algo_score": 57.8,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "podcast"
    },
    {
      "id": "a5c27a221448022b897ba2e48d8a53dbc1b13aa8064f90041e11b4fb609180da",
      "url": "https://www.youtube.com/watch?v=RG4VyQARSfg",
      "title": "Stackoverflow is basically dead",
      "original_title": "Stackoverflow is basically dead",
      "summary": "Yup, it's bad!\nHere's the source for the material I showed: https://blog.pragmaticengineer.com/stack-overflow-is-almost-dead/\n\nIf you want to learn Data Engineering check out: LearnDataEngineering.com",
      "source_name": "Andreas Kretz (YouTube)",
      "published_ts": 1767989760,
      "category_key": "news",
      "score": 0.0042,
      "algo_score": 57.3,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "youtube"
    },
    {
      "id": "7ab91db7f6e071494a838bd7ad1c3472934ce470ab47640eb5ccd6aeb8a84417",
      "url": "https://www.youtube.com/watch?v=YiT8YejCf6g",
      "title": "Data Governance Is NOT the Foundation for AI",
      "original_title": "Data Governance Is NOT the Foundation for AI",
      "summary": "Data Governance Is NOT the Foundation for AI\nThat statement alone triggers a lot of people.\nAnd there‚Äôs a reason for that.\n\nIn this video, I break down why starting AI initiatives with data governance, definitions, and policies often leads to stalled projects, endless meetings, and zero business impact.\n\nThis is not an argument against data governance.\nIt‚Äôs an argument against treating it as the starting point.\nI‚Äôve seen AI and data teams spend months arguing over definitions, ownership, and frameworks,while leadership waits for results and eventually moves on. When AI fails, governance is blamed. But in reality, the problem usually starts much earlier.\n\nThis video covers:\nWhy data governance is often framed as the foundation for AI\nWhat actually causes AI projects to fail in companies\nThe difference between governance as a prerequisite vs a byproduct\nWhy leadership, goals, and direction matter more than documentation\nHow real AI systems change how governance should be built\nIf you work in data engineering, analytics, AI, or platform teams, this will likely feel uncomfortable and familiar.",
      "source_name": "Andreas Kretz (YouTube)",
      "published_ts": 1767903443,
      "category_key": "news",
      "score": 0.0038,
      "algo_score": 55.0,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "youtube"
    },
    {
      "id": "707d34120c393e6770f7b0a0734d0e5c1bf667251ac9f3c00dad23fa1e6b1f72",
      "url": "https://www.youtube.com/shorts/EJPisMWTMTA",
      "title": "The Power BI MCP Server is changing the game of how you do Power BI!",
      "original_title": "The Power BI MCP Server is changing the game of how you do Power BI!",
      "summary": "Check out the full video: https://youtu.be/7UapKxtxQUo\n\nüì¢ Become a member: https://guyinacu.be/membership \n\n*******************\n\nWant to take your Power BI skills to the next level? We have training courses available to help you with your journey.\n\nüéì Guy in a Cube courses: https://courses.guyinacube.com/\n\n*******************\nLET'S CONNECT!\n*******************\n\n-- https://bsky.app/profile/guyinacube.bsky.social\n-- http://twitter.com/guyinacube\n-- http://www.facebook.com/guyinacube\n\n\n#PowerBI #GuyInACube",
      "source_name": "Guy in a Cube (YouTube)",
      "published_ts": 1767886218,
      "category_key": "ai_data_engineering",
      "score": 0.0031,
      "algo_score": 45.7,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "technical",
      "tech_level": "intermediate",
      "source_type": "youtube"
    },
    {
      "id": "413551a4a654b20bbf57f27ca90d4dc1b454c4e0e17107862e2c175a5c7f5148",
      "url": "https://analyticshour.io/2026/01/06/288-our-llm-suggested-we-chat-about-mcp-kinda-meta-no/",
      "title": "#288: Our LLM Suggested We Chat about MCP. Kinda‚Äô Meta, No?",
      "original_title": "#288: Our LLM Suggested We Chat about MCP. Kinda‚Äô Meta, No?",
      "summary": "If there‚Äôs one thing that we absolutely knew would be coming along with the increased interest and use of AI, it would be‚Ä¶ more acronyms! And, along with the acronyms, we pretty much could predict that we see a lot of online flexing through casual dropping of said acronyms as though they‚Äôre deeply understood by everyone who‚Äôs anyone. We tackled one such acronym on this episode: MCP! That‚Äôs ‚Äúmodel context protocol‚Äù for those who like their acronyms written out, and Sam Redfern joined us to help us wrap our heads around the topic. You see, MCP is kinda‚Äô like some other more familiar acronyms like API and XML. But, it‚Äôs also like‚Ä¶ fingers? Sam‚Äôs enthusiasm and explanation certainly had us ready to dive in! This episode‚Äôs Measurement Bite from show sponsor Recast is an explanation of model robustness from Michael Kaminsk y! Links to Resources Mentioned in the Show Cursor History doesn‚Äôt repeat itself, but it often rhymes Zed Agentic Engineering Series MeasureCamp GitHub‚Äôs Official MCP Server Zed ACP Opencode.ai (Podcast) Good Hang with Amy Poehler (including the Rachel Dratch episode ) Bhavik (Bhav) Patel Manas Datta Superweek Christopher Berry Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models Normally, the image we drop on an episode is a photo taken by a human, and we attribute it accordingly. This time, given the topic, we just couldn‚Äôt resist, though: we threw the entire transcript at Nano Banana with a minimalist prompt to see what it came back with. Episode Transcript 00:00:05.75 [Announcer]: Welcome to the Analytics Power Hour. Analytics topics covered conversationally and sometimes with explicit language. 00:00:15.15 [Michael Helbling]: Hi, everyone. Welcome. It‚Äôs the Analytics Power Hour. This is episode 288. We spent the last decade putting walls around our data, securing it, governing it, putting labels on it. And now the AI revolution walks up and is like, hey, can I see all that? Today, we‚Äôre going to discuss Moedel Context Protocol, or MCP. I mean, it‚Äôs an open standard. It promises to stop all the copy, paste madness and let AI talk directly to your data systems. Is it the end of the data silo or just the beginning of a new governance headache? Well, we‚Äôre going to try to establish an MVP for PMF of MCP all in one hectic hour. All right, let me introduce my co-host, Val Kroll. How are you doing? I‚Äôm good. This is going to be an interesting one, yeah. All my acronyms, yeah, that was fun. All right, Tim Wilson, always a pleasure. Likewise. All right, I just used the acronyms to make myself sound smart. That‚Äôs all. Let‚Äôs get that in early. And I‚Äôm Michael Helbling. All right, well, we need a guest, someone to help us dive into this topic. And we‚Äôve got a great one. Sam Redfern is a staff data scientist at Canva, currently working on search and recommendations there and previously marketing measurement. Prior to that, he has held data roles at both Meta and IAG, and today he is our guest. Welcome to the show, Sam. 00:01:36.31 [Sam Redfern]: Thank you very much, Michael, Tim, and Val. We‚Äôre really excited to be here. First time caller, long time listener. Oh, that‚Äôs awesome. 00:01:43.76 [Michael Helbling]: Well, we‚Äôll ask questions and take our answers off the air. No, no. 00:01:48.48 [Michael Helbling]: So. 00:01:51.27 [Michael Helbling]: Sam, I‚Äôm excited to talk to you about this, because obviously, all things AI are very of the moment, and everyone sees the term MCP. But I think if we just take a step back, maybe you could just fill us in on what exactly an MCP is, model context protocol, where did it come from, give us some background on the whole concept to establish the conversation today. 00:02:17.34 [Sam Redfern]: No worries. Super pumped to be talking about this. Let‚Äôs take a step back and think about what this is solving, in a sense. We‚Äôve had access to these large language models tools for a little while now. In the early days of GPT2 and GPT3, before chat GBT, these things were like word calculators in a sense. I really like the analogy that it‚Äôs like you put the numbers into your calculator and you get the equation out. This is the same for almost words. Early large language models acted like that. And the innovation in the open AI space was to basically feed the output back into the input and make this resumable format. And what‚Äôs interesting about this whole, so let‚Äôs step back from MCP and branding and letting technical teams come up with the term for things because this is how we got NFTs as a term at the same time. But the core problem to be solved with these is that we‚Äôve got something that feels a little bit like a person in the sense that you will give it some words and it will respond with some words back. Could you give that agent or that large language model the ability to do something other than just converse? And so the first application of tool use, in a sense, in large language models, actually came from the open-source LangChain team. And for those who don‚Äôt know what LangChain is, it‚Äôs a framework for building agentic experiences. And so you can have your anthropic model your open AI model or whatever you want, and then you allows you to piece together bits of technology to add context into the large language model to try and get it output. And so in April 2023, PR was submitted to the Landtrait project, allowing it to open up for the large language model to take a browser URL and to go have the back end application request the contents of that HTML and then bring it back into the context window of the agent itself. And if you think about it as like the core thing that it‚Äôs trying to do is it‚Äôs trying to get this I think about it as fingers in a sense, is it‚Äôs trying to give the large language the ability to touch something, a bit of information, bring it closer to it for it to understand. That‚Äôs at its core what these MCP tools are. MCP is like a brand term through Anthropoc. To say it‚Äôs a standard is to be very generous. But I‚Äôm really bullish about the concept of giving these large language models access to tools for them to be able to solve problems. 00:05:22.34 [Val Kroll]: So I have to admit that I really did think that MCP was just like the API for LLMs. But the more I was looking into this, it was kind of understanding that those fingers like you use in your analogy is really giving it more access than just here‚Äôs this endpoint. And it‚Äôs just a one-time thing. Can you talk about some of the things that you give it access to with those fingers or to grab to kind of give a little bit more color to what it actually does or what it‚Äôs capable of, if that makes sense? 00:05:54.59 [Sam Redfern]: Yeah, absolutely. So this is in the weeds of how they work. I think the context to understand is if you‚Äôve ever done work inside of large enterprises and you‚Äôve tried to create an application access username and password, it‚Äôs a total pain in the butt. to go get this thing. And then your infrastructure team is like, well, you‚Äôre going to change the password every three weeks. And then you have to have a cryptographic token to do something. And it‚Äôs in some sort of space. And the reason why, actually, Anthropoc had a previous attempt at tool use in October 2024, a month before MCPs were announced, where they had a system that would take over your browser and move your cursor around. And the reason why MCPs are running on your local computer is that your user account has access to all these systems. That‚Äôs why the early paradigms of these systems are as close as possible to the end user‚Äôs system. So the analogy I give on the fingers, in a sense, is inside these MCPs, you can give it access to any number of‚Ä¶ The standard allows you to sort of use representatives any number of tools. And you have bits of information, right? So when the agent starts, it‚Äôs basically given a list of all the tools that the MCP server has available to the agent. And so has the name of the tool. And so let‚Äôs just do a really simple example of like us, like in our agent environment, we have two tools, right? One of them is called a saw and the other one‚Äôs called a drill, right? In our SOAR tool, we would describe the name as SOAR. We would say the description is it cuts wood in a single direction across a line. Then the inputs to that is the position of the wood and the depth. That is a finger for lack of a better term. That‚Äôs our first tool and our second tool might be drill. That allows you to drill a hole through the piece of wood. 00:08:03.11 [Val Kroll]: Okay, so I have to ask one more. Sorry, I‚Äôm hogging the air. But I guess the one other thing that I‚Äôm struggling to grasp a little bit is what was the need for standardization of this, like the protocol? Can you talk about what that is solving? Because what you shared in that analogy was great. I‚Äôm absolutely going to use that, and I‚Äôll give you credit every time. but like why was there a need to standardize outside of like you know enterprises you know would feel more secure with that or you know the governance would be easier but is there any more more to it than just that piece? 00:08:39.22 [Sam Redfern]: In the adoption curve, we are so far away from the governance piece on this stuff. There‚Äôs a bunch of companies right now that are trying to put governance around these systems, and I‚Äôm sure at some point we‚Äôll talk to maybe some of the potential downsides of the standard if we want to call it that. But the reason why Anthropic went down this path is In the technical details around how the LLM is trained, they have been doing this work of training the large language model to use this like special escape set of characters. So when the large language model is like Okay, I think what I need to do is use the saw tool and then it has this string of characters saw tool string of characters, and that indicates to the sort of the agent that‚Äôs hosting the large language model. Okay, I have to take the text below this. and send it into the tool itself with the input parameters that it needs for it. Anthropic had this huge lead because they‚Äôve done the work of training their large language models to for tool use and using their reinforcement techniques to basically say, this is what you have to do. And this was this huge lead that anthropic had for a couple of years, in a sense. Everything feels like it‚Äôs a couple of years. It‚Äôs really about eight months, right? Until other people started trying to solve this problem. Opening, I had their own sort of call procedures kind of method, like I think they were called functions. And it was a very similar kind of thing. Like anyone could have come up with a standard. The core problem they were trying to solve is how do you give the large language model a hand for it to basically make decisions about what information is pulled towards it or what information or what actions it takes when it‚Äôs pushing out. 00:10:36.40 [Tim Wilson]: This is slowly coming a little more into focus and still pretty damn fuzzy for me. I know recently it seems like there‚Äôs been a lot of chatter about Google Analytics having an MCP server. Is that the right terminology? That is something that that the Google team said, we‚Äôre going to produce this to basically make the, this is a saw. This is what it does. These are the inputs. And it‚Äôs just a much a lot. I mean, your analogy was very, very simple. Is it as simple as that, which has me going back to saying, well, when Val said, It‚Äôs like an API for LOMs. It sure sounds like an API for LOMs. And I‚Äôm missing where that analogy is breaking down. 00:11:35.02 [Sam Redfern]: I think you can use it. There‚Äôs a lot of analogies of talking about these NCP tools as being the early dates of APIs and stuff like that as well. I think there‚Äôs an extra bit of the near direction of where these systems are moving, which is more interesting in the API part, but just to come back to that. The way I think about it, APIs is a great way of talking about it, and there‚Äôs lots of people doing weird fun things with these tools right now. If you remember, I think some of us on the call are old enough to remember the early days of web 2.0 and people were making APIs for like the weather and it was open and everything was fine and you know we were very far from like the standardized way of we think about this sort of stuff now right like it‚Äôs uh The way you design an API is very standardized now. I think the thing that‚Äôs different is one, we‚Äôre dealing with this huge amount of non-determinism, right? And we‚Äôre dealing with all of these different terms and terminologies that exist. So I think everyone on the podcast might have heard of the term agent, right? And so an agent is the idea where you have a resumable output. You have like some text that is the system prompt, and then you have this resumable conversation. There‚Äôs another term that‚Äôs being formed right now called a harness. A harness is an idea where you have an agent and you have a tool plugged into the side of it. That has a domain of knowledge attached to it at the same time. Cursor is an agent. The claw desktop is an agent. Oh, sorry, sorry. Cursor is a harness, right? It‚Äôs got access to all these different tools. I think the, I actually think of NTP and where it‚Äôs at right now is more akin to these digital document formats like XML, right? So we started with XML and the number of people who are writing XML these days is almost none. However, the amount of change of this standardized document format then brought us to JSON and now it has unfortunately brought us to YAML and Markdown. We are at the XML stage of this development is that this is going to tool use conceptually attaching to large language models through agents and harnesses is That is going to stay for a long time. Whether it‚Äôs the MTP standard or someone comes along with a better standard, then we‚Äôll see how that goes. 00:14:12.44 [Michael Helbling]: You know how developers got the AI engineer role? It‚Äôs time for the rest of us. I think we‚Äôre witnessing the rise of the AI analyst. 00:14:22.32 [Tim Wilson]: OK, does that just mean asking a chatbot to do math? Because I have Excel for that, Michael. 00:14:28.43 [Michael Helbling]: Well, no, Tim. I‚Äôm talking about Ask Why. It‚Äôs full stack analytics. I ask a question in plain English, and the product prism orchestrates the whole thing. You can pull in data from Excel or BigQuery. 00:14:42.10 [Tim Wilson]: Hold on. You‚Äôre sending BigQuery data to an LLM? Security is going to have a heart of track. 00:14:48.17 [Michael Helbling]: Well, that‚Äôs the best part. Ask why doesn‚Äôt upload your data. Explain? Well, it creates a semantic layer. It sends the context to the LLM. The LLM writes the code, and that code runs locally on your data. Your actual numbers never touch their servers, so it‚Äôs totally traceable. 00:15:07.61 [Tim Wilson]: So, I get the automation, but my data stays safe and secure? 00:15:13.21 [Michael Helbling]: Exactly. Plus, it remembers context, so as you automate routine tasks, it stores those, so you don‚Äôt have to explain it all again the next time you do that same task. 00:15:23.83 [Tim Wilson]: OK, I‚Äôm listening. 00:15:25.81 [Michael Helbling]: Where do I get it? Well, it‚Äôs even beta right now, and you can go to ask-y.ai. That‚Äôs ask-y.ai. You can get ahead of the curve and join the ranks of the AI analysts. 00:15:39.33 [Tim Wilson]: And because we like you guys, use code APH when you sign up, and our friends at Ask Why will put you at the top of their wait list. 00:15:48.17 [Michael Helbling]: Yep, stop pasting data into black boxes. Get Ask Why. 00:15:52.99 [Tim Wilson]: that I‚Äôve had the XML question as well as whether it was, because I remember that being coming from an HTML world and then XML came out and it‚Äôs like, look, XML doesn‚Äôt give a shit about what you‚Äôre rendering in a browser, but it is this structured world. So I feel like, and then JSON, I sort of understood because of the XML. And that makes sense because there were, there was talk of saying different, applications uses would say using this XML structure, let‚Äôs define kind of specifically how that is going to be used in the context of this financial services thing. So you‚Äôre saying that is also a useful if imperfect analogy? 00:16:40.80 [Sam Redfern]: Yeah, look. Uh, history sort of rhymes more than copies, right? Like, um, you know, it‚Äôs, it‚Äôs going to, um, uh, like, It‚Äôs the first time in software that we‚Äôve had this amount of non-determinism to deal with, right? You think about what success has meant in software development or data before, and it‚Äôs like some human‚Äôs ability to remember some random function as part of a library and be able to write that code as fast as possible and do it in as perfect as close to grammar as possible. The problem with this new world that we‚Äôre going into is the skill of dealing with non-determinism is not closely overlapping with that historical set of skills. It‚Äôs going to feel different and people who talk about the vibes of a model, there‚Äôs some truth in it in a sense. Getting a feel and it‚Äôs true with tool design. When you‚Äôre building an MCP, so we‚Äôll just go back to the MCP paradigm, And so you‚Äôre thinking about the tools that you‚Äôre building and the fingers that you‚Äôre giving this agent and this harness access to. When you‚Äôre starting out, you‚Äôre doing kind of the early playful part of programming, in a sense, right? Where you‚Äôre just like, oh, does this connect to this? And when I run through it, what problems do I see with it? I do think that, like, It feels like those early days of these standards and people are playing around with them. And then when you want to get serious about the thing that you‚Äôre building, you‚Äôre then looking through the agent logs, you‚Äôre seeing what tools it‚Äôs calling, you‚Äôre seeing the parameters, you‚Äôre seeing how many times it correctly passes in the correct parameters and everything like that. 00:18:30.07 [Tim Wilson]: So let me hit the non-determinism point. And maybe I‚Äôm going to go back to using the Google Analytics MCP as an example that the The client, the application that‚Äôs hooked, the agent that is hooking in and using the MCP, say it‚Äôs a LLM, it‚Äôs core. And maybe I‚Äôm missing the non. I‚Äôm thinking of that as being it‚Äôs a it‚Äôs a probabilistic thing, but it‚Äôs hitting the MCP to get stuff back. Is the MCP necessarily also kind of non deterministic? Or is it no, like the inputs may be kind of floating around a little bit, but and or maybe it just depends on what it‚Äôs an MCP for. If in the Google Analytics example, I would say if the input is users in the last month that the MCP would say, well, as long as that, or is it that input‚Äôs going to come in with the little squishiness in it, and it‚Äôs up to the MCP to say, I got to figure out what I should go and pull and return. 00:19:39.91 [Sam Redfern]: Yeah, and I think this is a good point to talk about this interesting dimensions that‚Äôs coming up recently. If I was going on a league team, which I‚Äôm definitely not, and I don‚Äôt think I‚Äôve used Google Analytics for over a decade, and I missed many of the big transitions. I‚Äôm probably not the best person to talk about GA, but So the Google Analytics MCP is going to have this problem where they have these dimensions and measures and breakdowns, and then they‚Äôre obviously trying to do it on the cheap on the inside. And so they‚Äôre only storing some of the information. So they‚Äôre going to have a basic report tool, so it‚Äôs going to be called the report tool. And the name of it is going to be traffic analysis. And it‚Äôs going to be put the date range in, and then it‚Äôs just going to return back a very minimized array of what the traffic has been. 00:20:41.10 [Tim Wilson]: Report tool, that would be like a saw, but there‚Äôs going to be separately a drill. When you‚Äôre saying a tool, that is a tool that‚Äôs available as part of the MCP. Okay. 00:20:53.24 [Sam Redfern]: That‚Äôs right. Now, where this gets interesting and anthropic announced for lack of a bit of time on the, I think a couple of days ago, announces code execution with MCPs and allowing you to actually write code. This is the thing that I‚Äôve actually found over the last couple of weeks, which is it‚Äôs way better getting the LLM to write code to interact with APIs or SQL or something along those lines than it is to actually give it access to all of these tools and all of these intermediary steps. If and you might have seen this from your own experience of, you know, you‚Äôre probably spending a little bit less time hacking away at a piece of sequel, getting it to form exactly what you want it to these days. You know, you‚Äôre probably spending a bit more time of like here‚Äôs all the table space that I‚Äôm working on. here is a thing that I want to query, here‚Äôs what the outputs look like, and then you‚Äôre sort of having this sort of feedback loop where you‚Äôre doing that work. And my guess is, is that if you wanted to build a more sophisticated MCP, and if you were Google, you would actually lean into this concept where you would let the agent go build a little piece of Python code or JavaScript or something along those lines to query a bunch of known API endpoints to form the data back in the way that you want it to. Snowflake has its MCP server and Canva would make something called data MCP, which takes all of this data information we have and allows the LLM access to understanding how to use it. you‚Äôre really doing this piece of work around context engineering and you‚Äôre trying to think about like what is the LLM going to put into this tool for then it to get this output out. And so Michael to say, and so your sort of question here is that the MCP tool itself is deterministic, right? So it is an application in the traditional software sense. I think a lot of these MTP tools are sending data outside of out to the internet, right? They‚Äôre connected into API or a SQL database or something along those lines, but you can have deterministic tools inside of the MTP server as well that‚Äôs locally that‚Äôs connected. So you could just have like a calculator tool and it just adds numbers together and then returns exactly the right number out. You know, we‚Äôve heard the joke of counting the number r of r‚Äôs and strawberry, right? So you could have a little Python function that just counts the number r‚Äôs and strawberry and it‚Äôs just like, all right. the R counter tool, put the word strawberry in, and this is how many R‚Äôs you get back. And so this is the whole idea of, and this is, I understand I‚Äôm going to do shout outs later on, but Zed, which is an ID, has an agentic engineering series. And what they‚Äôre saying, And I just think that they have this really great framing of the problem that we‚Äôre working on today, which is how do you take the advantages of non-deterministic systems and couple it with the advantage of deterministic systems to get something more than the sum of its components? 00:24:00.95 [Val Kroll]: So I would love to take a little bit of a turn because you‚Äôve teased it a little bit, but I‚Äôm so eager to hear some of your favorite use cases and examples and that you can talk about. And I know you mentioned before, it‚Äôs still early days, but if you could talk about some of the things that you felt like weren‚Äôt possible for or too much effort for what it was worth in the past, but now it‚Äôs unlocked this or solved this for you. 00:24:27.20 [Sam Redfern]: I‚Äôll talk a little bit about some of the stuff we‚Äôve got working inside of Canberra at the moment. We use a large database vendor, which I will keep their name out of just so they don‚Äôt get in trouble. They‚Äôre going down this path of building out their own separate MCP tools and stuff like that. But what‚Äôs interesting and what I think is a big opportunity for people in this space is that building these tools for your organization is actually the critical skill that we‚Äôre going to see in the coming period of time. Every organization or company is really different, in a sense. And they made a database choice five years ago, and they made like a data transformation tool twice like four years ago. And you have all the incremental knowledge and information that‚Äôs built on top of that, which is going to kind of be unique to your organization in a sense, right? And I think there‚Äôs going to be vendors who are building tools in this space. But if you‚Äôre sort of a midsize company, like I think something to really think about is building customized versions of these tools that actually work with the flows of your organization and really having teams that are like building, thinking about these agenting and engineering practices on how to actually automate parts of the work that people don‚Äôt want to do. So some of the use cases that I‚Äôm sort of playing around at the moment, just so just the last week I‚Äôve been working on using the Altair Python visualization library and actually building a Python based sort of sandbox environment for it to run the Altair code. And so The way this works is you just put the SQL statement of the data that you want to pass into the Altair code, and then you have a Python sandbox part of the field of the tool. It just puts 300 lines of Python into it, and it builds the visualizations out of it, right? So using these really nice Python visualization libraries has always been a pain in the butt unless you tattoo the way every part of the application works on your arm so you can know exactly how it works. But again, we don‚Äôt have to worry so much about grammar anymore, because if you feed these systems examples, they can come back and help you visualize this way faster. And I think that‚Äôs where, you know, Zed has this post where they, their concept is leverage, not magic, right? And what we‚Äôre trying to do is we‚Äôre trying to take our staff members and we‚Äôre trying to make them move faster and explore more in a shorter period of time to get to a better end outcome. Just on other sort of like interesting fun use cases, I‚Äôve been, At home, I‚Äôve got my own little sort of home lab kind of thing and stuff like that. And part of playing around with that is there‚Äôs all these command switches and stuff like that. And so I built a custom NCP server for home that documents all the different applications that I use in the CLI. And it has all of the context of it. I basically put in a free text field of what I‚Äôm trying to do. It then uses a search engine to search over the data. It then takes that context, puts it into the LLM, and then the LLM goes and gives me all the command switches and stuff like that. Another one is, I think the reason why Moe recommended me for this is I gave a presentation at MeasureCamp about, at MeasureCamp, you have to come up with a talk title, otherwise people don‚Äôt show up. I said that MCP is the real apex predator for your job in 2026. And obviously, you know, I don‚Äôt think that‚Äôs true. But so I wrote that someone was like, you need to give a talk sound. I‚Äôm just like, fine. So I wrote that part at 11 o‚Äôclock, I then vibe coded up a maybe the game battleship. And so I made a version of battleship that uses MCP tools as the the fingers that the LLMs can use to play against each other. And then I built an agent harness where I could get different vendors, MCP tools to actually fight the game battleship against each other. And then you could actually watch the turn by turn thing of watching them compete against each other. And they would then have their thinking of like how they thought about the strategy of the other player. And then you could like change the prompt and be like, okay, you are going to be the random player and you‚Äôre just going to do the most random things you possibly can. And then the other one is like the most strategic player of like, this is the common moves in battleship. I‚Äôm going to do this and stuff like that. And it‚Äôs just, it‚Äôs like, like, it‚Äôs a whole new paradigm of like weird things to play around with. And like MCPs are just like this, this layer for you to like do this joining between deterministic and non-deterministic systems. But once you start playing with these systems and you‚Äôre finding different ways of interesting things to do with them, like, you know, it‚Äôs, it‚Äôs, it‚Äôs, It puts the fund back into sort of like the early stages of programming again. 00:29:38.16 [Val Kroll]: So you giving the context of like deterministic, non-deterministic is really that‚Äôs helping it crystallize a little bit in my mind what some of this is. But I do want to go back to when you first started talking about some of these examples, you were talking about how every organization is different. Everyone‚Äôs working with a different stack. Everything has to be kind of in context of what‚Äôs going on inside your organization. Can I just go back and just repeat a little bit one of my earlier questions. What is the value then of the standardization versus it being custom inside of your organization? Is it just about the ability to leverage those other tools that are using MCP or is there internal benefit too? I guess I might be just, it‚Äôs not clicking for me. I would love to just hear you share. 00:30:27.67 [Sam Redfern]: No, no, no, no. Okay, so MCP is the thing that allows you at the moment until someone comes up with a better standard. And we should probably talk about some of the downsides of MCP as well. Just all the criticism, sorry, the criticisms as they stand of MCP, but MCP at the moment allows you to bridge that gap between deterministic and non-deterministic systems. You‚Äôve got the vendors, and the vendors are going out, and they are building their own customers. MCP is right, because what they want, because what they‚Äôre getting, is they‚Äôre getting pressure from leadership teams of like, okay, we need to get some AI in this organization right now. I have called desktop on my computer and I want to be able to query this information directly from Claude and have that come back to me in a sense, right? And MCPs is like a path you can go down there, but the problem is that you‚Äôre wrestling with the non-deterministic nature of these systems when you do that type of connection in a sense, right? And what you actually, this is where building up that practice inside of your organization is really important because when you get into the detail of how these systems work, you realize that giving senior leadership teams access to the raw thing that directly queries the database is problematic for lots of different reasons around you‚Äôre not able to check it, you can‚Äôt give it a system prompt, all that sort of stuff. So MCPs, the standard, if we can call it that, is just the little connecting block, in a sense. the practice of what I‚Äôm talking about about the non-standardization inside of organizations is that you can totally go use the vendor solutions, right? But it‚Äôs always going to feel like it‚Äôs through a fuzzy piece of glass, because unless you‚Äôre doing exactly what the vendor has, right? Like, if you‚Äôre If you‚Äôre 100% Google shop, and you‚Äôve never used anything other than Google, then maybe the Google stack is going to be great because that‚Äôs what they‚Äôre going to be using internally. And they‚Äôre going to be copying from that of how they‚Äôre building it. But I don‚Äôt know about you, but most organizations I ever interact with is it sort of like a collage of different solutions. And the money is in getting them to connect together, right? Yeah, templatized versus custom kind of. 00:32:38.05 [Tim Wilson]: Altair, take Canva, take Snowflake, take Google Analytics and MCP for those. Is there the option that Canva or Altair or Snowflake or Google, and those are intentionally very wildly different types of platforms, they can sort of create an MCP, one of these connectors that say this is kind of generic, but there‚Äôs also an option that I as a user of Canva with access, I could also build my own MCP, my own connector, or is it okay? 00:33:20.36 [Sam Redfern]: So you‚Äôre raising on a really good topic, which is called context pollution, right? So there was a criticism of GitHub‚Äôs MCP server where it has like 24 some number of tools, right? And the majority of people use like three, right? And so I push. If you get into the details of how NTPs work is that they repaste the entire list of tools and the tool descriptions and all this sort of stuff with every single message that goes through, right? Because they are trying to solve the context engineering problem of, like, The LLN needs to really know what all the tools are at every single turn. And you can go and add 70 tools to an agent harness. And you should do that to watch it not work, because it‚Äôs very entertaining. And you can suddenly watch all of your contacts disappear and have all sorts of problems, right? 00:34:24.92 [Michael Helbling]: You got extra tokens to spare. 00:34:27.04 [Sam Redfern]: Go ahead. You know, somebody would go win the token awards or whatever it is. I did the other day, right? You know, some people need the token trophy. That‚Äôs great. But the like your job as an engineer or a technology person inside of an organization is to do it in the most sensible, reliable way possible, right? And you‚Äôre trying to harness these nondeterministic systems to get the best outcome. And part of the reason why you go and build that custom harness that is fit for purpose for your organization and has different flatters depending on exactly the task that you‚Äôre trying to get into is you‚Äôre trying to, it‚Äôs in the name, you‚Äôre trying to take that harness and you‚Äôre trying to constrain this non-determinic system to only work in this particular domain. I think a lot of people, when they talk about these MCPs, they‚Äôre talking about it from their experience of having clawed desktop on their computer and connecting it up to JIRA or some other thing like that. That‚Äôs a totally valid use case. I don‚Äôt have to open JIRA anymore. I think the favorite part of my job now is when someone assigns me a ticket, it‚Äôs the only thing I have connected to the clawed desktop on my computer. and I interact with all of my JIRA tickets through Claude. I‚Äôve solved the Atlassian interface problem by just never having to open it. That‚Äôs for me as a human here, but when we‚Äôre talking about making these systems do useful things in your organization that you can‚Äôt convince engineers to pick up, or it‚Äôs really boring work, or it‚Äôs testing work, or something like that. That‚Äôs where these systems kind of shine, right? We‚Äôre not trying to put someone out of a job or anything like that. What we‚Äôre trying to do is we‚Äôre trying to get that as tasks that are not particularly enjoyable, like documentation, testing tracking, all this sort of stuff, like building custom harnesses around that to help engineers make the best possible decision when they‚Äôre building something, That‚Äôs the real advantage of these tools. 00:36:30.89 [Michael Helbling]: Yeah. And I think, Tim, also, the Google Analytics example is tricky because it‚Äôs very limited. And it basically is an API layer to Google Analytics. It‚Äôs not really giving you more MCP-ish type of interaction. So I think it adds to the confusion a little bit. Because it‚Äôs like, you can do all the same things you can do with the Google Analytics MCP server with their API. It‚Äôs just call this function. But instead of you writing the query to the API, the LLM does it for you. But it‚Äôs not more stuff. 00:37:04.57 [Tim Wilson]: How does the GitHub MCP server? So I have two questions. One, it sounds like a lot of platforms maybe of those, if they‚Äôre 24, and I‚Äôm assuming it‚Äôs not exactly 24. However many tools there are within the GitHub MCP server that a lot of them are just a layer to the API, and maybe there are some that aren‚Äôt. But if you were saying, we do want to use a GitHub MCP server, this has got too much, would it be? I‚Äôm going to get their MCP server and I‚Äôm going to whittle it down and then probably check it back into GitHub just to make things confusing. But do MCP servers get, there could be the official Uber generic one developed by the platform and then somebody says, yeah, I need to make one that‚Äôs just a much narrower scope and maybe add some flavor on it or does it not work that way? 00:37:58.20 [Sam Redfern]: Yeah, great question Tim. And this is why the agent, like talking about agentic engineering and harnesses is really important because in a harness, you say, these are the MCP servers only have these tools, right? And so you can take the GitHub MCP server and you can say, here‚Äôs your three tools, deal with it. Sorry, I just, you know, let‚Äôs not get into the accuracy of AI overviews, but according to in June 2025, apparently exposes 51 plus tools. Okay. No, okay. You know, like, but this is like, if you‚Äôre in a world where you Do you narrow that down to a very limited set of the tools? And you can see this in the cloud desktop thing. If you load an NCP server on the cloud desktop, you have little switches where you can turn on and off tools in a sense. The intention of these systems is that you narrow the scope down to exactly the problem that you‚Äôre working on and just that. But what‚Äôs interesting, Tim, is why bother having the GitHub? If you‚Äôre doing the coding yourself and you‚Äôre using it inside a cursor or something along those lines, it‚Äôs like, why bother adding the GitHub MCP server at all? Why not just get the LLM to execute something in the command line with all the command switches of the GitHub CLI? 00:39:13.50 [Tim Wilson]: Also, is this getting us to the downsides? 00:39:18.24 [Val Kroll]: I was just going to say, he risks you a bit chomping at the bit, Sam. Let‚Äôs hear it. 00:39:24.80 [Tim Wilson]: I mean, there‚Äôs part of it feels like this is, it‚Äôs new enough and wild, wild west to know there‚Äôs like, there could be a governance issue that it would be very easy to embed MCPs into an organization and they‚Äôre not well thought out. They‚Äôre not well built. They, they, I mean, that just, it seems like there‚Äôs just a governance thing like anything that gets rolled out. that one Sam creates something and all of a sudden the entire organization is dependent on it. And maybe Sam‚Äôs not very good at, you know, or just half-assed it on a weekend or something like, I don‚Äôt know. So that‚Äôs my, I‚Äôm throwing that out that it seems like there‚Äôs a governance risk when you‚Äôre being, you‚Äôre able to do this stuff so quickly and roll it out. Is that one of the downsides? 00:40:13.13 [Sam Redfern]: I mean, building, and this is something Canva does really well, right? Like building AI tools for people to use in the application is just really different to building stuff internally. Like we are still at the early days of this stuff and Canva‚Äôs ecosystem team building out really strong solutions to the space of whether canvas empty server or client or something like those lines. So there was like the professional teams who are like building this sort of stuff for external consumption. So in open AI, you can, you know, you can. use the LLM to interact with it. You can use GPT-5 or whatever they call it these days to interact with Canva and modify your designs and stuff like that. That‚Äôs all using this style of tool technology in a sense, right? And there‚Äôs a lot of governance that‚Äôs been there, right? There‚Äôs a lot of thinking about permissioning, thinking about what information we‚Äôre giving to the LLM, what actions we‚Äôre giving to it, what are the actual actions that change something. One of the downsides of giving the LLM access to your terminal command line is that it could just delete all the files in the directory or something on the inside. I think my favorite one is where an engineer is trying to get the LLM to write the code so it passes all the tests and so it solves the problem by deleting the tests and it‚Äôs just like problem solved, I‚Äôm done. a technically correct, the best type of correct, but actually, no, that‚Äôs not what I wanted. And so this is why that agent harness framework is really useful because that‚Äôs where we‚Äôre like, here is this domain of a problem. Here is this very finance set of tools. Here‚Äôs how I want you to sort of exactly work on this particular part of the problem. And I don‚Äôt want you to have this like long chain where you‚Äôre sort of like jumping between things. I just want to create the agents of instance, have it solve one or two problems, and for the agent instance to end, so then we can move on to the next problem. That is why we‚Äôre trying to solve and harness this non-deterministic nature. Some of the criticisms of this MTP standard is like, one, it‚Äôs not a standard, right? Like a standard, if we think about it as from the Internet Enduring Task Force, the W3C is like a collection of for-profit companies coming together and sending some of their best engineers to basically have like a very disgruntled call with a bunch of other engineers from other sort of for-profit companies, right? Like I don‚Äôt, as far as I understand, it‚Äôs kind of just anthropic building this internally, polishing stuff on their blog, they picked up FastMTP, which is like an open source thing. And they just said, all right, this is the standard. We‚Äôre going to use this as our standard library and sort of extend it out and stuff like that. you know, coming back to that governance is like, this is not a structure that feels like it‚Äôs ready for like, you, it‚Äôs buyer beware on the internal corporate governance stuff. And the way you design these systems is really important. And so some of the data tools I build internally, it has no ability to write information to the database, right? Because that is completely like, we‚Äôre just not ready for that kind of world, right? And maybe in really select kind of instances where there‚Äôs a really strong, hard-to-surrounder and you have like a checking endpoint and all sorts of other stuff like that and things like that as well, things like Langchain are really useful. But we need to, that‚Äôs why I think most of the value of this space is still in the internal application use cases, in a sense. That‚Äôs where you can do a more experimentation and worry less about the strangeness of the internet and the internet and AI and all the problems attached to that. But when you‚Äôre developing these tools internally, you have a team of you know, a handful of engineers and like, you can make their lives like tangibly better because they don‚Äôt have to put context into their mind at a particular part of the problem. And they can just have that answer come back. And even if it‚Äôs right 90% of the time, it‚Äôs probably better than when you got your junior data scientists sort of do it in the first place anyway. So, you know, that‚Äôs that‚Äôs the like, that‚Äôs the challenge. As far as One of the other criticisms of Anthropox MCP is that it doesn‚Äôt have authentication baked in. Moest of the MCP, so it‚Äôs counterintuitive having this term of MCP server and client in a sense, right? And what happens is you‚Äôre literally running a little application. You‚Äôre like, you know, Python run this like Damon or something along those lines. And then that is just talking to the it‚Äôs like running a local web server in a sense, right? And that is the security model that has been sold for in the early days. And that‚Äôs why the Zed has their ACP agent. What is it Zed? ACP. I think in a couple of years, we‚Äôre going to be talking about the agent client protocol as maybe a better way of building this sort of stuff. Everyone sort of agrees that the ACP protocol is probably a better representation of where we‚Äôre going in this space. And it is an open standard. I don‚Äôt think they‚Äôre sort of like the W3C or the internet engineering password style of standard. Back to that XML example, I don‚Äôt know about you. I don‚Äôt read a lot of XML these days. We‚Äôre going to be moving to something else, but I‚Äôm very bullish on the concept of tool use in these applications and giving large language models these fingers to do things. 00:45:53.98 [Tim Wilson]: Is there any movement? It sounds like Zed has stepped in and done a little bit of this. Is there any movement to say, like the W3C had its different groups and came together that we should get? 00:46:08.82 [Val Kroll]: Didn‚Äôt Google and Microsoft and OpenAI, didn‚Äôt they all adopt it? Am I totally misunderstanding what that means? 00:46:16.54 [Tim Wilson]: that it‚Äôs another thing to say, here‚Äôs our, here‚Äôs our, we got to solve authentication. We got to have a recommendation and a standard for how authentication is going to be handled means they can‚Äôt just say, like it‚Äôs not there. That‚Äôs something that new that needs to be incorporated in a way that they say, yeah, we think this is generally going to work for most. We can all work with this, right? Cause that‚Äôs, I mean, it‚Äôs not, it‚Äôs not a static. I mean, I guess let me ask that question. It‚Äôs MCP. How static is it? Like when HTML came out, it wasn‚Äôt like, okay, we‚Äôre done. Well, there was a bunch of other stuff that was needed and browsers added functionality. And so it was kind of, it naturally had to evolve and is MCP the same thing that it needs to, yeah. 00:47:04.94 [Sam Redfern]: Yeah. So there‚Äôs a really interesting part of this, which is that there is a, I think there is a recommended output format to MCP servers that as part of their standard. But I think what‚Äôs interesting about this is that like because of the non-deterministic nature of these systems. And because you can, I don‚Äôt know if you‚Äôve ever played around with this, but it‚Äôs always good fun is to, you can have the start of your question in XML, then you can do the middle bit in YAML and then the end bit in JSON. And the large language model doesn‚Äôt skip a beat. And it‚Äôs just like, oh yeah, sure, I understand this, right? Like it doesn‚Äôt matter as much is kind of the context of this problem, right? Because We required these standards in the early days of the internet because they were purely deterministic systems with incredibly strong grammars. I just don‚Äôt think it matters as much anymore. That‚Äôs why I don‚Äôt think there‚Äôs been the same pressure to standardize because you don‚Äôt need to standardize in the same way. The only thing that matters is do you pass the tool call threshold in your large language model. And I think it may be, you know, like rather, rather than a very deliberate standard like TCP IP or IPv6, I think it‚Äôs going to be more along the lines of the QWERTY keyboard, which is like, we just kind of picked it because it was there first, not because it‚Äôs better. and MCP will probably change to something else in the future, right? But the primitives that make it interact with the large language model, I think, are now baked in enough that it would be surprised to see if we move away from that. And all we‚Äôre going to do is we‚Äôre going to find new ways of taking those primitives and doing this code execution thing. So I gave my example of this charting sort of like MCP extension that I built. Like all we‚Äôre going to do is we‚Äôre going to take the same primitives, but then we‚Äôre going to like do wildly different things with them that people didn‚Äôt think was possible before. 00:49:06.08 [Tim Wilson]: And at some point, that will have shifted to a point that it‚Äôs got a new label. And it‚Äôs like, oh, remember, it was just MCPs. Now we have something else, which is grounded in all that we learned from MCP. Okay. 00:49:17.86 [Sam Redfern]: Yeah. Now it‚Äôs going to be ACP. It‚Äôs going to be, who knows, whatever. I look forward to watching this name change over time. I‚Äôm sure there will be an XKCD comic at some point. There‚Äôs the end pop on standard XKCD comic, and we are not immune from that paradigm, which has been true in software for long enough. 00:49:40.98 [Tim Wilson]: I‚Äôve brought up that particular strip, I think, on two of the last four episodes. One was on semantic layers and one was on 00:49:48.77 [Michael Helbling]: Yeah, we‚Äôll check back in in six months because certainly things will have shifted quite a bit. All right, we do have to start to wrap up. And as we do that, let me jump into a quick break with our friend Michael Kaminsky from Recast, the Media Mix Moedeling and GeoLift platform helping teams forecast accurately and make better decisions. Michael‚Äôs been sharing bite-sized marketing lessons over the past few months to help you measure smarter. Over to you, Michael. 00:50:17.39 [Michael Kaminsky (Recast)]: When we perform statistical analysis of data, what we really care about is that we are discovering actual truths about the world, not random artifacts of the particular data set we‚Äôre looking at or the analytical methods we‚Äôre choosing. We want generalizable analyses, the kind where independent researchers answering the same question would converge on similar results. This is all another way of talking about a hugely important idea in model building or statistical analysis. Robustness. Without robustness, even a small tweak at assumptions or small changes of the data will spit out dramatically different results. Results that aren‚Äôt showing true causation or reflecting reality, but just picking up random noise. So how do we put this into practice when doing statistical analyses? We can randomly resample from our dataset or even randomly drop small amounts of data and see if the results are being driven by one particular outlier observation. Similarly, if we‚Äôre running a regression analysis with control variables, we can check how sensitive the results are to different control combinations. If the findings change dramatically depending on which controls we include, we should be skeptical of the overall results. The more robust our results are as things change, the more we feel confident that other analysts or researchers will end up drawing the same conclusions and the better chance we have of finding some underlying truth. 00:51:31.49 [Michael Helbling]: Thanks, Michael. And for those who haven‚Äôt heard, our friends at ReCast just launched their new incrementality testing platform, GeoLift, by ReCast. It‚Äôs a simple, powerful way for marketing and data teams to measure the true impact of their advertising spend. And even better, you can use it completely free for six months. Just visit www.getrecast.com slash geolift to start your trial today. All right. Well, one of the things we‚Äôd like to do is go around the horn and share a last call, something that might be of interest to our users. Sam, you‚Äôre our guest. Do you have a last call you‚Äôd like to share? 00:52:06.23 [Sam Redfern]: Well, I mean, obviously, thinking about this sort of this agentic engineering thing. OK, so I‚Äôm going to get in trouble by doing two. One of them is go to z.dev and go read about and always a problem. Go to z.dev. and go check out under resources and they have their agentic engineering series about the future of software development. I think it‚Äôs a great grounding of where we‚Äôre going in this industry and I think they lay out a really great vision of what this could be. The last one is that I don‚Äôt actually like Zed‚Äôs agent. I think one of the most important things here is to go get your hands dirty with these systems. They are just so much fun. And if you‚Äôre a bit of an old techie, it doesn‚Äôt matter as much about the grammar anymore and really just spend some money on tokens and explore it. And in that vein, I actually think the best agent you can get for nothing is OpenCode. And so I think it‚Äôs opencode.ai. Yeah. OpenCode, I think, right now is one of the best agent harnesses that you can possibly go and build things. They‚Äôve got really interesting things like the ability to define subagents that you can give different prompts and contacts to. And so if you want a really great base agent to play around with, to go and then build really interesting harnesses, can‚Äôt recommend the OpenCode thing enough. Nice. Thank you. 00:53:29.31 [Michael Helbling]: All right, Val, what about you? What‚Äôs your last call? 00:53:32.87 [Val Kroll]: So mine‚Äôs a total left turn. But I have just been really enjoying lately the Good Hang podcast with Amy Poehler. It‚Äôs been around not quite a year yet, I don‚Äôt think. But if you are just in the need of a good laugh, I am telling you, you will walk away from those with a stomach ache. The Rachel Dratch episode, I legit did a spit take. It is So funny. So anyways, she just has like lots of different celebrities on to talk about all different topics and it‚Äôs quite enjoyable. So does she have an MCP server? No, I‚Äôm saying keeping it light. We‚Äôre keeping it light. Yeah, that‚Äôs great. You need that. 00:54:18.51 [Michael Helbling]: All right, Tim, what about you? What‚Äôs your last call? 00:54:23.62 [Tim Wilson]: So I‚Äôm going to do kind of a mix of like the human side of things, just because we‚Äôre starting off the year. So now hopefully people are looking forward to what human people they‚Äôre going to go see in various places like in-person conferences. So I will plug that I am, I‚Äôm getting to return to Super Week this year, which I have missed for the last couple of years. And that‚Äôs a missed in-person and in Spirit, so superweek.hu. It‚Äôs February 2nd through 6th in Budapest. And then I‚Äôm going to double that up with just a couple of good follows. I feel like we need more humor on LinkedIn. And there are two guys who are both very reliably putting in just short, random, funny things, and also some good content. So I‚Äôm going to plug Bov Patel, Bovick Patel, and Manas, Dada, DA, TTA. He does all sorts of like something like finger guns, but every time he does something, he has a different sort of something guns at the end of it. So they‚Äôre just good follows to put a little less bloviating in your LinkedIn feed would be those two guys. And what did they teach you about B2B sales there, Tim? And they definitely make cracks about that along the way. 00:55:47.29 [Michael Helbling]: What about you, Michael? What‚Äôs your last call? Well, I‚Äôll be curious, Tim, to hear whether or not MCP servers come up at Super Week, which I‚Äôm sure they will. My last call is AI related. I just was hanging out with my good friend Christopher Berry a week or so ago, and he turned me on to a paper that some folks wrote about how to jailbreak large language models, because sometimes you just need it to give you the recipe for gunpowder or something. And apparently, a really great way to do that is just talk to it in poetry. So, if you add a poem, it will just tell it back to you as a poem and give you the information you want. No questions asked. So, not saying you should do that, but that‚Äôs something you should be aware of. We‚Äôll link the paper in the show notes. So, can I sneak in with one last thing? 00:56:37.69 [Sam Redfern]: Yeah, of course. It‚Äôs related to jailbreaking large-language models. There‚Äôs a community inside of Canberra, a channel where people share their tips and tricks for interacting with these large-language models. There was a thread on how do you get better outputs. Yelling at large-language models, surprisingly works, bribing large-language models surprisingly works. My favorite one is to tell the agent that a much smarter and more sophisticated agent is about to come and check its work. and it should hurry up and make sure that there‚Äôs no mistakes before it gets checked. 00:57:12.16 [Tim Wilson]: I so wanted to know that there was some Moe related threat in there that you‚Äôd be like, look, if you get this wrong, Moe kiss is going to be disappointed. And they‚Äôre like, that, oh my God, that is the ultimate hack. 00:57:25.77 [Michael Helbling]: Add some weights to that name inside of all the large language models inside of Canva. That‚Äôs probably a good idea. All right, Sam, this has been outstanding. Thank you so much for taking the time to come on the show. Talk about this topic. This has been great. Thank you very much for having me. It‚Äôs been a great time. Yeah, no, and I‚Äôm sure our listeners of which there are many will have a lot of questions or things like that. We‚Äôd love to hear from you. You can reach out to us on our LinkedIn page or through the Measures Slack chat group or via email at contact at analyticshour.io. as you‚Äôre listening or listening to this episode, also leave reviews and ratings. We like to get those as well on whatever platform you listen on. If you want, we also still have some stickers, then Tim will send them to you if you request a sticker over on analyticshour.io. Reach out to us that way. Awesome. Really great. I think this is a more technical topic, but I think it‚Äôs still very relevant to everybody in the data space because of the sort of the intersection of AI and data. It‚Äôs sort of a thing we‚Äôre all talking about. So, Sam, thank you for helping demythologize some of this, if you will, and bring some practical knowledge. I think it‚Äôs a huge service. And like you said, it‚Äôs changing every day. So, you know, apologies in advance for how outdated this podcast will be in about three weeks, but that‚Äôs just the way it works. You got to get started somewhere. The AI nodes take Christmas off. That‚Äôs right. Stop updating your LLMs for crying out loud. Yeah. The big news today was that Sam Altman issued a code red for open AI because Gemini is doing so well and they‚Äôve got to get back to getting hard work done. So, okay. Yeah. 00:59:14.15 [Tim Wilson]: Stop this 996 nonsense, right? 00:59:16.81 [Michael Helbling]: Yeah, right. We need some work-life balance. Take a break. Before the AIs take our jobs, we need some work-life balance. No, I‚Äôm just kidding. All right. I know that as you go out there and you‚Äôre working with data and you‚Äôre trying to use AI, it‚Äôs always complex and challenging and you‚Äôre learning a lot. It feels like the early days of analytics all over again. But I know I speak for both of my co-hosts, Tim and Val, when I say, no matter which MCP you‚Äôre using, don‚Äôt forget to keep analyzing. 00:59:43.59 [Announcer]: Thanks for listening. Let‚Äôs keep the conversation going with your comments, suggestions, and questions on Twitter at @analyticshour on the web at analyticshour.io, our LinkedIn group, and the Measure Chat Slack group. Music for the podcast by Josh Crowhurst. Those smart guys wanted to fit in, so they made up a term called analytics. Analytics don‚Äôt work. 01:00:08.09 [Charles Barkley]: Do the analytics say go for it, no matter who‚Äôs going for it? So if you and I were on the field, the analytics say go for it. It‚Äôs the stupidest, laziest, lamest thing I‚Äôve ever heard for reasoning in competition. 01:00:28.43 [Tim Wilson]: Rock flag and non-determinism. The post #288: Our LLM Suggested We Chat about MCP. Kinda‚Äô Meta, No? appeared first on The Analytics Power Hour: Data and Analytics Podcast .",
      "source_name": "Analytics Power Hour",
      "published_ts": 1767674142,
      "category_key": "ai_data_engineering",
      "score": 0.0031,
      "algo_score": 52.0,
      "upvotes": 0,
      "downvotes": 0,
      "content_type": "rex",
      "tech_level": "intermediate",
      "source_type": "podcast"
    }
  ]
}