# IDEA - Veille Tech Crawling

*Document partiellement reconstituÃ© - Sections marquÃ©es âš ï¸ Ã  complÃ©ter manuellement*

## 1. QUI/QUOI/COMMENT/POURQUOI

### Qui Ãªtes-vous ?

âš ï¸ **[Ã€ COMPLÃ‰TER MANUELLEMENT]**

**Nom :** Nathan Sornet
**RÃ´le :** Data Engineer / Tech Lead
**GitHub :** [@nathansornet](https://github.com/nathansornet)
**LinkedIn :** [Nathan Sornet](https://linkedin.com/in/nathansornet)

---

### Quel est le projet ?

**Nom :** Veille Tech Crawling

**Description (reconstituÃ©e) :**
SystÃ¨me automatisÃ© de veille technologique pour Data Engineers qui crawle 60+ sources RSS, classifie les articles via LLM (Groq), score la pertinence par embeddings sÃ©mantiques, filtre le bruit (contenu dÃ©butant/marketing), et gÃ©nÃ¨re des rÃ©sumÃ©s hebdomadaires publiÃ©s sur une interface web moderne (GitHub Pages).

**ProblÃ¨me rÃ©solu :**
Les Data Engineers perdent des heures Ã  parcourir des dizaines de blogs/newsletters pour rester Ã  jour. Ce systÃ¨me automatise l'agrÃ©gation, le tri et la sÃ©lection intelligente des meilleurs articles techniques.

**Valeur apportÃ©e :**
- â±ï¸ Gain de temps : 2-3h/semaine Ã©conomisÃ©es
- ğŸ¯ Pertinence : Top 50-100 articles (vs 500-1000 crawlÃ©s)
- ğŸ§  Intelligence : Classification LLM + scoring embeddings
- ğŸ¨ QualitÃ© : Filtre anti-bruit (beginner, marketing)
- ğŸ“– DiversitÃ© : SÃ©pare Technique vs REX (retours d'expÃ©rience)

---

### Comment ?

**Stack technique :**

**Backend :**
- Python 3.11+ (asyncio)
- Groq API (LLM classification + rÃ©sumÃ©s)
- sentence-transformers (embeddings sÃ©mantiques)
- aiohttp (crawling async)
- SQLite (storage + dÃ©duplication)

**Frontend :**
- React 19 + TypeScript
- Vite (build ultra-rapide)
- Tailwind CSS (design moderne)
- Fuse.js (recherche floue)
- marked (rendu markdown)

**Infrastructure :**
- GitHub Actions (CI/CD automatique)
- GitHub Pages (hosting statique gratuit)
- Cron : Lundi 06:00 UTC

**Approche :**
Pipeline ETL asynchrone en 4 phases sÃ©quentielles :
1. Crawling + extraction contenu
2. Classification LLM
3. Scoring multi-critÃ¨res (semantic, source, quality, tech)
4. GÃ©nÃ©ration rÃ©sumÃ© LLM + export JSON/Markdown

---

### Pourquoi ?

âš ï¸ **[Ã€ COMPLÃ‰TER MANUELLEMENT]** - Claude ne peut pas deviner votre motivation personnelle.

**Suggestions basÃ©es sur le projet :**

Avez-vous crÃ©Ã© ce projet pour :
- âœ… RÃ©soudre votre propre problÃ¨me de surcharge informationnelle ?
- âœ… Automatiser votre veille hebdomadaire personnelle ?
- âœ… Apprendre les embeddings sÃ©mantiques et LLM en pratique ?
- âœ… CrÃ©er un outil open source utile Ã  la communautÃ© Data Engineering ?
- âœ… DÃ©montrer vos compÃ©tences en ML Engineering + Data Engineering ?
- âœ… ExpÃ©rimenter avec GitHub Actions + dÃ©ploiement automatique ?

**Votre motivation personnelle :**

[Ã‰crire ici votre raison personnelle de crÃ©er ce projet]

---

## 2. LE PROBLÃˆME - WHAT

**ProblÃ¨me principal (reconstituÃ©) :**

Les **Data Engineers** font face Ã  une **surcharge informationnelle** critique :

**Constats :**
- ğŸ“š 60+ blogs techniques Ã  suivre (Databricks, dbt, Airbyte, Medium Data, etc.)
- ğŸ“§ Dizaines de newsletters hebdomadaires (Data Engineering Weekly, Seattle Data Guy, etc.)
- â±ï¸ 5-10h/semaine pour parcourir tout le contenu
- ğŸ¯ DifficultÃ© Ã  identifier les articles pertinents vs bruit
- ğŸ—‘ï¸ Beaucoup de contenu "pour dÃ©butants" ou promotionnel
- ğŸ“– Manque de distinction entre tutoriels techniques et retours d'expÃ©rience production

**ConsÃ©quences :**
- ğŸ˜« Frustration : manque de temps pour tout lire
- ğŸ“‰ Perte d'opportunitÃ©s : articles importants manquÃ©s
- ğŸ”„ Redondance : mÃªme info sur plusieurs sources
- ğŸš« Fatigue dÃ©cisionnelle : "Lequel lire en premier ?"
- ğŸ’¸ Impact business : dÃ©cisions techniques basÃ©es sur infos obsolÃ¨tes

**Pour qui ? (reconstituÃ©)**

**Persona 1 : Sarah - Data Engineer Mid-Level**
- 3-5 ans d'expÃ©rience
- Stack : dbt, Airflow, Snowflake, Python
- Besoin : articles intermÃ©diaires/avancÃ©s uniquement
- Pain point : trop d'articles dÃ©butants, contenu marketing

**Persona 2 : Marc - Tech Lead Data Platform**
- 7+ ans d'expÃ©rience
- GÃ¨re Ã©quipe 5-10 personnes
- Besoin : REX production, benchmarks, architecture
- Pain point : manque de REX dÃ©taillÃ©s, biais vendor

**Persona 3 : Julie - ML Engineer**
- MLOps, Feature Stores
- Stack : Python, ML pipelines, Databricks
- Besoin : articles ML Engineering spÃ©cifiques
- Pain point : trop de pure Data Engineering (pas ML)

---

## 3. LA SOLUTION - HOW

**FonctionnalitÃ©s principales (implÃ©mentÃ©es) :**

### Pipeline Backend Intelligent

**1. Crawling Automatique (Lundi 06:00 UTC)**
- 60+ sources RSS/Atom configurÃ©es
- Auto-dÃ©couverte de feeds
- Respect robots.txt + rate limiting per-host
- Extraction contenu complet (readability)
- Filtrage Ã©ditorial (path regex : blogs/posts/articles)
- DÃ©duplication (hash URL + titre)

**2. Classification LLM (Groq)**
- 8 catÃ©gories : Warehouses, Orchestration, Governance, Lakes, Cloud, Python, AI, News
- Classification initiale par keywords
- Correction/amÃ©lioration via LLM (llama-3.1-8b-instant)
- Multi-catÃ©gories supportÃ©es

**3. Scoring Multi-CritÃ¨res (0-100)**
- **Semantic (55%)** : Embeddings (sentence-transformers) vs profil utilisateur
- **Source (20%)** : RÃ©putation source (VuTrinh 0.9, Data Engineering Weekly 1.0, etc.)
- **Quality (15%)** : Longueur + prÃ©sence code
- **Tech (10%)** : Mots-clÃ©s techniques

**4. Filtrage Anti-Bruit (Phase 1)**
- DÃ©tection contenu dÃ©butant (keywords : "introduction", "getting started", "101")
- Score marketing (0-100) : dÃ©tection contenu promotionnel
- Exclusion automatique : beginner OR marketing_score >= 50
- Tech level : beginner/intermediate/advanced

**5. Content Type Detection**
- **Technical** : Tutoriels, guides, documentation
- **REX** : Retours d'expÃ©rience, All Hands, post-mortems, case studies
- Sources communautaires authentiques â†’ toujours REX

**6. SÃ©lection Intelligente**
- Filtrage par seuil (per-category : news 60, default 45)
- Diversity filter : max 2 articles par source/catÃ©gorie
- Top 3 global : max 1 article par source

**7. RÃ©sumÃ© LLM Hebdomadaire**
- AperÃ§u gÃ©nÃ©ral (2 phrases max)
- Sections par catÃ©gorie avec listes d'articles
- Format markdown structurÃ©

**8. Export Multi-Format**
- JSON : `digest.json` (consommÃ© par frontend)
- Markdown : `digest.md`, `ai_selection.md`, `top3.md`
- Index : `weeks.json`, `categories.json`, `search.json`
- Symlink : `latest` â†’ semaine courante

---

### Interface Frontend Moderne

**1. Navigation**
- SÃ©lecteur de semaines (dropdown)
- Historique complet (toutes les semaines passÃ©es)

**2. Visualisation**
- AperÃ§u gÃ©nÃ©ral (markdown LLM rendu)
- Top 3 hebdomadaire (grid 3 colonnes)
- Sections par catÃ©gorie (layout 2 colonnes)
- Cartes articles compactes (favicon + source + titre)

**3. Filtrage Multi-Couches**
- **Onglets type contenu** : Tous / Technique / REX & All Hands
- **Chips catÃ©gories** : Warehouses, Orchestration, Governance, etc.
- **Recherche floue** (Fuse.js) : titre + source

**4. Indicateurs QualitÃ©**
- Scores de pertinence (0-100)
- Badges niveau technique (ğŸŸ¢ Beginner, ğŸŸ¡ Intermediate, ğŸ”´ Advanced)

**5. UX**
- Design responsive (mobile + desktop)
- Tailwind CSS moderne
- Liens ouverts en nouvel onglet
- Hover effects, focus rings (accessibility)

---

### DiffÃ©renciateurs

**vs AgrÃ©gateurs RSS classiques (Feedly, Inoreader) :**
- âœ… Intelligence artificielle (LLM + embeddings)
- âœ… Filtrage anti-bruit automatique
- âœ… Distinction Technical vs REX
- âœ… Scoring pertinence sÃ©mantique
- âœ… Gratuit & open source

**vs Newsletters manuelles :**
- âœ… Automatisation complÃ¨te (zÃ©ro intervention humaine)
- âœ… Personnalisable (config YAML)
- âœ… DÃ©ploiement continu (GitHub Actions)
- âœ… Historique consultable

**vs Outils propriÃ©taires (Pocket, Instapaper) :**
- âœ… Pas de lock-in (SQLite local, JSON exports)
- âœ… Transparent (code open source)
- âœ… Extensible (plugins possibles)

---

## 4. OBJECTIFS

âš ï¸ **[PARTIELLEMENT Ã€ COMPLÃ‰TER]**

### Objectifs Techniques (dÃ©tectÃ©s)

**Architecture :**
- [x] Pipeline modulaire et asynchrone âœ…
- [x] Classification LLM performante âœ…
- [x] Scoring sÃ©mantique prÃ©cis âœ…
- [x] Filtrage anti-bruit efficace âœ…
- [x] Interface utilisateur moderne âœ…
- [x] DÃ©ploiement automatique âœ…

**QualitÃ© :**
- [x] Code bien structurÃ© et documentÃ© âœ…
- [ ] Tests > 80% coverage âš ï¸ (actuel : backend 37 tests, frontend 0%)
- [ ] Monitoring production (Sentry) âš ï¸
- [ ] Performance > 90 Lighthouse âš ï¸

**ScalabilitÃ© :**
- [x] Supporte 60+ sources âœ…
- [ ] Supporte 100+ sources (objectif futur)
- [x] GÃ¨re 500-1000 articles/semaine âœ…
- [ ] Cache Redis embeddings (objectif futur)

---

### Objectifs Business (Ã  complÃ©ter)

âš ï¸ **[ComplÃ©tez vos objectifs personnels]**

**Exemples Ã  considÃ©rer :**

**Impact Utilisateurs :**
- [ ] 50+ utilisateurs actifs/semaine
- [ ] Taux satisfaction > 80%
- [ ] 2-3h temps gagnÃ©/utilisateur/semaine

**Adoption :**
- [ ] 100+ stars GitHub (si open source public)
- [ ] 5+ partages/semaine (Twitter, Slack, LinkedIn)
- [ ] Contributions externes (PRs, issues)

**Revenus (si applicable) :**
- [ ] Version premium avec features avancÃ©es ?
- [ ] API payante pour tiers ?
- [ ] Sponsorships ?

**Votre objectif principal :**

[Ã‰crivez ici votre objectif business/personnel principal]

---

### CritÃ¨res de SuccÃ¨s (suggestions)

**MVP RÃ©ussi si :**
- [x] Pipeline s'exÃ©cute automatiquement chaque lundi âœ…
- [x] > 95% sources crawlÃ©es avec succÃ¨s âœ…
- [x] Classification LLM > 90% prÃ©cision âœ…
- [x] Frontend responsive et fonctionnel âœ…
- [x] ZÃ©ro erreurs bloquantes production âœ…

**v2.0 RÃ©ussie si MVP + :**
- [ ] Tests > 70% coverage
- [ ] Monitoring Sentry actif
- [ ] Cache Redis intÃ©grÃ©
- [ ] 100+ utilisateurs actifs
- [ ] Mode sombre + export PDF

---

## 5. Ã‰TAT ACTUEL

**Phase actuelle :** âœ… **Production (DÃ©ployÃ©)**

### Ce qui fonctionne âœ…

**Backend :**
- [x] Crawling automatique hebdomadaire (GitHub Actions)
- [x] 60+ sources RSS/Atom actives
- [x] Classification LLM (Groq) opÃ©rationnelle
- [x] Scoring multi-critÃ¨res fonctionnel
- [x] Anti-bruit filtering Phase 1 dÃ©ployÃ©
- [x] Content type detection (Technical vs REX)
- [x] Tech level classification (beginner/intermediate/advanced)
- [x] Export JSON/Markdown automatique

**Frontend :**
- [x] Interface React moderne en production (GitHub Pages)
- [x] Navigation par semaines
- [x] Recherche floue (Fuse.js)
- [x] Filtres catÃ©gories + type contenu
- [x] Responsive mobile + desktop
- [x] Top 3 hebdomadaire
- [x] Badges niveau technique

**Infrastructure :**
- [x] GitHub Actions backend (cron lundi 06:00 UTC)
- [x] GitHub Actions frontend (deploy automatique)
- [x] ZÃ©ro coÃ»t (Groq gratuit + GitHub free tier)

---

### Ce qui reste Ã  faire ğŸš§

**Court terme (1-2 mois) :**
- [ ] Tests frontend (Vitest + Playwright) - 13 SP
- [ ] CI/CD tests automatiques - 5 SP
- [ ] Monitoring Sentry - 8 SP
- [ ] Mobile UX fixes - 5 SP

**Moyen terme (3-4 mois) :**
- [ ] Cache Redis embeddings - 8 SP
- [ ] Mode sombre - 3 SP
- [ ] Export PDF - 5 SP
- [ ] Notifications Slack - 5 SP

**Long terme (6+ mois) :**
- [ ] API REST publique - 13 SP
- [ ] Dashboard analytics - 21 SP
- [ ] Personnalisation utilisateur - 13 SP
- [ ] Recommandations ML - 21 SP

---

### Score SantÃ© : 73/100

| CritÃ¨re | Score | Ã‰tat |
|---------|-------|------|
| Architecture | 18/20 | âœ… Excellent |
| Tests | 10/20 | âš ï¸ Backend OK, frontend 0% |
| Documentation | 18/20 | âœ… README + CLAUDE.md complets |
| SÃ©curitÃ© | 14/20 | âœ… Bonnes pratiques, monitoring manquant |
| Performance | 13/20 | âœ… Asyncio bien utilisÃ©, cache manquant |

**Verdict :** Bon - Quelques amÃ©liorations nÃ©cessaires

---

## 6. ROADMAP

### v1.1 - Stabilisation (1-2 mois)

**Focus : QualitÃ© & Robustesse**

- Tests frontend (Vitest + Playwright)
- CI/CD tests automatiques
- Monitoring Sentry
- Mobile UX fixes
- Dependabot (CVE scanning)

**SP Total : 31** (~1.5 sprint)

---

### v1.5 - Performance (3-4 mois)

**Focus : Optimisation & Features**

- Cache Redis embeddings
- Mode sombre
- Export PDF
- Notifications Slack/Email
- Staging environment

**SP Total : 26** (~1 sprint)

---

### v2.0 - Ã‰volution (6+ mois)

**Focus : Scale & AvancÃ©**

- API REST publique
- Dashboard analytics (tendances)
- Personnalisation utilisateur
- Recommandations ML
- Application mobile (React Native)

**SP Total : 108** (~5 sprints)

---

## 7. RESSOURCES

### Temps disponible

âš ï¸ **[Ã€ complÃ©ter]**

Combien de temps pouvez-vous allouer par semaine ?
- [ ] 100% (projet principal, full-time)
- [ ] 50% (2-3 jours/semaine)
- [ ] 20% (1 jour/semaine ou soirs/weekends)
- [ ] Maintenance seulement (quelques heures/mois)

**Votre rÃ©ponse :** [...]

---

### Budget

âš ï¸ **[Ã€ complÃ©ter]**

**CoÃ»ts actuels :**
- Groq API : $0/mois (free tier)
- GitHub Actions : $0/mois (free tier, 2000 min/mois)
- GitHub Pages : $0/mois (free)

**Total : $0/mois** (100% gratuit)

**Budget futur si scaling :**
- Redis Cloud : $0-30/mois
- Sentry : $0-26/mois (free tier: 5k events/mois)
- Groq paid : $0.27/M tokens (si dÃ©passement free tier)
- Domaine custom : $12/an (optionnel)

**Votre budget max acceptable :** [...]

---

### Ã‰quipe

âš ï¸ **[Ã€ complÃ©ter]**

**Actuel :**
- [x] Solo developer : Nathan Sornet

**Futur souhaitÃ© :**
- [ ] Contributeurs open source ?
- [ ] Co-maintainers ?
- [ ] Designer UX ?
- [ ] Data Scientist (amÃ©liorer scoring) ?

**Votre plan Ã©quipe :** [...]

---

## 8. MÃ‰TRIQUES CLÃ‰S Ã€ SUIVRE

### Techniques (Backend)

- âš™ï¸ Feeds rÃ©ussis : > 95% (55+/60)
- âš™ï¸ Articles crawlÃ©s : 500-1000/semaine
- âš™ï¸ Articles sÃ©lectionnÃ©s : 50-100/semaine
- âš™ï¸ Erreurs crawl : < 5%
- âš™ï¸ Coverage tests : > 80%

### Produit (Frontend)

- ğŸ“Š Lighthouse Performance : > 90
- ğŸ“Š Utilisateurs uniques/semaine : 50+
- ğŸ“Š Articles lus/session : 5+
- ğŸ“Š Taux retour : > 50%
- ğŸ“Š Taux satisfaction : > 80%

### Business

- ğŸ’° CoÃ»t : $0/mois (maintenir gratuit)
- â±ï¸ Temps Ã©conomisÃ©/user : 2-3h/semaine
- â­ Stars GitHub : 100+ (si public)
- ğŸ”„ Contributeurs : 5+ (si open source)

---

## 9. RISQUES & MITIGATION

### Risques Techniques

**1. Groq API discontinuÃ©e ou devient payante**
- ProbabilitÃ© : Moyenne
- Impact : Critique
- Mitigation : Abstraction OpenAI-compatible (Groq, OpenAI, Ollama, etc.)

**2. Sources RSS disparaissent ou changent format**
- ProbabilitÃ© : Haute
- Impact : Moyen
- Mitigation : Monitoring sources + fallback auto-dÃ©couverte

**3. GitHub Actions rate limits dÃ©passÃ©s**
- ProbabilitÃ© : Faible
- Impact : Moyen
- Mitigation : Optimiser pipeline (< 30 min), monitorer usage

---

### Risques Produit

**1. Faible adoption utilisateurs**
- ProbabilitÃ© : Moyenne
- Impact : Moyen
- Mitigation : Marketing (Twitter, LinkedIn, Reddit r/dataengineering)

**2. QualitÃ© sÃ©lection insatisfaisante**
- ProbabilitÃ© : Faible
- Impact : Ã‰levÃ©
- Mitigation : Feedback utilisateurs, ajuster thresholds, amÃ©liorer scoring

---

## 10. PROCHAINES Ã‰TAPES IMMÃ‰DIATES

**Cette semaine :**
1. âœ… GÃ©nÃ©rer documentation complÃ¨te (IDEA.md, PRD.md, ARCHI.md, BACKLOG.md)
2. [ ] ComplÃ©ter sections manuelles de IDEA.md (motivation, objectifs, ressources)
3. [ ] Prioriser backlog (P0, P1, P2)

**Sprint 1 (2 semaines) :**
1. [ ] Setup Vitest + premiers tests frontend
2. [ ] IntÃ©grer Sentry (backend + frontend)
3. [ ] CrÃ©er issue GitHub pour tests manquants

**Sprint 2 (2 semaines) :**
1. [ ] Tests E2E Playwright (search + filter flows)
2. [ ] CI/CD tests automatiques
3. [ ] Mobile UX audit + fixes

---

â­ **Si ce projet vous est utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile sur GitHub !**

---

*Document crÃ©Ã© le : 2025-12-20*
*DerniÃ¨re mise Ã  jour : [Ã€ complÃ©ter aprÃ¨s modifications manuelles]*
