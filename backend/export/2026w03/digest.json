{
  "ai_data_engineering": [
    {
      "url": "https://www.etsy.com/codeascraft/how-etsy-uses-llms-to-improve-search-relevance?utm_source=OpenGraph&utm_medium=PageTools&utm_campaign=Share",
      "title": "How Etsy Uses LLMs to Improve Search Relevance",
      "summary": "Ever searched for something specific, only to be met with results that are close, but not quite ? On Etsy‚Äôs Search Relevance team, that frustration is exactly what we are tackling. Our goal is simple yet ambitious: to help buyers find exactly what they‚Äôre looking for, and to help sellers reach the people seeking their special products. Search plays a central role in that mission. Historically, Etsy‚Äôs search models have relied heavily on engagement signals ‚Äì such as clicks, add-to-carts, and purchases ‚Äì as proxies for relevance. These signals are objective, but they can also be biased: popular listings get more clicks, even when they‚Äôre not the best match for a specific query. To address this, we introduce semantic relevance as a complementary perspective to engagement, capturing how well a listing aligns with a buyer‚Äôs intent as expressed in their query. We developed a Semantic Relevance Evaluation and Enhancement Framework , powered by large language models (LLMs). It provides a comprehensive approach to measure and improve relevance through three key components: High quality data : we first establish human-curated ‚Äúgolden‚Äù labels of relevance categories (we‚Äôll come back to this) for precise evaluation of the relevance prediction models, complemented by data from a human-aligned LLM that scales training across millions of query-listing pairs Semantic relevance models : we use a family of ML models with different trade-offs in accuracy, latency, and cost; tuned for both offline evaluation and real-time search Model-driven applications : we integrate relevance signals directly into Etsy‚Äôs search systems enabling both large-scale offline evaluation and real-time enhancement in production Together, this framework brings a more intent-aware search experience that better serves both buyers and sellers across our marketplace. Figure 1. Overview of the Semantic Relevance Evaluation and Enhancement Framework Capturing Shades of Relevance Let‚Äôs return to the idea of relevance categories . Based on user research, we define three categories for semantic relevance of query-listing pairs: Relevant : listing matches all parts of the query, accounting for meaning and proper nouns Partially relevant : listing matches part of the query or is thematically related but not a full match Irrelevant : listing has no meaningful connection to the query; its presence in top results would make the search feel broken Figure 2. Examples for the three relevance categories. Text highlighted in green shows how the product aligns with the search query, whereas red highlights indicate mismatches.* In an ideal world, we‚Äôd rely on human judgments for all query-listing pairs. But large-scale human annotation is time-consuming and expensive, rendering it infeasible. Instead, language models unlock the ability to generate these judgments at scale, transforming our ability to make every search on Etsy produce more relevant results. Data: Anchored by Humans, Scaled by LLMs With recent advances in LLMs, a promising approach to evaluate search relevance is to use LLM-as-a-judge : directly using LLMs to judge the relevance of our search system without looping in humans. However, this approach faces two main challenges: Domain shift : off-the-shelf LLMs may not capture the unique preferences and vocabulary of Etsy users Performance-cost tradeoff : larger LLMs offer stronger reasoning but are expensive for large-scale inference, while smaller LLMs are faster and cheaper, but less accurate To address these challenges, we start with human-curated golden labels to evaluate and align a powerful LLM with these human-labels, then use a full dataset scaled up by the LLM for training our relevance judge. In other words, humans define what good looks like, and LLMs help us scale it . LLMs do not replace human judgment, instead they align with and amplify it. We maintain a detailed, evolving relevance labeling guideline, continuously refined through user research and annotation feedback. What relevance means in our marketplace shifts over time and social context. For example, people searching for ‚Äúface masks‚Äù pre-2020 were primarily looking for masks for costumes or fashion, which is a completely different intent from protective masks post-2020. These guidelines ensure our definitions of relevance accurately reflect Etsy users‚Äô intent and capture cultural trends over time. Query-listing pairs are sampled from search logs using a mix of approaches, including both random, stratified sampling for broad coverage, and targeted sampling for challenging cases. Each query-listing pair is labeled by two Etsy admins, with an ongoing review process to both break ties and adjust labeling guidelines accordingly. For quality control, we continuously track metrics such as row-level disagreement rates, which measures how often multiple annotators disagree with each other for the same query-listing pair. To scale beyond manual annotation, we introduced a few-shot, chain-of-thought (CoT) prompting strategy using the o3 model , implemented in LangGraph. The prompt instruction is inspired by the annotation guidelines described above, and includes comprehensive query and listing features, like title, images, text description, attributes, variations, and extracted entities (read more about listing extracted entities in another one of our posts ). We also applied self-consistency sampling to improve reliability. This model, known as the LLM annotator (as seen in Figure 1), is first validated against the human-labeled golden data to ensure its judgement aligns with humans. Once validated, we use it to generate large-scale training data to develop the production models. The LLM annotator thus serves as the foundation for our teacher-student modeling pipeline, bridging the gap between expensive manual labeling and scalable automated annotation. Models: Balancing Accuracy, Latency and Cost Our modeling pipeline uses a three-tier cascaded distillation design , where each model balances accuracy and efficiency for a specific purpose. The stack includes: The LLM annotator : our most accurate and cost-intensive model, aligned closely with human-labeled golden data The teacher model : a fine-tuned smaller LLM (Qwen 3 VL 4B) that delivers high-throughput annotation at scale The student model : a lightweight, BERT-based two-tower model optimized for real-time inference The LLM annotator aligns best with the golden labels, but is too costly for recurrent, large-scale inference. To reduce cost while maintaining quality, we performed supervised fine-tuning (SFT) with a smaller LLM, Qwen 3 VL 4B, using the training data generated by the LLM annotator. This teacher model preserves human alignment while enabling us to label millions of query-listing pairs daily, which is ideal for recurring evaluation and monitoring. The teacher, however, is too slow to surface relevant search results quickly, which is critical for helping our sellers reach potential buyers. As such, we further distilled the teacher into a student model with a two-tower architecture. The distillation process aligns the student‚Äôs output with that of the teacher, so that the student judges relevance labels nearly as accurately as the teacher, while being lightweight and fast. The resulting model ensures we deliver search results almost as fast as before, with only <10ms additional latency. All three models ‚Äì the LLM annotator, teacher, and student ‚Äì are evaluated against the same golden dataset to ensure traceable performance and consistent alignment with human judgment. Figure 3 shows their accuracy measured using multi-class Macro F1 , and individual class F1 scores. Figure 3. Performance of semantic relevance models against human golden labels Applications: From Evaluation to Action With these models in place, we can both measure and enhance search relevance across Etsy. Search relevance evaluation We use the teacher model to measure how well our search system surfaces relevant listings. Each day, we sample search requests and perform offline inference using the teacher model, then aggregate the predicted relevance labels into summary metrics. These metrics are reviewed regularly by our team, and if we observe unexpected trends like a sudden decline of relevance, we work to quickly diagnose and address the problem. Similarly, we monitor relevance metrics in A/B tests. The computed relevance metrics are discussed when we decide whether to roll out a new change to our search system, to ensure those changes affect semantic relevance of search results in a neutral to positive way. We sample sufficient amounts of requests separately from control and treatment variants, to ensure statistical power. Using vLLM for high-throughput inference, we process millions of query-listing pairs daily at a very low cost, maintaining both statistical power and operational efficiency. Improving search in production The lightweight student model is embedded directly into Etsy‚Äôs real-time search stack. It improves relevance through several integration points: Filtering : removes retrieved listings predicted as irrelevant before downstream ranking Feature enrichment : contributes model-predicted relevance scores as features for the downstream ranking model Loss weighting : adjusts training weights of the ranking model based on predicted relevance Relevance boosting : promotes listings deemed highly relevant using heuristic rules among the final returned search results How Semantic Relevance is Changing Etsy Search The Semantic Relevance Evaluation and Enhancement Framework is fully deployed in Etsy‚Äôs search stack, and continues to evolve. We‚Äôve observed a measurable uplift in semantic relevance: the percentage of fully relevant listings (as defined by the relevance categories described earlier) has increased from 58% to 62% between August and October 2025. Figure 4. Improvement of semantic relevance metrics over time This improvement reflects Etsy‚Äôs growing ability to align search results with buyer intent. For instance, in searches like ‚Äúfall decor,‚Äù the enhanced search engine now focuses on surfacing seasonal decor items, while deprioritizing loosely related listings like clothing, which appeared before the enhancement on relevance. Figure 5. Before and after comparison when searching for ‚Äúfall decor‚Äù * Beyond these immediate gains, semantic relevance has shifted how we evaluate and improve search at Etsy, by adopting a user-centered approach. By grounding our evaluation in semantic intent in addition to behavioral signals, we move closer to our goal of connecting buyers with the relevant products, not just the most popular ones. While search results are influenced by multiple factors, and outcomes may vary, on the seller side, improving semantic relevance can also help surface items from small or new sellers who may not yet have the visibility of more established shops. What‚Äôs Next In ongoing and future efforts, we hope to explore the following directions: Better understanding of relevance-engagement dynamics. In online experiments, we often observe engagement metrics decline even as semantic relevance improves (a pattern also noted by other e-commerce platforms ). We suspect this results from applying uniform relevance treatments despite contextual variation. Next, we plan to explore adaptive strategies that tailor adjustments by query type. Refining partial relevance. Inspired by Amazon‚Äôs ESCI framework, we‚Äôre exploring finer-grained labels, for example, introducing new subcategories of complements and substitutes. This could potentially improve evaluation precision and power new user search experiences. Reducing annotation effort through LLM facilitation. When LLM judgments are self-consistent, they align better with human labels. This may indicate easier query-listing pairs. We are exploring using LLMs for these easy cases, focusing human effort on more complex cases. Simplifying the multi-stage model stack . Our current three-tier distillation pipeline provides flexibility but adds operational complexity. We plan to simplify this setup by exploring better performance-efficiency tradeoffs and potentially merging model tiers. Improving relevance in retrieval. So far, post-retrieval filtering is the first stage where our semantic relevance model applies. We see strong potential to enhance both inference and measurement further upstream in the retrieval layer. Conclusion Key takeaways: LLMs can meaningfully evaluate search relevance when grounded in human judgment. Aligning LLM assessments with human-labeled data ensures we measure, and continually improve, the search experience that is so essential to connecting buyers and sellers on Etsy. Semantic relevance redefines how Etsy optimizes search. By complementing engagement metrics with semantic relevance, we address real customer pain points and deliver more satisfying search experiences. Teacher-student distillation offers a flexible and efficient way to apply relevance modeling across diverse performance, latency and cost requirements. Ultimately, improving semantic relevance strengthens the human connections that define Etsy. By understanding what shoppers truly mean, we can help them find the right items. And by emphasizing relevant listings over popular ones, we can help create fairer opportunities on the search relevance factor of search visibility for our sellers ‚Äì 89% of whom are businesses of one. Acknowledgments This work is brought to you in a collaborative effort by the Search Relevance Team, enabled by ML Enablement, and the Merchandising teams. Thanks to the following contributors Data: Susan Liu, Jugal Gala, David Blincoe, Yuqing Zhang, Taylor Hunt, Liz Mikolaj Models: David Blincoe, Oriane Cavrois, Orson Adams, Yuqing Zhang Application: Grant Sherrick, Kaushik Bekal, Haoming Chen, Patrick Callier, Davis Kim, Marcus Daly Product leadership: Julia Zhou, Willy Huang, Argie Angeleas Engineering leadership: Yinlin Fu, Congzhe Su, Xiaoting Zhao ML Enablement partners: Ari Carter, Stan Schwertly, Shreya Agarwal, K Ogilvie, Marvin Wang, etc. Other cross-team partners: Will Beckman, Karl Yokono, Audrey Chen, Heather Campbell, David Le, Khadeeja Din, etc. Early contributors: Ethan Benjamin, Cung Tran, Maggie Matsui, Jack Gammack, Yogeeta Chatoredussy, Austin Clapp, Benjamin Russell, Khaled Jabr Special thanks to Oriane Cavrois & David Blincoe for helping this piece come to life. * Images are provided for illustrative purposes. Item availability on Etsy may vary.",
      "published_ts": 1768593748,
      "source_name": "Etsy Engineering",
      "content_type": "rex"
    },
    {
      "url": "https://www.databricks.com/blog/ai-business-strategies-success-todays-market",
      "title": "AI for Business: Strategies for Success in Today‚Äôs Market",
      "summary": "AI is reshaping how organizations build and operate, bringing automation and intelligence...",
      "published_ts": 1768593600,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://huggingface.co/blog/microsoft/optimind",
      "title": "Introducing OptiMind, a research model designed for optimization",
      "summary": "Introducing OptiMind, a research model designed for optimization\nMost optimization workflows start the same way: a written problem description. Notes, requirements, and constraints are captured in plain language long before any solver is involved. Translating that description into a formal mathemati",
      "published_ts": 1768502956,
      "source_name": "Hugging Face Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/school-of-product-2025-de-l'incubation-a-la-transformation-produit",
      "title": "School of Product 2025 - De l'incubation √† la transformation produit",
      "summary": "D√©couvrez comment l‚Äôincubateur de France Travail devient un levier pour diffuser la culture produit √† l‚Äô√©chelle. Entre start ups d‚Äô√âtat, r√©organisation en cha√Ænes de valeur et nouveaux modes de pilotage, l‚Äôarticle montre ce qui fonctionne, ce qui bloque et ce qui arrive ensuite.",
      "published_ts": 1768470490,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://huggingface.co/blog/open-responses",
      "title": "Open Responses: What you need to know",
      "summary": "Open Responses: What you need to know\nOpen Responses is a new and open inference standard. Initiated by OpenAI, built by the open source AI community, and backed by the Hugging Face ecosystem, Open Responses is based on the Responses API and is designed for the future of Agents. In this blog post, w",
      "published_ts": 1768435200,
      "source_name": "Hugging Face Blog",
      "content_type": "technical"
    },
    {
      "url": "https://engineering.fb.com/2026/01/14/ml-applications/adapting-the-facebook-reels-recsys-ai-model-based-on-user-feedback/",
      "title": "Adapting the Facebook Reels RecSys AI Model Based on User Feedback",
      "summary": "We‚Äôve improved personalized video recommendations on Facebook Reels by moving beyond metrics such as likes and watch time and directly leveraging user feedback.¬† Our new User True Interest Survey (UTIS) model, now helps surface more niche, high-quality content and boosts engagement, retention, and satisfaction. We‚Äôre doubling down on personalization, tackling challenges like sparse user data [...] Read More... The post Adapting the Facebook Reels RecSys AI Model Based on User Feedback appeared first on Engineering at Meta .",
      "published_ts": 1768423893,
      "source_name": "Meta Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.blog.langchain.com/choosing-the-right-multi-agent-architecture/",
      "title": "Choosing the Right Multi-Agent Architecture",
      "summary": "In this post, we‚Äôll explore when multi-agent architectures become necessary, the four main patterns we‚Äôve observed, and how LangChain empowers you to effectively build multi-agent systems.",
      "published_ts": 1768413974,
      "source_name": "LangChain Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/le-seuil-de-delegation",
      "title": "Le seuil de d√©l√©gation",
      "summary": "Avec Blackwell, NVIDIA passe de 8 √† 72 GPU par domaine. Ce n'est pas une am√©lioration de l'inf√©rence, c'est un nouveau mode: la d√©l√©gation. Vous assignez une t√¢che, elle tourne des heures. Les mod√®les open-weights locaux ne pourront jamais y acc√©der. La qualit√© est l'√©chelle. La d√©pendance est √† sens unique.",
      "published_ts": 1768390810,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/ai-catalog-discover-and-share-agents/",
      "title": "AI Catalog: Discover, create, and share agents and flows",
      "summary": "Welcome to Part 5 of our eight-part guide, Getting started with GitLab Duo Agent Platform , where you'll master building and deploying AI agents and workflows within your development lifecycle. Follow tutorials that take you from your first interaction to production-ready automation workflows with full customization. In this article: What is the AI Catalog? Browsing and enabling agents and flows Creating, sharing, and managing visibility Understanding versioning üéØ Try GitLab Duo Agent Platform today! Introduction to the AI Catalog The AI Catalog is a central repository for discovering, creating, and sharing agents and flows across your organization. It promotes consistency, reusability, and collaboration by enabling teams to leverage pre-built solutions and best practices. What you can do: Discover : Browse agents and flows created by GitLab and the community. Create : Create and maintain custom agents and flows in a single interface. Enable : Enable agents and flows at your top-level group level, then use them in your projects. Share : Publish your agents and flows for others to use (Public or Private). Duplicate : Copy and customize existing agents and flows. AI Catalog Accessing and working with the AI Catalog Navigate to Explore ‚Üí AI Catalog . The catalog currently provides two types: Agents ‚Äî Custom agents for on-demand, interactive, or context-specific tasks. Flows ‚Äî Custom flows for repeatable, multi-step automations, orchestrating a team of agents. For detailed information, see the AI Catalog documentation . Discover agents and flows The AI Catalog makes it easy to find agents and flows that fit your needs: How to browse: Navigate to Explore ‚Üí AI Catalog . Select either Agents or Flows tab. Browse the available agents or flows and inspect title, description and visibility status. Click on any agent or flow to view more details. Enabling agents and flows: Once you find an agent or flow you want to use: Click the agent or flow to view details. Click the Enable in group button to add the agent or flow to your top-level group. Enable it in your project to start using it. Creating, sharing, and managing visibility Create agents and flows Here are step-by-step instructions for creating agents and flows. Create agents: Navigate to Explore ‚Üí AI Catalog ‚Üí Agents ‚Üí New agent . Brainstorm and define a specific task or specialization for this agent, for example, a debugging and troubleshooting agent. Add a display name and description to allow others to identify the purpose and why they would want to use the agent, for example troubleshoot-debugger . Specify visibility and access. Select a private project and set visibility to private to start with experiments. Define the agent behavior, capabilities, and specialization in the system prompt. For details on crafting effective system prompts, see Part 3: Understanding agents . Optionally select and limit the tool access for agents. For example, a debugging agent needs read access to code, issues, and merge requests, but may not require write access to make changes. Create flows: Navigate to Explore ‚Üí AI Catalog ‚Üí Flows ‚Üí New flow . Brainstorm and define a complex multi-step specific task, for example, a CI/CD pipeline optimizer flow. Add a display name and description to allow others to identify the purpose and why they would want to use the flow, for example ci-cd-optimizer . Specify visibility and access. Select a private project and set visibility to private to start with experiments. Define the flow behavior and its agent components, prompts, and routers. For details on flow YAML structure, see Part 4: Understanding flows . For more details, see: Custom Agents documentation Custom Flows documentation Share your work and set visibility When creating agents or flows, you can choose between Private and Public visibility to control who can access and use them. Private: Can be viewed only by members of the managing project who have at least the Developer role, or by users with the Owner role for the top-level group. Cannot be enabled in other projects. Useful for team-specific or sensitive workflows. Public: Viewable by anyone on the instance. Can be enabled in any project that meets prerequisites. Appears in AI Catalog for discovery. Best practices for sharing When publishing agents and flows to the AI Catalog, follow these guidelines: Naming: Use clear, descriptive names (e.g., security-code-review , api-documentation-generator ). Avoid generic names like agent1 or my-flow . Include the purpose in the name when possible. Documentation: Provide a clear description of what the agent or flow does. Include use cases and examples. Document any prerequisites or dependencies. Quality: Test thoroughly before publishing. Ensure the agent or flow solves a real problem. Keep it maintainable and well-documented. Consider edge cases and error handling. Visibility decisions: Start with Private to test with your team. Move to Public once validated and documented. Only publish if it provides value to others. Consider the audience and use cases. Understanding versioning Custom agents and flows in the AI Catalog maintain a version history to track changes. How versioning works: GitLab automatically creates a new version when you update an agent's system prompt or modify a flow's configuration. Versions use semantic versioning (e.g., 1.0.0 , 1.1.0 ). GitLab manages semantic versioning automatically ‚Äî updates always increment the minor version. Versions are immutable, ensuring consistent behavior. Version pinning: When you enable an agent or flow: In a group : GitLab pins it to the latest version. In a project : GitLab pins it to the same version as your top-level group. This means: Your projects use a fixed, stable version of the agent or flow. Updates in the AI Catalog don't automatically affect your configuration. You must opt-in to update to new versions ‚Äî updates are never automatic. You maintain full control over when to adopt new versions. Viewing versions: Navigate to Automate ‚Üí Agents or Automate ‚Üí Flows . Select the agent or flow to view its version on the right side in the About section. Updating to the latest version When a new version of an agent or flow is available in the AI Catalog, you can update your projects to use it. Navigate to Automate ‚Üí Agents or Automate ‚Üí Flows . Click the agent or flow you want to update. Click the Update button (appears when a newer version is available). Review the changes in the new version. Confirm the update to pin your project to the latest version. What's next? You now understand how to discover, create, and share agents and flows through the AI Catalog. Next, in Part 6 , learn how to monitor agent and flow activity through sessions, set up event-driven triggers, and manage your AI workflows. Resources AI Catalog documentation Custom Agents documentation Custom Flows documentation Next: Part 6: Monitor, manage, and automate AI workflows Previous: Part 4: Understanding flows",
      "published_ts": 1768348800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/getting-started-with-gitlab-duo-agentic-chat/",
      "title": "Getting started with GitLab Duo Agentic Chat",
      "summary": "Welcome to Part 2 of our eight-part guide, Getting started with GitLab Duo Agent Platform , where you'll master building and deploying AI agents and workflows within your development lifecycle. Follow tutorials that take you from your first interaction to production-ready automation workflows with full customization. In this article: What is GitLab Duo Agentic Chat? Accessing GitLab Duo Agentic Chat Model selection Agent selection Common use cases Troubleshooting What is GitLab Duo Agentic Chat? GitLab Duo Agentic Chat is your primary interface for interacting with AI agents throughout your development workflow. Unlike simple Q&A chatbots that only answer questions, it's an autonomous AI collaboration partner that can take action on your behalf: Creating and modifying code, opening merge requests, triaging and updating issues/epics, and running workflows with full SDLC platform context. It does so while keeping you informed every step of the way. üéØ Try GitLab Duo Agent Platform today! Key capabilities: Code operations: Create files, edit code, and open merge requests. Project insights: Query issues, epics, merge requests, Git commits, CI/CD pipelines, analytics (GLQL), and security scans. Actionable tasks: Triage, update, or create issues and epics, remediate vulnerabilities, generate documentation and tests, fix failing CI/CD pipelines. Context awareness: Remember conversation history, understand project architecture, and search the codebase, wiki, and GitLab docs. Extensibility: Integrate with external services through Model Context Protocol (MCP). Multi-agent support: Use specialized agents for different tasks. üéØ Try it now: Interactive demo of GitLab Duo Agentic Chat ‚Äî Explore the chat interface and features. Accessing GitLab Duo Agentic Chat Environment How to Access Notes Web UI Click Duo icon in top-right corner Persistent panel, stays open as you navigate VS Code Primary Side Bar > GitLab Duo Agent Platform > Chat tab Integrated into your IDE workflow JetBrains Tool window > GitLab Duo Agent Platform > Chat tab Available in IntelliJ, PyCharm, etc. Visual Studio Extensions > GitLab > \"Open Agentic Chat\" Windows only, GitLab 18.3+ Web UI panel features Collapsed: Icon visible in top-right Panel open: Sidebar slides out (~400px width) Maximized: Expands for detailed responses GitLab project with the Duo chat panel opened Model selection Large language models ( LLMs ) excel at different tasks and knowledge requirements. Choose the right model for your needs when necessary. Model selection in GitLab Duo Chat Configuration levels Group-level: Set by Group Owner, applies to all users User-level: Individual control when group allows Agent selection Agents are specialized AI collaboration partners for specific tasks. Switch between them based on your needs: Agent Description Use For GitLab Duo General-purpose development collaboration (default agent) Getting started; questions on algorithms, architecture, and design patterns; debugging, refactoring, and explaining code Planner Product management and planning workflows Issue creation, epic planning, roadmap assistance, attention triage Security Analyst Vulnerability management and security workflows Security impact analysis, vulnerability triage, remediation Data Analyst Query, visualize, and surface data across GitLab Volume analysis, team performance, trend analysis, status monitoring, work item discovery, GLQL query generation Custom Agents Created by your team for specific needs Team-specific workflows, domain expertise Agent selection Agent selection in GitLab Duo Chat How to switch agents Open GitLab Duo Agentic Chat. IDE: Click the agent dropdown (below model selector). Web UI: Create a new chat. Select the agent you need. Model selection in IDE Model selection in UI Common use cases Issue management and triage For issue management and planning workflows, use the Planner Agent , a specialized agent designed for product management tasks. Example prompts: \"List all open issues labeled 'bug' and 'high-priority' created in the last 30 days.\" \"Create an issue for implementing user authentication with OAuth2, include acceptance criteria and technical requirements.\" \"Analyze Issue #456 and suggest related issues that might have the same root cause.\" \"Break down Epic #123 into smaller tasks with estimated complexity.\" Vulnerability analysis and remediation For security workflows, use the Security Analyst Agent , a specialized agent designed for vulnerability management and remediation. Example prompts: \"Show me all critical vulnerabilities in the latest pipeline scan.\" \"Triage all vulnerabilities from the latest security scan and identify which are false positives.\" \"Explain vulnerability #789 in simple terms and show me where it's located in the code.\" \"What's the recommended fix for the SQL injection vulnerability in the user search endpoint?\" \"Create an MR to fix the XSS vulnerability found in src/components/UserProfile.vue .\" Code understanding and documentation Get answers about your codebase without having to manually search through files with the GitLab Duo Agent. Example prompts: \"How does the authentication flow work in this application?\" \"Find all places where the sendEmail function is called.\" \"Explain what the calculateDiscount method does in src/pricing/calculator.ts .\" \"Generate documentation for the API endpoints in src/api/routes/ .\" \"What design patterns are used in the src/services/ directory?\" Onboarding to a new project Quickly get up to speed on a new project by understanding its architecture, setup, and dependencies using the GitLab Duo Agent . Example prompts: \"Give me an overview of this project's architecture and main components.\" \"Where is the database schema defined?\" \"How do I set up my local development environment?\" \"What are the main dependencies and what do they do?\" Debugging and pipeline troubleshooting Quickly identify and resolve issues in your code and CI/CD pipelines with AI-powered analysis using the GitLab Duo Agent . Example prompts: \"Why is the CI/CD pipeline failing on the test stage?\" \"Analyze the error logs from Job #12345 and suggest fixes.\" \"Why did Pipeline #9876 fail? Show me the error logs from the failed deployment job.\" \"The application crashes when processing large files. Help me debug this.\" \"Review the recent commits that might have caused the performance regression.\" \"How can I optimize the build time for this pipeline?\" \"Create a new CI/CD job to run security scans on every MR.\" Code review and quality improvement Get AI assistance during code reviews to catch issues and improve code quality using a Custom Agent trained on your team's coding standards and best practices. Example prompts: \"Review MR !234 for potential bugs and security issues.\" \"Suggest performance optimizations for the database queries in this MR.\" \"Check if MR !456 follows our coding standards and best practices.\" \"Identify any accessibility issues in the new UI components.\" Feature implementation Accelerate development by generating code, tests, and documentation using the GitLab Duo Agent . Example prompts: \"Create a REST API endpoint for user registration with validation.\" \"Generate unit tests for the OrderService class with 80% coverage.\" \"Implement pagination for the product listing page.\" \"Add error handling and logging to the file upload functionality.\" Refactoring and code improvement Modernize and improve existing code with AI guidance using GitLab Duo Agent . Example prompts: \"Refactor the UserController to follow SOLID principles.\" \"Convert this JavaScript file to TypeScript with proper type definitions.\" \"Suggest improvements to make this function more testable.\" \"Identify code duplication in the src/utils/ directory and suggest how to consolidate it.\" \"Modernize the project from Java 8 to 21. Follow the guidance in Epic 188.\" \"Create a migration plan for modernizing the COBOL mainframe code, and evaluate Java/Python.\" Troubleshooting Issue Possible Causes Solutions Chat not appearing ‚Ä¢ Duo not enabled ‚Ä¢ Insufficient permissions ‚Ä¢ Enable GitLab Duo for project ‚Ä¢ Verify Developer+ role Model selection unavailable ‚Ä¢ Group policy locked ‚Ä¢ Version too old ‚Ä¢ Check with group owner ‚Ä¢ Upgrade to GitLab 18.4+ More troubleshooting tips are available in the documentation . What's next? GitLab Duo Agentic Chat is supported in IDEs and the GitLab UI. Future releases will bring terminal support with GitLab Duo CLI, currently in development. Follow the product epic for more insights.\nNow that you've learned GitLab Duo Agentic Chat, explore the different types of agents and how to create custom ones in Part 3: Understanding agents . Explore foundational agents, create custom agents for your team, and integrate external agents like Claude Code and OpenAI Codex. Resources GitLab Duo Agentic Chat documentation GitLab Duo Agent Platform documentation Next: Part 3: Understanding agents Previous: Part 1: Introduction to GitLab Duo Agent Platform",
      "published_ts": 1768348800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/gitlab-duo-agent-platform-complete-getting-started-guide/",
      "title": "Get started with GitLab Duo Agent Platform: The complete guide",
      "summary": "GitLab Duo Agent Platform is a new AI-powered solution that embeds multiple intelligent assistants (\"agents\") throughout your software development lifecycle. It serves as an orchestration layer where developers collaborate asynchronously with AI agents across DevSecOps, transforming linear workflows into dynamic, parallel processes. Routine tasks, from code refactoring and security scans to research, can be delegated to specialized AI agents , freeing human developers to focus on solving complex problems and driving innovation. The platform leverages GitLab's role as a central DevSecOps platform (encompassing code management, CI/CD pipelines, issue tracking, test results, security scans, and more) to provide these agents with complete project context, enabling them to contribute meaningfully while adhering to your team's standards and practices. This comprehensive eight-part guide will take you from your first interaction to production-ready automation workflows with full customization. üí° Join GitLab Transcend on February 10 to learn how agentic AI transforms software delivery. Hear from customers and discover how to jumpstart your own modernization journey. Register now. Evolution from GitLab Duo Pro/Enterprise to Duo Agent Platform GitLab Duo Agent Platform is an evolution, not a replacement of Duo Pro and Enterprise. It's a superset that moves from 1:1 developer-AI interactions to many-to-many team-agent collaboration. Duo Pro enhanced individual developer productivity in the IDE with AI-powered code suggestions and chat. Duo Enterprise expanded beyond coding to deliver comprehensive AI capabilities across the entire software development lifecycle. But it was still primarily an approach in enabling 1:1 interaction between the user and an AI assistant ‚Äî mostly a Q&A experience with one use case at a time. Duo Agent Platform moves from 1:1 interactions to many-to-many team-agent collaboration, where specialized agents autonomously handle routine tasks across the software lifecycle. The complete series Part Title What You'll Learn 1 Introduction to GitLab Duo Agent Platform Platform architecture, four ways to use agents, accessing agents and flows, first interactions, sessions, and model selection 2 Getting started with GitLab Duo Agentic Chat Accessing chat across Web UI and IDEs, model selection and switching, agent selection, common use cases, and troubleshooting 3 Understanding agents: Foundational, custom, and external Foundational agents (GitLab Duo, Planner, Security Analyst, Data Analyst), creating custom agents with system prompts, external agents setup, AGENTS.md customization, and choosing the right agent type 4 Understanding flows: Multi-agent workflows Introduction to foundational flows, creating custom YAML workflows, flow execution, multi-agent orchestration, and monitoring 5 AI Catalog: Discover, create, and share agents and flows Browsing and discovering agents and flows, enabling agents and flows in projects, creating and publishing your own agents and flows, and managing visibility 6 Monitor, manage, and automate AI workflows Automate menu overview, monitoring sessions with detailed logs, setting up event-driven triggers, and managing AI workflows 7 Model Context Protocol integration MCP overview, GitLab as MCP client connecting to external tools, GitLab as MCP server for external AI tools, and configuration examples 8 Customizing GitLab Duo Agent Platform Custom chat rules, AGENTS.md configuration, system prompts for agents, agent tool configuration, MCP setup, and custom flow YAML configuration Key concepts reference Core components Component Description Key Features Duo Agentic Chat Primary interface for agent interaction ‚Ä¢ Available in Web UI and IDEs ‚Ä¢ Supports model selection ‚Ä¢ Maintains conversation history Agents Specialized AI collaboration partners for specific tasks ‚Ä¢ Foundational: Provided by GitLab (Planner, Security Analyst, etc.) ‚Ä¢ Custom: Created by your team ‚Ä¢ External: External AI providers like Claude and OpenAI Flows Multi-step workflows combining agents ‚Ä¢ Foundational: Provided by GitLab (Developer, Fix CI/CD Pipeline, etc.) ‚Ä¢ Custom: User-defined workflows you create AI Catalog Central repository for discovering, creating, and sharing ‚Ä¢ Browse and discover agents and flows ‚Ä¢ Add to your projects ‚Ä¢ Share across organization Automate Menu Management hub for AI workflows ‚Ä¢ Sessions: Flow activity logs ‚Ä¢ Flows: Multi-step workflows ‚Ä¢ Agents: Specialized AI assistants ‚Ä¢ Triggers: Event-based automation Model Context Protocol (MCP) External integration framework ‚Ä¢ Client: GitLab Duo connects to external MCP servers (Jira, Slack, AWS, etc.) ‚Ä¢ Server: GitLab acts as MCP server for external AI tools (Claude Desktop, Cursor, etc.) Essential terminology Term Definition Agent Specialized AI assistant for specific tasks and to answer complex questions Foundational Agent Pre-built agents created and maintained by GitLab (e.g., GitLab Duo, Planner, Security Analyst) ‚Äî available immediately with no setup Custom Agent Agents you create with custom system prompts and tools for team-specific workflows ‚Äî configured through project/group settings External Agent External AI providers like Claude, OpenAI, Google Gemini, and more integrated into the platform Flow Combination of one or more agents working together to solve a complex problem Foundational Flow Pre-built workflows by GitLab (Issue to MR, Fix Pipeline, Convert Jenkins, Software Development Flow) ‚Äî triggered via UI buttons or IDEs Custom Flow YAML-defined workflows you create for team-specific automation ‚Äî triggered by events or mentions Trigger Event that automatically starts a flow (e.g., mention, assignment) Session Record of agent or flow activity with complete logs and pipeline execution details System Prompt Instructions defining agent behavior, expertise, and communication style Service Account Account used by flows or external agents to perform GitLab operations with specific permissions MCP Model Context Protocol for external integrations (connects to Jira, Slack, AWS, etc.) AGENTS.md Industry-standard file for customizing agent behavior at user or workspace level Custom Rules Rules that customize how GitLab Duo behaves in your IDE Tools Capabilities that agents can use to interact with GitLab and external systems (e.g., create issues, merge requests, run pipelines, analyze code) Ready to get started? Begin your journey with Part 1: Introduction to GitLab Duo Agent Platform to learn the platform fundamentals. Feedback We'd love to hear from you! Found an error? Have a suggestion? Open an issue Contribute Discuss",
      "published_ts": 1768348800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/introduction-to-gitlab-duo-agent-platform/",
      "title": "Introduction to GitLab Duo Agent Platform",
      "summary": "Welcome to Part 1 of our eight-part guide, Getting started with GitLab Duo Agent Platform , where you'll master building and deploying AI agents and workflows within your development lifecycle. Follow tutorials that take you from your first interaction to production-ready automation workflows with full customization. GitLab Duo Agent Platform represents a fundamental shift in how developers interact with AI during the software development lifecycle. Moving beyond code into full SDLC context, GitLab Duo Agent Platform enables multiple specialized AI agents to work alongside your team, handling complex tasks asynchronously while you focus on innovation and problem-solving. GitLab Duo Agent Platform transforms traditional linear development workflows into dynamic, multi-agent collaboration systems. What is GitLab Duo Agent Platform? GitLab Duo Agent Platform is an AI orchestration layer that enables: Asynchronous collaboration between developers and specialized AI agents Full SDLC context across code, issues, epics, merge requests, CI/CD pipelines, wikis, analytics, and security scans Multi-agent flows where many agents collaborate in parallel on complex tasks Intelligent automation that understands your organization's standards, practices, and compliance requirements Think of it as adding AI team members who can take on entire workflows, from understanding requirements to creating merge requests, while you maintain full visibility and control. üéØ Try GitLab Duo Agent Platform today! Platform architecture GitLab Duo Agent Platform consists of several interconnected components working together to provide comprehensive AI assistance. The diagram below shows the user interaction methods with GitLab Duo Agent Platform. It illustrates the four ways users can engage with agents: GitLab Duo Agent Platform architecture diagram How teams interact with GitLab Duo Agent Platform Four ways to use agents GitLab Duo Agentic Chat ‚Äî Open the chat panel in the GitLab UI or your IDE for interactive conversations with foundational and custom agents. Select from available AI models and get real-time help. Trigger Custom Flows ‚Äî Mention flows in issue or merge request comments, or assign reviewers to automatically trigger Custom Flows. These run asynchronously via runner execution. Trigger Foundational Flows ‚Äî Built and maintained by GitLab, including Developer , Code Review , Fix CI/CD Pipeline , Convert Jenkins to GitLab CI/CD , and Software Development Flow . Trigger External Agents ‚Äî Assign or mention external AI agents (like Claude Code or OpenAI Codex) in issue or merge request comments to automatically trigger them. These run asynchronously via runner execution. Where to manage and discover AI Catalog ‚Äî Browse, create, and share agents and flows across your organization. Discover agents and flows created by GitLab and your team, then add them to your projects. You can also create and publish your own custom agents and flows for others to use. Automate Capabilities ‚Äî Your central hub for managing everything. View and manage your agents, configure and monitor flows, review all activity in sessions (including pipeline status), and set up triggers for event-based automation. Let's explore each component briefly (we'll dive deeper in subsequent posts): GitLab Duo Agentic Chat Your primary interface for interacting with agents. Available as a persistent panel in the GitLab UI and in your IDE. Learn more in Part 2: Getting Started with GitLab Duo Agentic Chat . GitLab Duo Agentic Chat panel in the web UI GitLab Duo Agentic Chat panel in VS Code Agents Agents are specialized AI-powered assistants designed to handle specific tasks throughout your development workflow. Think of them as team members with unique expertise and capabilities. Type Description Where Used Setup Required Foundational Maintained by GitLab for common development workflows (Security Analyst, Planner, GitLab Duo), available by default in the chat of any project GitLab Duo Chat No Custom Created by you for team-specific needs with custom prompts and tools GitLab Duo Chat Yes External External AI providers (Claude, OpenAI) triggered via mentions or assignments @mentions, assignments Optional About external agents External agents run in the background on GitLab platform compute when triggered by mentions (e.g., @ai-codex ) or assignments in issues and merge requests. Unlike foundational and custom agents that use synchronous feedback loops, external agents execute asynchronously, enabling powerful automation with specialized AI providers. What makes agents powerful Specialized prompts : Each agent has a unique system prompt that defines its expertise, behavior, and communication style. Access to tools : Agents can read files, access issues/MRs/epics, search code, analyze CI/CD job logs and vulnerability reports, and more based on their configuration. Project context: Access to issues, merge requests, code, CI/CD pipelines, and security vulnerabilities. Learn more in Part 3: Understanding agents . Discover how to create custom agents, integrate external AI providers, and configure agent prompts and tools for your team's specific needs. Flows Flows are multi-step workflows that combine multiple actions to solve complex problems. Unlike agents that respond to questions, flows execute complete workflows autonomously via runner execution. Type Description Where Triggered Setup Required Foundational Maintained by GitLab for common development workflows (Developer, Fix Pipeline, Convert Jenkins to GitLab CI/CD, Software Development) You invoke using dedicated UI action buttons, or using the IDE extension Flows tab No Custom User-defined workflows you create, tailored to your needs Mentions in issues/MRs, assignment Yes What makes flows powerful Multi-step execution : Combine multiple operations into a single workflow Asynchronous processing : Run in background while you continue working Full pipeline access : Execute via runner execution with complete project context Event-driven : Automatically triggered by GitLab events Learn more in Part 4: Understanding flows , including multi-agent workflows. Agents vs. flows: What's the difference? Understanding when to use an agent vs. a flow is key to working effectively with GitLab Duo Agent Platform. Aspect Agents (Interactive in Chat) Flows (Automated on Platform) Purpose Interactive work, quick iterations, conversational guidance Complex multi-step tasks, background automation, event-driven workflows Where GitLab Duo Chat (Web UI, IDEs) Issues, Merge Requests, UI action buttons How Real-time conversation with ability to take actions Triggered by events or button clicks Execution Interactive, runs immediately in chat context Asynchronous via runner execution Example \"Refactor this function\" (agent modifies code), \"Create tests\" (agent generates test file) \"Generate MR for issue #123\" (flow creates branch, commits, opens MR) Quick decision guide Working interactively or want instant feedback? ‚Üí Use chat Need background automation, MR review, or complex multi-file tasks? ‚Üí Use flow Key insight Both agents and flows can take actions and create code. The main difference is how they interact and run: Agents communicate interactively in your chat interface, while flows run asynchronously in the background on platform compute. AI Catalog A centralized library where you can browse, discover, create, and share agents and flows across your organization, detailed in Part 5: AI Catalog . AI Catalog Automate capabilities Your hub for managing agent and flow workflows: Agents : View and manage agents in your project, detailed in Part 3 . Flows : View, create, and manage flows in your project, detailed in Part 4 . Sessions : Agent activity logs Triggers : Event-based automation management for flows in your project Understanding sessions Every agent and flow execution creates a session that logs agentic activities. Sessions provide full transparency into what happened, including agent reasoning, execution details, tool calling, outputs, and the complete decision trail. Sessions overview showing execution status and progress To view sessions: Navigate to your project > Automate > Sessions . From there, you can access the pipeline console to see detailed execution logs. Model selection One of the powerful features of GitLab Duo Agent Platform is the ability to choose which AI model powers your conversation. Available in: GitLab 18.4 and later How to select: Open GitLab Duo Agentic Chat. Look for the model dropdown. Click to see available models. Select the model best suited for your task. Note: Model selection is currently available in the Web UI only. IDE integration uses the default model selected for your group. Your first agent interaction Let's walk through a simple first interaction with GitLab Duo Agentic Chat: Example 1: Understanding your project (Agent) Scenario: You've just joined a project and need to understand its structure and architecture. Steps: Open GitLab Duo Chat panel (click Duo icon in top-right). Ensure Agentic mode (Beta) is toggled on. Select the Duo Agent (default). Type: \"Give me an overview of this project's architecture.\" Press Enter . What happens: The agent: Analyzes your repository structure Reviews your README, code organization, and documentation Provides a comprehensive overview with key components You can ask follow-up questions for clarification. Chat showing Architecture Overview Example 2: Generating a merge request (Flow) Scenario: You have an issue that needs to be resolved with code changes. Steps: Open the issue in GitLab. Click Generate MR with Duo button. An agent session starts. Within a few minutes, an MR is created with: Code changes across multiple files A descriptive commit message An explanation of changes in MR description What happens: The Developer Flow: Analyzes the issue Understands repository structure, design patterns, and SDLC context Makes appropriate code changes Opens a ready-to-review MR Issue with \"Generate MR with Duo\" button Common questions Q: Are my conversations with agents private? A: Yes. Conversations follow GitLab's standard privacy and security models. Learn more. Q: Can I use GitLab Duo Agent Platform with self-hosted models? A: Yes, starting with GitLab 18.8, it requires additional setup. See GitLab documentation . What's next? Now that you understand the basics of GitLab Duo Agent Platform, you're ready to dive deeper into each component: Part 2: Getting started with GitLab Duo Agentic Chat ‚Äî Master the persistent chat panel, learn model selection strategies, understand agent switching, and use chat effectively across Web UI and all supported IDEs. Part 3: Understanding agents ‚Äî Explore foundational agents built by GitLab, create custom agents with specialized prompts for your team's workflows, and integrate external CLI agents from providers like Claude Code and OpenAI Codex. Part 4: Understanding flows ‚Äî Discover how flows orchestrate multiple agents to solve complex problems, create custom YAML-defined workflows, and leverage external AI providers for automated pipeline execution. Part 5: AI Catalog ‚Äî Browse the centralized repository to discover agents and flows created by GitLab and the community, add them to your projects, and publish your own solutions for others to use. Part 6: Monitor, manage, and automate AI workflows ‚Äî Monitor all agent and flow activity through sessions, set up event-driven triggers to automate workflows, and manage your entire GitLab Duo Agent Platform ecosystem from one central location. Part 7: Model Context Protocol integration ‚Äî Extend GitLab Duo's capabilities by connecting to external tools like Jira, Slack, and AWS through the open MCP standard, and enable external AI tools to access your GitLab data. Part 8: Customizing GitLab Duo Agent Platform - Configure custom chat rules, create system prompts for agents, set up agent tools, integrate external systems with MCP, and customize flows for your team's specific needs. Resources GitLab Duo Agent Platform documentation GitLab Duo Agent Platform site GitLab Community Forum Next: Part 2: Getting started with GitLab Duo Agentic Chat",
      "published_ts": 1768348800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/understanding-agents-foundational-custom-external/",
      "title": "Understanding agents: Foundational, custom, and external",
      "summary": "Welcome to Part 3 of our eight-part guide, Getting started with GitLab Duo Agent Platform , where you'll master building and deploying AI agents and workflows within your development lifecycle. Follow tutorials that take you from your first interaction to production-ready automation workflows with full customization. In this article: What are agents? Types of agents Common use cases How to create a custom agent Best practices üéØ Try GitLab Duo Agent Platform today! What are agents? Agents are specialized AI collaboration partners within GitLab Duo Agent Platform . Each agent type serves different purposes and runs in different contexts. Types of agents Type Interface Maintainer Use Case Foundational GitLab Duo Chat GitLab Common development tasks Custom GitLab Duo Chat You Team-specific workflows External Platform You, see configuration examples External AI integrations Foundational agents Built and maintained by GitLab, these agents are available immediately with no setup required.\nThe availability of foundational agents can be managed by namespace owners or instance administrators .\nStart the interaction with foundational agents by opening GitLab Duo Agentic Chat in the IDE or Web UI. GitLab Duo This is the default agent, your general-purpose development collaboration partner for creating and modifying code, opening merge requests, triaging and updating issues/epics, and running workflows with full SDLC platform context. Example prompts: \"Explain how the authentication system works.\" \"Where is the user profile logic located?\" \"How should I implement feature X?\" Planner Agent Helps with product planning, breaking down epics, and creating structured issues. Example prompts: \"Create an epic for the new payment system with subtasks.\" \"Break down issue #789 into smaller tasks.\" \"Generate acceptance criteria for this feature.\" Learn more about Planner Agent. Security Analyst Agent Triages vulnerabilities, identifies false positives, and prioritizes security risks. Example prompts: \"Triage all vulnerabilities from the latest scan.\" \"Which SAST findings are false positives?\" \"Prioritize security issues by actual risk\" Learn more about Security Analyst Agent. Data Analyst Agent Queries, visualizes, and surfaces data across the GitLab platform using GitLab Query Language (GLQL) to provide actionable insights about your projects and teams. Example prompts: \"How many merge requests were created in the last quarter?\" \"Show me what each team member has worked on this month.\" \"What are the trends in issue resolution times?\" \"Find all open issues with the 'bug' label in my project.\" \"Generate a GLQL query to count merge requests by author.\" Learn more about Data Analyst Agent. Custom agents Create your own agents tailored to your team's specific workflows and standards. Common use cases Troubleshooting and Debugging Agent : Debug software bugs and regressions, and analyze deployment failures. Documentation Agent : Maintain docs following your conventions. Onboarding Assistant : Help new team members with company-specific practices. Compliance Monitor : Ensure regulatory requirements are met. Localized Support Agent : Triage support issues in a localized language, for example, German. Watch the GitLab DACH Roadshow Vienna 2025 Duo Agent Platform use cases talk recording: üéØ Try it now: Interactive demo of Custom Agents ‚Äî Explore how to create and configure custom agents. How to create a custom agent Custom agents are configured through your project or group settings. The key component is the system prompt , which defines your agent's behavior and expertise. System Prompt Example from the custom agent devops-debug-failures-agent : Your speciality is that you can correlate static SDLC data with runtime data from CI/CD pipelines, logs, and other tool calls necessary.\nExpect that the user has advanced knowledge, but always provide commands and steps to reproduce your analysis so they can learn from you.\nStart with a short summary and suggested actions, and then go into detail with thoughts, analysis, suggestions.\nThink creative and consider unknown unknowns in your debug journey. Visibility options: Private : Only viewable by members of the managing project (Developer role+). Cannot be enabled in other projects. Public : Can be viewed by anyone and enabled in any project that meets the prerequisites. Appears in the AI Catalog for discovery. Custom agent configuration interface Full setup guide available in the documentation. Best practices System prompt tips: Be specific about the agent's role and responsibilities. Define clear quality standards and constraints. Include examples of expected output. Keep prompts focused on one primary task. Start small: Begin with read-only permissions. Test thoroughly before granting write access. Gather team feedback and iterate. External agents External agents run in the background on the GitLab platform when triggered by mentions (e.g., @ai-codex ) or assignments in issues and merge requests. Unlike foundational and custom agents that work interactively in chat, external agents execute asynchronously, enabling powerful automation with specialized AI providers. Credential management: Starting with GitLab Duo Agent Platform general availability, GitLab-managed credentials will be used to support external agents, preventing the need for customers to manage and rotate API keys themselves. When to use external agents You need specific agentic AI behavior or LLMs for specialized tasks. You want event-triggered automation (not interactive chat). You need to meet specific compliance or data residency requirements. Why use external agents? Leverage specialized AI models: Access provider-specific capabilities like Claude Code's code analysis or OpenAI Codex's task delegation. Meet compliance requirements: Keep data within approved AI providers for regulatory or security policies. Experiment with providers: Test different agentic AI and LLM behavior to find the best fit for your workflows. Access unique features: Use provider-specific tools like Claude Code's code analysis or OpenAI Codex's task delegation. Real-world example A development team uses OpenAI Codex as an external agent for code review. When developers create merge requests, they assign Codex as a reviewer. The agent: Analyzes the code changes in the MR. Checks for best practices and code quality issues. Suggests improvements and optimizations. Posts detailed review comments with specific recommendations. Links to relevant documentation. All of this happens automatically in the background while the developer continues working, with results posted directly in the merge request. Supported external agents The following integrations have been tested and are available: Anthropic Claude ‚Äî Code generation, review, and analysis OpenAI Codex ‚Äî GPT-powered code assistance Example usage: @ai-codex Please implement this issue This triggers a runner execution job that runs the external AI tool and posts results back to GitLab. Setting up external agents For complete setup instructions including service accounts, triggers, and configuration examples, see the External Agents documentation . Customizing agent behavior with AGENTS.md Customize how agents using AGENTS.md files following the agents.md standard. Learn more in Part 8: Customizing GitLab Duo Agent Platform: Chat rules, prompts, and workflows . Choosing the best agent type for your use cases Feature Foundational Agents Custom Agents External Agents Setup Zero setup, maintained by GitLab Requires system prompt configuration Requires flow config Availability Available immediately in Chat Available in Chat after enabled in project Runs on platform compute Customization Limited (custom instructions) Behavior customizable via system prompt Customize prompt Interaction Agentic chat Agentic chat Event-triggered, asynchronous Best For General development tasks Team-specific workflows External AI integrations Summary GitLab Duo Agent Platform offers these agent types: Foundational: Ready-to-use agents for common tasks (Chat, Planner, Security Analyst, Data Analyst) Custom: Create team-specific agents with custom prompts and behaviors External: Integrate external AI tools Start with foundational agents, create custom agents for team-specific needs, and explore external agents when you need specialized AI providers. Next: Part 4: Understanding flows Previous: Part 2: GitLab Duo Agentic Chat",
      "published_ts": 1768348800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.blog.langchain.com/langsmith-agent-builder-generally-available/",
      "title": "Now GA: LangSmith Agent Builder",
      "summary": "LangSmith Agent Builder is now generally available‚Äîenabling anyone to build agents for complex daily tasks, without writing code.",
      "published_ts": 1768320038,
      "source_name": "LangChain Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.uber.com/blog/from-static-rate-limiting-to-intelligent-load-management/",
      "title": "How Uber Conquered Database Overload: The Journey from Static Rate-Limiting to Intelligent Load Management",
      "summary": "üß† Overload in stateful databases isn‚Äôt one-dimensional. See how we built an intelligent load manager that sheds smarter, adapts to diverse signals, and stays fair under pressure. Even better, this approach led to a ~70% reduction in P99 latency.",
      "published_ts": 1768314600,
      "source_name": "Uber Engineering Blog",
      "content_type": "rex"
    },
    {
      "url": "https://blog.octo.com/digital-omnibus--l'europe-est-elle-en-train-de-detricoter-sa-propre-souverainete-numerique",
      "title": "Digital Omnibus : l‚ÄôEurope est-elle en train de d√©tricoter sa propre souverainet√© num√©rique ?",
      "summary": "Au moment o√π l‚ÄôIA rebattait les cartes du pouvoir num√©rique, l‚ÄôEurope pensait avoir trouv√© sa singularit√© : un mod√®le fond√© sur la confiance et la protection des citoyens.",
      "published_ts": 1768302877,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    }
  ],
  "cloud_infra_observability": [
    {
      "url": "https://aws.amazon.com/blogs/aws/amazon-ec2-x8i-instances-powered-by-custom-intel-xeon-6-processors-are-generally-available-for-memory-intensive-workloads/",
      "title": "Amazon EC2 X8i instances powered by custom Intel Xeon 6 processors are generally available for memory-intensive workloads",
      "summary": "AWS is announcing the general availability of Amazon EC2 X8i instances, next-generation memory optimized instances powered by custom Intel Xeon 6 processors available only on AWS. X8i instances are SAP-certified and deliver the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud.",
      "published_ts": 1768517537,
      "source_name": "AWS Blog",
      "content_type": "technical"
    },
    {
      "url": "https://github.blog/engineering/infrastructure/when-protections-outlive-their-purpose-a-lesson-on-managing-defense-systems-at-scale/",
      "title": "When protections outlive their purpose: A lesson on managing defense systems at scale",
      "summary": "User feedback led us to clean up outdated mitigations. See why observability and lifecycle management are critical for defense systems. The post When protections outlive their purpose: A lesson on managing defense systems at scale appeared first on The GitHub Blog .",
      "published_ts": 1768510472,
      "source_name": "GitHub Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/how-slack-achieved-operational-excellence-for-spark-on-amazon-emr-using-generative-ai/",
      "title": "How Slack achieved operational excellence for Spark on Amazon EMR using generative AI",
      "summary": "In this post, we show how Slack built a monitoring framework for Apache Spark on Amazon EMR that captures over 40 metrics, processes them through Kafka and Apache Iceberg, and uses Amazon Bedrock to deliver AI-powered tuning recommendations‚Äîachieving 30‚Äì50% cost reductions and 40‚Äì60% faster job completion times.",
      "published_ts": 1768424541,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://www.rudderstack.com/blog/multi-agent-ai-analytics-spec",
      "title": "How we track multi-agent AI systems without losing visibility into agent orchestration",
      "summary": "Instrument multi-agent AI systems with standardized events for agent sessions, steps, cost, and latency to optimize orchestration, control spend, and prove ROI.",
      "published_ts": 1768322381,
      "source_name": "Rudderstack Blog",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-lambda-for-net-10-aws-client-vpn-quickstart-best-of-aws-reinvent-and-more-january-12-2026/",
      "title": "AWS Weekly Roundup: AWS Lambda for .NET 10, AWS Client VPN quickstart, Best of AWS re:Invent, and more (January 12, 2026)",
      "summary": "At the beginning of January, I tend to set my top resolutions for the year, a way to focus on what I want to achieve. If AI and cloud computing are on your resolution list, consider creating an AWS Free Tier account to receive up to $200 in credits and have 6 months of risk-free [‚Ä¶]",
      "published_ts": 1768239587,
      "source_name": "AWS Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/healthcare-pharma-contact-center-modernization",
      "title": "Modernize Healthcare & Pharma Contact Centers",
      "summary": "How healthcare and life sciences organizations can modernize contact centers to cut costs and deliver personalized patient experiences on trusted data",
      "published_ts": 1768237200,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    }
  ],
  "data_modeling_governance": [
    {
      "url": "https://stripe.com/blog/three-agentic-commerce-trends-nrf-2026",
      "title": "The three biggest agentic commerce trends from NRF 2026",
      "summary": "Not only are the majority of retailers actively implementing, or have plans to implement, agentic commerce, but many are also moving to a more tactical phase of optimizing their setup‚Äîrefining their product catalog strategy to launch faster and investing in their own agentic shopping experiences in addition to integrating with third-party agents.",
      "published_ts": 1768521600,
      "source_name": "Stripe Engineering Blog",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/gitlab-duo-agent-platform-is-generally-available/",
      "title": "Announcing general availability for GitLab Duo Agent Platform",
      "summary": "We‚Äôre excited to announce the general availability of GitLab Duo Agent Platform. This is an important moment for GitLab, our customers and the industry at large. It is our first step in delivering our vision to bring agentic AI into the entire software development lifecycle. AI tools have been rapidly improving developers‚Äô ability to write code, and in some cases, developers are reporting 10x productivity gains. Unfortunately, since only about 20% of a developer‚Äôs time is spent writing code, the associated improvement in total innovation velocity and delivery gained by AI is incremental. This is often described as the AI paradox in software delivery. In addition, for many teams, increasing the speed of code authoring has led to new bottlenecks including a larger backlog of code reviews, security vulnerabilities, compliance checks and downstream bug fixes. GitLab Duo Agent Platform addresses the AI paradox by unlocking intelligent orchestration and agentic AI automation across the software lifecycle. Learn more in this video, and read more below. üí° Join GitLab Transcend on February 10 to learn how agentic AI transforms software delivery. Hear from customers and discover how to jumpstart your own modernization journey. Register now . We're also excited to announce that GitLab customers with active GitLab Premium and Ultimate subscriptions are being credited with $12 and $24 dollars, respectively, in GitLab Credits per user at no additional cost.* These credits will refresh every month and give users access to all GitLab Duo Agent Platform features. Here is a simple explanation for how GitLab Credits work: a GitLab Credit is a virtual currency used for GitLab‚Äôs usage-based products. GitLab Duo Agent Platform usage will draw down on available credits, starting with the included credits mentioned above. From there, customers can decide to commit to a shared pool of credits for their entire organization, or pay for them monthly, on demand. For more information, please check out our article introducing GitLab Credits . Customers of GitLab Duo Pro or Duo Enterprise subscriptions are welcome to continue using those products, or migrate to Duo Agent Platform at any time. The remainder of your Duo Enterprise contract value can be converted into GitLab Credits at any time. Contact your GitLab representative to learn more. Here are exciting use cases and capabilities you can try today: A unified experience for human and agent collaboration GitLab Duo Agent Platform introduces a unified user experience designed for seamless integration between humans and their AI agents inside GitLab. Developers and their teams can engage Duo Agentic Chat on nearly every page, ask questions contextually, follow async agentic sessions and interact with agents within familiar workflows like issues, merge requests, and pipeline activities ‚Äî making AI actions transparent and easy to guide through everyday work. Agentic Chat: Intelligent, context-aware assistance Gitlab Duo Agentic Chat brings true multi-step reasoning across the GitLab Web UI and IDEs, using full lifecycle context from issues, merge requests, pipelines, security findings, and more. Building on the previously released Duo Chat, Agentic Chat can perform actions on your behalf autonomously and help you answer complex questions more comprehensively. It gives every member of the software team accurate, context-aware guidance that helps improve onboarding, code quality, and delivery speed. GitLab Duo Agentic Chat supports numerous use cases to enable developer <> AI collaboration. For additional details on how to get started, please see our \"Getting started with GitLab Duo Agent Platform\" guide and check out this growing set of suggested prompts . Analyze In the Web UI, Agentic Chat can create issues, epics, merge requests, and provide summaries, highlight key findings, and offer actionable guidance based on real-time context from the specific project, issue, epic, merge request, and more. Agentic Chat helps developers understand unfamiliar code, dependencies, architecture, and project structure, in the IDE or inside a GitLab repo. Code Agentic Chat can generate code, configurations, and infrastructure-as-code across a wide range of languages and frameworks. It can help fix bugs, modernize architecture and code, generate tests, and produce documentation for faster onboarding. Directly at developers' fingertips, Agentic Chat is their collaboration partner in VS Code, JetBrains IDEs, Cursor, and Windsurf, with optional user- and workspace-level rules to tailor responses. CI/CD Agentic Chat can help you better understand, configure, and troubleshoot existing pipelines, or create new ones from scratch. Secure Agentic Chat can explain vulnerabilities, prioritize issues based on reachability, and recommend fixes that can help save you time. Agents: Specialists that collaborate on demand GitLab Duo Agent Platform enables developers to delegate tasks to specialized agents. The platform offers a unique combination of foundational, custom, and external agents, all seamlessly integrated into GitLab user experience, making it easy to choose the right agent for any task. Foundational agents are pre-built by GitLab experts and are ready out-of-the-box to handle the most complex tasks in the software delivery cycle. The following foundational agents are included as part of GitLab Duo Agent Platform‚Äôs general availability, with others currently in beta and coming soon. Planner Agent helps teams structure, prioritize, and break down work directly inside GitLab so planning becomes clearer, faster, and easier to act on. Security Analyst Agent reviews vulnerabilities and security signals, explains their impact in plain language, and helps teams understand what to address first. Custom agents can be built using the AI Catalog, a central repository where teams create, publish, manage, and share custom agents and flows across the organization. Teams can create agents and flows with specific context and capabilities to replicate the way their engineering team works ‚Äî and tackle problems using the engineering standards and guardrails their engineers use. External agents are seamlessly integrated into GitLab and include some of the very best AI tools available, including Claude Code from Anthropic and Codex CLI from OpenAI. Users will enjoy native GitLab access to these tools for use cases like code generation, code review, and analysis with transparent security and embedded LLM subscriptions. Together, these approaches give teams flexibility in how they adopt agentic AI, from specialized agents, to organization-specific automation, to integrating external AI tools ‚Äî all within a single, governed platform. Flows: Turning multi-step work into repeatable, guided progress Flows automate complex tasks with multiple agentic workflows, from start to finish. Our engineering team has built several flows included at GA, with more on the way: Developer (Issue to Merge Request) flow builds a structured MR from a well-defined issue so teams can begin work immediately. Convert to GitLab CI/CD flow helps teams migrate or modernize pipeline configurations without manual rewriting. Fix CI/CD pipeline flow analyzes failures, identifies likely causes, and prepares recommended changes. Code Review flow analyzes code changes, merge request comments, and more to streamline code reviews with AI-native analysis and feedback. Software development in IDE flow guides work through everyday development and review stages. MCP Client: Connect GitLab Duo Agent Platform to the tools your teams already use The MCP Client enables GitLab Duo Agent Platform in IDEs to securely connect to external systems like Jira, Slack, Confluence, and other MCP-compatible tools to pull in context and take action across your DevSecOps toolchain. Instead of AI assistance being siloed inside individual tools, the MCP Client allows GitLab Duo Agent Platform to understand and operate across the systems where planning, collaboration, and execution actually happen. This reduces manual context switching and enables more complete, end-to-end AI-powered workflows that reflect how teams work in practice. Included at GA: Connection to external MCP-compatible systems such as Jira, Confluence, Slack, Playwright, and Grafana Configuration at the workspace and user level Group-level controls to enable or restrict MCP usage User approval flow for tool access Support across Agentic Chat in the IDE extensions We plan to add more features to the GitLab MCP server capability, which is currently in beta, and make it generally available in upcoming releases. Choose the right model for your team and workloads GitLab Duo Agent Platform is built on a flexible model selection framework that enables teams to tailor the platform to align with their privacy, security, and compliance needs. GitLab defaults to an optimal LLM for each feature, but administrators have the option to select from supported models such as OpenAI GPT-5 variants, Mistral, Meta Llama, and Anthropic Claude. This gives teams more precise control and flexibility over what is used for chat, coding tasks, and agent interactions for each specific use case, based on your organization‚Äôs standards. For a full list of supported models and details on model section configuration, see the Model Selection section of our documentation. Governance, visibility, and deployment flexibility The GitLab Duo Agent Platform gives organizations the control and transparency they need to help them adopt AI responsibly, while offering flexible deployment options that work across different environments. Included at GA: Available on all platforms: GitLab.com, GitLab Self-Managed, and GitLab Dedicated as part of the GitLab 18.8 release cycle. Governance and visibility: Teams can see how agents are used, what actions they perform, and how they contribute to work. Usage and activity details help leaders understand adoption, measure impact, and ensure AI is being used appropriately. These controls make it easier to roll out AI at scale with confidence. Group-based access controls: Administrators can define namespace-level rules governing which users can access GitLab Duo Agent Platform features, supporting flexible adoption from immediate organization-wide enablement to phased rollouts. With LDAP and SAML integration, they can enable governance at scale without manual configuration. Model selection and self-hosted options: LLM selection is available for all GA features across GitLab.com, Self-Managed, and Dedicated. Top-level namespace owners choose the model, and subgroups inherit those settings automatically. For organizations that want more control, the platform supports self-hosted models for GitLab Self-Managed deployments. Watch a demo of GitLab Duo Agent Platform in action: Stay up to date with GitLab To make sure you‚Äôre getting the latest features, security updates, and performance improvements, we recommend keeping your GitLab instance up to date. The following resources can help you plan and complete your upgrade: Upgrade Path Tool ‚Äì enter your current version and see the exact upgrade steps for your instance Upgrade Documentation ‚Äì detailed guides for each supported version, including requirements, step-by-step instructions, and best practices By upgrading regularly, you‚Äôll ensure your team benefits from the newest GitLab capabilities and remains secure and supported. For organizations that want a hands-off approach, consider GitLab‚Äôs Managed Maintenance service . Managed Maintenance can help your team stay focused on innovation while GitLab experts keep your Self-Managed instance reliably upgraded, secure, and ready to lead in DevSecOps. Ask your account manager for more information. * GitLab customers with active Premium and Ultimate subscriptions will automatically receive $12 and $24 of included credits per user, respectively, which will reset each month. These credits are available for a limited time, and are subject to change ( see promo terms ). This blog post contains \"forward‚Äëlooking statements\" within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934. Although we believe that the expectations reflected in these statements are reasonable, they are subject to known and unknown risks, uncertainties, assumptions and other factors that may cause actual results or outcomes to differ materially. Further information on these risks and other factors is included under the caption \"Risk Factors\" in our filings with the SEC. We do not undertake any obligation to update or revise these statements after the date of this blog post, except as required by law.",
      "published_ts": 1768435200,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/introducing-gitlab-credits/",
      "title": "Introducing GitLab Credits, usage-based pricing for GitLab Duo Agent Platform",
      "summary": "We built GitLab Credits because seat-based pricing for agentic AI was not making sense. Seat-based pricing creates AI ‚Äúhaves\" and \"have-nots‚Äù for engineering teams, a fundamental misalignment with the way that modern agentic AI should be used across the software development lifecycle. Today, you have to buy a seat for every individual before they can start using AI. While this works for the few heavy users, it can be too expensive and unfair for the majority of the team with light or spiky usage. That's why in many organizations, only a portion of the team gets to have an ‚ÄúAI seat.\" Add to that, GitLab Duo Agent Platform is different from Duo Pro, Duo Enterprise, and other AI developer tools in the market. Agents and agentic workflows can be invoked by your team when they need AI assistance and triggered by SDLC events running in the background. With Duo Agent Platform, agentic AI is no longer only tied to user seats. GitLab Credits addresses these issues as our new virtual currency for usage-based pricing, starting with GitLab Duo Agent Platform. That means, every member in your organization with a GitLab account (Premium or Ultimate) can now use agentic AI capabilities without you paying for an AI seat, whether invoked by them or set up as background agents. How GitLab Credits work GitLab Credits are pooled across your entire organization. Your GitLab Duo Agent Platform usage is drawn down from GitLab Credits. That includes both synchronous and asynchronous use of agents and agentic flows. This includes: Foundational agents such as Security Analyst, Planner, and Data Analyst Foundational flows such as Code Review, Developer, and Fix CI/CD Pipeline External agents such as Anthropic Claude Code and OpenAI Codex Custom agents and flows you build and publish in your GitLab AI Catalog Agentic Chat in the GitLab UI and in the IDE used by your developers Note: External agents are available to try at no cost in 18.8 and do not consume GitLab Credits. We will be introducing pricing next month with our 18.9 release. Custom flows are currently in beta and do not consume GitLab Credits. The amount of credits drawn down is based on the number of agentic requests by large language models ( more details here ). As more LLMs become available, we will certify them for use with GitLab Duo Agent Platform and add to this list, providing customers with a transparent view of how they are consumed. The total count of GitLab Credits is calculated at the end of the month based on actual usage. This model also automatically offsets usage from power users against that of lighter users, effectively lowering your total cost of AI for every individual (as compared to paying per seat for every individual). For simplicity, each GitLab Credit has an on-demand list price of $1. You can use GitLab Duo Agent Platform without any commitments and usage is billed monthly (at the end of each month). For enterprise customers that sign up for annual commitments , we offer volume discounts for monthly credits. As a limited-time promotion * , all GitLab customers that have active Premium and Ultimate subscriptions will automatically receive $12 and $24 in included credits per user , respectively. These credits will refresh every month until the end of the promotion period and give your team access to all GitLab Duo Agent Platform features at no extra cost. When you accept our billing terms, any usage above these included credits will be billed through committed monthly credits or on-demand credits. Cost governance with GitLab Credits Sizing GitLab Credits: Your account team has a sizing calculator as part of the GA of GitLab Duo Agent Platform to estimate the number of GitLab Credits you‚Äôll need every month. This calculator was built with usage patterns we‚Äôve observed during the beta period. In addition, as an existing or a new customer, you can request a free trial to confirm your estimated actual usage. Usage visibility: With the 18.8 release, you have detailed usage information through two complementary dashboards ‚Äî one in the GitLab Customers Portal for billing managers focused on financial oversight, and one in-product for administrators focused on operational monitoring. Both provide attribution of usage, cost breakdowns, and historical trends so you always know exactly how your credits are being consumed. If you follow a cross-charging practice internally, you‚Äôll be able to use project- and group-level rollups for cost allocations. Usage controls: You can enable or disable GitLab Duo Agent Platform access for specific teams or projects, ensuring only approved usage can tally up to your credits. We also plan to add user-level controls shortly after GA to help you manage who can use GitLab Duo Agent Platform capabilities and draw-down credits. Automated usage notifications: We‚Äôll proactively keep you informed about your GitLab Credit usage via email alerts when you reach 50%, 80%, and 100% of your committed monthly credits, giving you time to adjust usage, purchase additional commitments, or plan for on-demand billing. Upgrading from seat-based GitLab Duo Pro/Enterprise to GitLab Credits for Duo Agent Platform If you‚Äôve purchased and are using GitLab Duo Pro and Duo Enterprise, you can keep using those capabilities as supported options. You can upgrade to GitLab Duo Agent Platform at any time and do what you can with ‚Äúclassic‚Äù Duo and access new capabilities such as agentic chat, additional foundational agents, custom agents and flows, external agents, and more. At the time of upgrade, we will roll forward your investment in seats for GitLab Duo Pro and Duo Enterprise to GitLab Credits for Duo Agent Platform. The remaining dollar amount of seat commitments will be exchanged for monthly GitLab Credits with volume-based discounts. The monthly GitLab Credits can then be shared across every team member in your organization you allow, not just the users who had assigned Duo seats before. Competitive comparison: GitLab Credits vs. seat-based pricing Benefit GitLab Credits Seat-based pricing AI for everyone Every approved team member gets AI access from day one Creates AI \"haves\" and \"have-nots\" ‚Äî forces seat rationing No upfront Investment Start small with included credits, increase commitment as ROI becomes clear Must purchase seats upfront before proving value Pay for what you use Only the AI work actually performed above included tier is billed Pay per seat regardless of actual usage Optimized spend Shared credit pool allows you to offset power users with light users Must pay for light users, overages for premium requests from power users Detailed visibility Usage dashboards with detailed attribution and historical trends Limited insight into which users drive value Granular cost controls Choose who can access, proactive alerts, and upcoming budget controls to limit Limit who gets a seat to control costs Sizing flexibility Calculator to estimate monthly credits, with more unit discounts with volume Count who gets a seat multiplied by price per seat Simplified contracts and billing Single SKU and bill covers all agentic capabilities across the DevSecOps lifecycle Multiple AI licenses required across different third-party tools Getting started For existing Premium/Ultimate customers : With GA, GitLab Duo Agent Platform will be available for customers with active Premium and Ultimate licenses ** . GitLab.com SaaS customers will gain access automatically. GitLab Self-Managed customers will gain access when they upgrade to the GitLab 18.8 release (with the planned Duo Agent Platform general availability). GitLab Dedicated customers will be upgraded to GitLab 18.8 during their scheduled maintenance window in February and will be able to use Duo Agent Platform from that point. Enable GitLab Duo : Ensure GitLab Duo Agent Platform is enabled in your namespace settings. Start exploring : Use your included monthly GitLab Credits to try GitLab Duo Agent Platform capabilities. Go beyond included credits: You will be able to opt-in to GitLab Credits for expanded usage beyond included credits at the on-demand list price. For volume discounts with commitment, please contact us to get a quote for your specific usage level. Visit our GitLab Duo Agent Platform documentation to learn more about getting started. Notes * These included promotional credits are available for a limited time at GA, and subject to change at GitLab‚Äôs discretion. ** Excludes GitLab Duo with Amazon Q and GitLab Dedicated for Government customers. To learn more about GitLab Duo Agent Platform and all the ways agentic AI can transform how your team works, visit our GitLab Duo Agent Platform page . If you are an existing GitLab customer, reach out to your GitLab account manager or partner to schedule a live demonstration of our platform capabilities. GitLab Credits FAQ 1. What are GitLab Credits and why did GitLab introduce them? GitLab Credits is a new virtual currency for usage-based GitLab capabilities, starting with GitLab Duo Agent Platform. GitLab introduced this model because seat-based pricing was forcing organizations to ration AI access within engineering teams, and Duo Agent Platform usage is not just tied to seats. Credits are pooled across your entire organization, allowing you to give every team member access to AI capabilities, or set up background agentic workflows, without requiring individual seat purchases upfront. 2. How does credit consumption work? Credits are drawn down based on the number of agentic requests made, with different rates depending on which LLM is used. For example, you get two model requests per credit for Claude-sonnet-4.5 (the default for most features), and 20 requests per credit for models like gpt-5-mini or claude-3-haiku. 3. What's included for existing Premium and Ultimate customers? As a limited-time promotion, customers with active Premium and Ultimate subscriptions automatically receive included credits free of charge alongside the GA release of Duo Agent Platform in GitLab 18.8: $12 in credits per user per month for Premium $24 in credits per user per month for Ultimate Included credits are at a per-user level, refresh monthly, and enable access to all GitLab Duo Agent Platform features at no extra cost. Usage above these included credits will be billed separately. These included promotional credits are available for a limited time after GA, and subject to change at GitLab‚Äôs discretion. 4. How can I control and monitor credit usage? GitLab provides multiple governance tools: detailed usage dashboards in both the Customers Portal and in-product, the ability to enable/disable access for specific teams or projects, upcoming user-level controls, and automated email alerts at 50%, 80%, and 100% of committed monthly credits. We also expect to offer a sizing calculator to estimate your monthly credit needs. 5. How do I get started with GitLab Duo Agent Platform? Once GA, for existing Premium/Ultimate customers, access is automatic on GitLab.com SaaS. Self-Managed customers gain access when upgrading to GitLab 18.8 with the planned Duo Agent Platform general availability. Simply enable GitLab Duo Agent Platform in your namespace settings and start exploring using your included monthly credits. For usage beyond included credits, you can opt-in to on-demand billing or contact GitLab for volume discounts with annual commitments. This blog post contains \"forward‚Äëlooking statements\" within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934. Although we believe that the expectations reflected in these statements are reasonable, they are subject to known and unknown risks, uncertainties, assumptions and other factors that may cause actual results or outcomes to differ materially. Further information on these risks and other factors is included under the caption \"Risk Factors\" in our filings with the SEC. We do not undertake any obligation to update or revise these statements after the date of this blog post, except as required by law.",
      "published_ts": 1768435200,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/access-snowflake-horizon-catalog-data-using-catalog-federation-in-the-aws-glue-data-catalog/",
      "title": "Access Snowflake Horizon Catalog data using catalog federation in the AWS Glue Data Catalog",
      "summary": "AWS has introduced a new catalog federation feature that enables direct access to Snowflake Horizon Catalog data through AWS Glue Data Catalog. This integration allows organizations to discover and query data in Iceberg format while maintaining security through AWS Lake Formation. This post provides a step-by-step guide to establishing this integration, including configuring Snowflake Horizon Catalog, setting up authentication, creating necessary IAM roles, and implementing AWS Lake Formation permissions. Learn how to enable cross-platform analytics while maintaining robust security and governance across your data environment.",
      "published_ts": 1768424426,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/understanding-flows-multi-agent-workflows/",
      "title": "Understanding flows: Multi-agent workflows",
      "summary": "Welcome to Part 4 of our eight-part guide, Getting started with GitLab Duo Agent Platform , where you'll master building and deploying AI agents and workflows within your development lifecycle. Follow tutorials that take you from your first interaction to production-ready automation workflows with full customization. In this article: What are flows and how do they work? Foundational flows provided by GitLab Creating custom flows Flow execution and orchestration Real-world examples and use cases üéØ Try GitLab Duo Agent Platform today! Introduction to flows Flows are combinations of one or more agents collaborating together. They orchestrate multi-step workflows to solve complex problems, and are executed on the GitLab platform compute. Key characteristics of flows: Multi-agent orchestration : Combine multiple specialized agents Built-in : Run on platform compute, no extra environment necessary Event-driven : Triggered by mention, assignment, or assign as reviewer Asynchronous : Run in background while you continue working Complete workflows : Handle end-to-end tasks from analysis to implementation Think of flows as autonomous workflows that can gather context, make decisions, execute changes, and deliver results, all while you focus on other work. Flows vs. agents: Understanding the difference Agents work with you interactively. Flows work for you autonomously. Aspect Agents Flows Interaction Interactive chat Autonomous execution When to use Questions, guidance, and performing tasks interactively Autonomous multi-step workflows User involvement Active conversation Trigger and review results Execution time Real-time responses Background processing Complexity Single-agent tasks Multi-agent orchestration Flow types overview Type Interface Maintainer Use Case Foundational UI actions, IDE interface GitLab Software Development, Developer in issues, Fix CI/CD Pipeline, Convert to GitLab CI/CD, Code Review, SAST false positive detection Custom Mention, assign, assign reviewer You Examples: Larger migration/modernization, release automation, dependency update management Foundational flows Foundational flows are production-ready workflows created and maintained by GitLab. They're accessible through dedicated UI controls or IDE interfaces. Currently available foundational flows Flow Where Available How to Access Best For Software Development IDEs (VS Code, JetBrains, Visual Studio) Flows tab in IDE Feature implementation, complex refactoring, multi-file changes Developer GitLab Web UI \"Generate MR with Duo\" button on issues Well-defined features, bug fixes with clear steps Fix CI/CD Pipeline GitLab Web UI Failed pipeline interface Pipeline debugging, CI/CD configuration issues Convert to GitLab CI/CD GitLab Web UI \"Convert to GitLab CI/CD\" button on Jenkinsfile Jenkins to GitLab CI/CD migration Code Review GitLab Web UI Assign as reviewer on MR Automated code review with AI-native analysis and feedback SAST false positive detection GitLab Web UI Security scan results Automatically identify and filter false positives in SAST findings Custom flows Custom flows are YAML-defined workflows you create for your team's specific needs. They run in GitLab Runner and can be triggered by GitLab events. üéØ Try it now: Interactive demo of Custom Flows ‚Äî Explore how to create and configure Custom Flows. Why create custom flows? Custom flows automate repetitive multi-step tasks that are specific to your team's workflow. Unlike foundational flows that serve general purposes, custom flows are tailored to your organization's processes, tools, and requirements. Common use cases: Automated code review : Multi-stage review process (security scan ‚Üí quality check ‚Üí style validation) Compliance checking : Verify regulatory requirements, license compliance, or security policies on each MR Documentation generation : Auto-update API docs, README files, or changelogs based on code changes Dependency management : Weekly security scans, automated updates, and vulnerability reports Custom testing : Specialized test suites for your tech stack or integration tests Real-world example A fintech company creates a compliance flow that runs on every merge request. When triggered by @compliance-flow , the flow executes the following steps: Security agent scans code for PCI-DSS violations and checks for exposed sensitive data. Code review agent verifies that changes follow secure coding standards and best practices. Documentation agent checks that API changes include updated documentation. Summary agent aggregates findings and posts a compliance report with pass/fail status. The entire compliance review happens automatically in 5-10 minutes, providing consistent checks across all merge requests. How to trigger custom flows Custom flows can be triggered in multiple ways: 1. Via mentions in Issues/MRs: Mention the flow in a comment to trigger it. Example for a documentation generation flow: @doc-generator Generate API documentation for this feature 2. By assigning the flow to an issue or MR: Assign the flow using either: GitLab UI : Click the \"Assign\" button on the issue/MR and select the flow Command : Use the /assign command in a comment. Example: /assign @doc-generator 3. By assigning the flow as a reviewer: Assign the flow as a reviewer on a merge request using either: GitLab UI : Click the \"Assign reviewer\" button on the merge request and select the flow Command : Use the /assign_reviewer command in a comment. Example: /assign_reviewer @doc-reviewer Any of these methods automatically triggers the flow to execute and perform its tasks. How to create custom flows Custom flows are created through the GitLab UI at Automate ‚Üí Flows ‚Üí New flow in your project, or from Explore ‚Üí AI Catalog ‚Üí Flows ‚Üí New flow . You define your flow using YAML configuration that specifies components, prompts, routing, and execution flow. The YAML schema allows you to create sophisticated multi-agent workflows with precise control over agent behavior and orchestration. Key elements of a custom flow: Components : Define the agents and steps in your workflow Prompts : Configure AI model behavior and instructions Routers : Control the flow between components Toolsets : Specify which GitLab API tools agents can use Example custom flow YAML Background: This example shows a feature implementation flow for a travel booking platform. When a developer creates an issue with feature requirements, they can trigger this flow to automatically analyze the requirements, review the codebase, implement the solution, and create a merge request, all without manual intervention.\nHere's the YAML configuration: version: \"v1\"\nenvironment: ambient\ncomponents:\n  - name: \"implement_feature\"\n    type: AgentComponent\n    prompt_id: \"implementation_prompt\"\n    inputs:\n      - from: \"context:goal\"\n        as: \"user_goal\"\n      - from: \"context:project_id\"\n        as: \"project_id\"\n    toolset:\n      - \"get_issue\"\n      - \"get_repository_file\"\n      - \"list_repository_tree\"\n      - \"find_files\"\n      - \"blob_search\"\n      - \"create_file\"\n      - \"create_commit\"\n      - \"create_merge_request\"\n      - \"create_issue_note\"\n    ui_log_events:\n      - \"on_agent_final_answer\"\n      - \"on_tool_execution_success\"\n      - \"on_tool_execution_failed\"\n\nprompts:\n  - name: \"Cheapflights Feature Implementation\"\n    prompt_id: \"implementation_prompt\"\n    unit_primitives: []\n    prompt_template:\n      system: |\n        You are an expert full-stack developer specializing in travel booking platforms, specifically Cheapflights.\n\n        Your task is to:\n        1. Extract the issue IID from the goal (look for \"Issue IID: XX\")\n        2. Use get_issue with project_id={{project_id}} and issue_iid to retrieve issue details\n        3. Analyze the requirements for the flight search feature\n        4. Review the existing codebase using list_repository_tree, find_files, and get_repository_file\n        5. Design and implement the solution following Cheapflights best practices\n        6. Create all necessary code files using create_file (call multiple times for multiple files)\n        7. Commit the changes using create_commit\n        8. Create a merge request using create_merge_request\n        9. Post a summary comment to the issue using create_issue_note with the MR link\n\n        Cheapflights Domain Expertise:\n        - Flight search and booking systems (Amadeus, Sabre, Skyscanner APIs)\n        - Fare comparison and pricing strategies\n        - Real-time availability and inventory management\n        - Travel industry UX patterns\n        - Performance optimization for high-traffic flight searches\n\n        Code Standards:\n        - Clean, maintainable code (TypeScript/JavaScript/Python/React)\n        - Proper state management for React components\n        - RESTful API endpoints with comprehensive error handling\n        - Mobile-first responsive design\n        - Proper timezone handling (use moment-timezone or date-fns-tz)\n        - WCAG 2.1 accessibility compliance\n\n        Flight-Specific Best Practices:\n        - Accurate fare calculations (base fare + taxes + fees + surcharges)\n        - Flight duration calculations across timezones\n        - Search filter logic (price range, number of stops, airlines, departure/arrival times)\n        - Sort algorithms (best value, fastest, cheapest)\n        - Handle edge cases: date line crossing, daylight saving time, red-eye flights\n        - Currency amounts use proper decimal handling (avoid floating point errors)\n        - Dates use ISO 8601 format\n        - Flight codes follow IATA standards (3-letter airport codes)\n\n        Implementation Requirements:\n        - No TODOs or placeholder comments\n        - All functions must be fully implemented\n        - Include proper TypeScript types or Python type hints\n        - Add JSDoc/docstring comments for all functions\n        - Comprehensive error handling and input validation\n        - Basic unit tests for critical functions\n        - Performance considerations for handling large result sets\n\n        CRITICAL - Your final comment on the issue MUST include:\n        - **Implementation Summary**: Brief description of what was implemented\n        - **Files Created/Modified**: List of all files with descriptions\n        - **Key Features**: Bullet points of main functionality\n        - **Technical Approach**: Brief explanation of architecture/patterns used\n        - **Testing Notes**: How to test the implementation\n        - **Merge Request Link**: Direct link to the created MR (format: [View Merge Request](MR_URL))\n\n        IMPORTANT TOOL USAGE:\n        - Extract the issue IID from the goal first (e.g., \"Issue IID: 12\" means issue_iid=12)\n        - Use get_issue with project_id={{project_id}} and issue_iid=<extracted_iid>\n        - Create multiple files by calling create_file multiple times (once per file)\n        - Use create_commit to commit all files together with a descriptive commit message\n        - Use create_merge_request to create the MR and capture the MR URL from the response\n        - Use create_issue_note with project_id={{project_id}}, noteable_id=<issue_iid>, and body=<your complete summary with MR link>\n        - Make sure to include the MR link in the comment body so users can easily access it\n\n      user: |\n        Goal: {{user_goal}}\n        Project ID: {{project_id}}\n\n        Please complete the following steps:\n        1. Extract the issue IID and retrieve full issue details\n        2. Analyze the requirements thoroughly\n        3. Review the existing codebase structure and patterns\n        4. Implement the feature with production-ready code\n        5. Create all necessary files (components, APIs, tests, documentation)\n        6. Commit all changes with a clear commit message\n        7. Create a merge request\n        8. Post a detailed summary comment to the issue including the MR link\n\n      placeholder: history\n    params:\n      timeout: 300\n\nrouters:\n  - from: \"implement_feature\"\n    to: \"end\"\n\nflow:\n  entry_point: \"implement_feature\" What this flow does: This flow orchestrates an AI agent to automatically implement a feature by analyzing issue requirements, reviewing the codebase, writing production-ready code with domain expertise, and creating a merge request with a detailed summary comment. For complete documentation and examples, see: Custom Flows documentation Flow Registry Framework (YAML Schema) Flow execution Flows run on GitLab platform compute. When triggered by an event (mention, assignment, or button click), a session is created and the flow starts to execute. Available environment variables Flows have access to environment variables that provide context about the trigger and the GitLab object: AI_FLOW_CONTEXT ‚Äî JSON-serialized context including MR diffs, issue descriptions, comments, and discussion threads AI_FLOW_INPUT ‚Äî The user's prompt or comment text that triggered the flow AI_FLOW_EVENT ‚Äî The event type that triggered the flow ( mention , assign , assign_reviewer ) These variables allow your flow to understand what triggered it and access the relevant GitLab data to perform its task. Multi-agent flows Custom flows can include multiple agent components that work together sequentially. The flow's YAML configuration defines: Components : One or more agents (AgentComponent) or deterministic steps Routers : Define the flow between components (e.g., from component A to component B to end) Prompts : Configure each agent's behavior and model For example, a code review flow might have a security agent, then a quality agent, then an approval agent, with routers connecting them in sequence. Monitoring flow execution To view flows that are running for your project: Navigate to Automate ‚Üí Sessions . Select any session to view more details. The Details tab shows a link to the CI/CD job logs. Sessions show detailed information including step-by-step progress, tool invocations, reasoning, and decision-making process. When to use flows Complex multi-step tasks Background automation Event-driven workflows Multi-file changes Tasks that take time Automated reviews/checks What's next? You now understand flows, how to create them, and when to use them vs. agents. Next, learn how to discover, create, and share agents and flows across your organization in Part 5: AI Catalog . Explore the AI Catalog to browse available flows and agents, add them to your projects, and publish your own agents and flows. Resources GitLab Duo Agent Platform Flows Foundational Flows documentation Custom Flows documentation Flow execution configuration GitLab CI/CD Variables guide Service Accounts Next: Part 5: AI Catalog Previous: Part 3: Understanding agents",
      "published_ts": 1768348800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.rudderstack.com/blog/ai-stress-test-modern-data-stack",
      "title": "AI is a stress test: How the modern data stack breaks under pressure",
      "summary": "AI acts on customer context in real time. See how latency, drift, and weak governance break experiences, and what an AI-ready data stack needs.",
      "published_ts": 1768336808,
      "source_name": "Rudderstack Blog",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/access-databricks-unity-catalog-data-using-catalog-federation-in-the-aws-glue-data-catalog/",
      "title": "Access Databricks Unity Catalog data using catalog federation in the AWS Glue Data Catalog",
      "summary": "AWS has launched the catalog federation capability, enabling direct access to Apache Iceberg tables managed in Databricks Unity Catalog through the AWS Glue Data Catalog. With this integration, you can discover and query Unity Catalog data in Iceberg format using an Iceberg REST API endpoint, while maintaining granular access controls through AWS Lake Formation. In this post, we demonstrate how to set up catalog federation between the Glue Data Catalog and Databricks Unity Catalog, enabling data querying using AWS analytics services.",
      "published_ts": 1768250264,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    }
  ],
  "etl_orchestration": [
    {
      "url": "https://aws.amazon.com/blogs/big-data/using-amazon-emr-deltastreamer-to-stream-data-to-multiple-apache-hudi-tables/",
      "title": "Using Amazon EMR DeltaStreamer to stream data to multiple Apache Hudi tables",
      "summary": "In this post, we show you how to implement real-time data ingestion from multiple Kafka topics to Apache Hudi tables using Amazon EMR. This solution streamlines data ingestion by processing multiple Amazon Managed Streaming for Apache Kafka (Amazon MSK) topics in parallel while providing data quality and scalability through change data capture (CDC) and Apache Hudi.",
      "published_ts": 1768513705,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/your-gtm-data-finally-untangled",
      "title": "Your GTM Data, Finally Untangled | Dagster Compass",
      "summary": "Connect Salesforce, Google Ads, and Gong to Compass and ask questions in Slack. No dashboards, no SQL, no tickets. Get real answers from your GTM data in seconds.",
      "published_ts": 1768488057,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://airbyte.com/blog/connectors-are-living-organisms",
      "title": "Connectors are Living Organisms | Airbyte",
      "summary": "Explore why connectors behave like living organisms constantly evolving, adapting to change, and powering resilient, scalable data integration systems.",
      "published_ts": 1768435200,
      "source_name": "Airbyte Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/how-to-enforce-data-quality-at-every-stage",
      "title": "How to Enforce Data Quality at Every Stage of Your Data Pipeline",
      "summary": "Learn how to enforce data quality across ingestion, transformation, and consumption. Catch data issues early and prevent broken dashboards with Dagster.",
      "published_ts": 1768236711,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://airbyte.com/blog/chat-with-schema",
      "title": "Chat with Your Schema: AI-Powered Configuration in Agent Engine | Airbyte",
      "summary": "Discover Chat with Your Schema in Agent Engine ‚Äì AI-powered configuration that simplifies data integration, automates workflows, and enhances agent intelligence.",
      "published_ts": 1768176000,
      "source_name": "Airbyte Blog",
      "content_type": "technical"
    }
  ],
  "hors_sujet": [],
  "lake_storage_formats": [
    {
      "url": "https://www.uber.com/blog/apache-hudi-at-uber/",
      "title": "Apache Hudi‚Ñ¢ at Uber: Engineering for Trillion-Record-Scale Data Lake Operations",
      "summary": "Check out this deep dive into how Uber runs Apache Hudi‚Ñ¢ at extreme scale‚Äîhandling trillions of records, petabytes of data, and high-concurrency table services across regions.",
      "published_ts": 1768573800,
      "source_name": "Uber Engineering Blog",
      "content_type": "technical"
    }
  ],
  "news": [
    {
      "url": "https://blog.cloudflare.com/astro-joins-cloudflare/",
      "title": "Astro is joining Cloudflare",
      "summary": "The Astro Technology Company team ‚Äî the creators of the Astro web framework ‚Äî is joining Cloudflare. We‚Äôre doubling down on making Astro the best framework for content-driven websites, today and in the years to come.",
      "published_ts": 1768572000,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://engineering.salesforce.com/how-a-mock-llm-service-cut-500k-in-ai-benchmarking-costs-boosted-developer-productivity/",
      "title": "How a Mock LLM Service Cut $500K in AI Benchmarking Costs, Boosted Developer Productivity",
      "summary": "By Sandeep Bansal and Seetharaman Gudetee. In our Engineering Energizers Q&A series, we spotlight the engineering minds driving innovation across Salesforce. Today‚Äôs edition features Sandeep Bansal, a senior software engineer from the AI Cloud Platform Engineering team, whose internal LLM mock service validates performance, reliability, and cost efficiency at scale ‚Äî supporting production-readiness benchmarks beyond [‚Ä¶] The post How a Mock LLM Service Cut $500K in AI Benchmarking Costs, Boosted Developer Productivity appeared first on Salesforce Engineering Blog .",
      "published_ts": 1768514549,
      "source_name": "Salesforce Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/enterprise-bcdr-data-platform-strategy",
      "title": "Is Your Business Continuity and Disaster Recovery Strategy Enterprise-Ready?",
      "summary": "Learn the three critical BCDR questions every data leader must ask to ensure true enterprise resilience and avoid expensive downtime.",
      "published_ts": 1768499598,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.cloudflare.com/human-native-joins-cloudflare/",
      "title": "Human Native is joining Cloudflare",
      "summary": "Cloudflare acquires Human Native, an AI data marketplace specialising in transforming content into searchable and useful data, to accelerate work building new economic models for the Internet.",
      "published_ts": 1768485600,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/aws/opening-the-aws-european-sovereign-cloud/",
      "title": "Opening the AWS European Sovereign Cloud",
      "summary": "Deutsch | English | Espa√±ol | Fran√ßais | Italiano As a European citizen, I understand first-hand the importance of digital sovereignty, especially for our public sector organisations and highly regulated industries. Today, I‚Äôm delighted to share that the AWS European Sovereign Cloud is now generally available to all customers. We first announced our plans to [‚Ä¶]",
      "published_ts": 1768461174,
      "source_name": "AWS Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/databricks-genie-powers-conversational-insights-atlassian-rovo",
      "title": "Databricks Genie Powers Conversational Insights in Atlassian Rovo",
      "summary": "Powering the Future of TeamworkFor millions of users, Atlassian is where work happens....",
      "published_ts": 1768356900,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/customizing-gitlab-duo-chat-rules-prompts-workflows/",
      "title": "Customizing GitLab Duo Agent Platform: Chat rules, prompts, and workflows",
      "summary": "Welcome to Part 8 of our eight-part guide, Getting started with GitLab Duo Agent Platform , where you'll master building and deploying AI agents and workflows within your development lifecycle. Follow tutorials that take you from your first interaction to production-ready automation workflows with full customization. In this article: Introduction to customization Customize agent behavior Extend capabilities with MCP Create custom agents and flows üéØ Try GitLab Duo Agent Platform today! Introduction to customization GitLab Duo Agent Platform delivers powerful capabilities right away, and you can unlock even greater value by tailoring it to your team's specific needs. GitLab offers flexible customization options across multiple levels: User-level : Personal preferences that apply across all projects (custom rules, AGENTS.md, MCP config) Workspace-level : Project-specific configurations (custom rules, AGENTS.md, MCP config) Project-level : Custom agents and flows you create and manage within a specific project Part 1: Customize agent behavior Custom rules Custom rules provide instructions for agents and flows, ensuring consistent behavior across your team without requiring repetition. For example, in development style guides or how to execute tests. Navigate to IDE workspace or user configuration directory . User-level custom rules User-level rules apply to all your projects and workspaces. For detailed instructions on creating user-level custom rules, see the GitLab documentation . Create the file ~/.gitlab/duo/chat-rules.md in your home directory. Example rules: - Include JSDoc comments for all functions\n- Use single quotes for strings\n- Follow the existing code style in the repository\n- Write concise explanations, avoid lengthy descriptions\n- Suggest tests for any code changes\n- Use async/await instead of promises Workspace-level custom rules Workspace rules apply only to a specific project. They override user-level rules for that project. Create the file .gitlab/duo/chat-rules.md in your project root. Example rules for a Vue.js project: - Use Vue 3 Composition API with `<script setup>`\n- Always include TypeScript types for props\n- Use scoped styles with SCSS\n- Follow the Slippers UI design system\n- Keep components under 300 lines\n- Use kebab-case for component names\n- Include accessibility attributes (aria-*, role) Best practices for custom rules Be specific : \"Use single quotes\" is better than \"follow style guide.\" Prioritize : List most important rules first. Team-focused : Rules should reflect your team's standards, not personal preferences. Actionable : Rules should be clear enough for an AI agent to follow. Maintainable : Update rules when your standards change. Avoid conflicts : Don't contradict your codebase's actual style. Tip: Use Code Owners to manage who approves changes to .gitlab/duo/chat-rules.md . For a detailed use case tutorial for custom rules, see the Custom rules in GitLab Duo Agentic Chat for greater developer efficiency deep-dive blog post . AGENTS.md for customizing agent behavior AGENTS.md is an industry-standard file for customizing agent behavior. It allows you to define how agents should behave in your chat conversations, foundational flows, and custom flows without modifying the agents themselves. Difference to custom rules: AGENTS.md are consumed by all agents and flows (foundational and custom). It also follows an industry standard that other AI tools can use, for example, Claude Code as external agent . Use AGENTS.md when you want your instructions to apply across multiple contexts. User-level (applies to all your projects and workspaces): macOS/Linux: ~/.gitlab/duo/AGENTS.md Windows: %APPDATA%\\GitLab\\duo\\AGENTS.md Workspace-level (applies to a specific project): Create AGENTS.md in your project root. Subdirectory-level (applies to specific directories in monorepos): Create AGENTS.md in subdirectories for context-specific instructions. How it works: User-level AGENTS.md applies globally across all projects. Workspace-level AGENTS.md applies to a specific project. Subdirectory-level AGENTS.md files provide context for specific parts of your codebase. Agents and flows combines instructions from all applicable levels. Newly added or updated AGENTS.md instructions require triggering new flows, or starting a new chat with a (custom) agent. What AGENTS.md controls Agent personality and tone Project-specific instructions Coding standards and conventions Tool usage preferences Output formatting requirements Repository structure and organization Example AGENTS.md # Agent Customization for Our Project\n## General Guidelines\n- Always prioritize code quality over speed\n- Follow our project's architecture patterns\n- Reference existing code examples when suggesting changes\n- Ask for clarification if requirements are ambiguous\n## Code Style\n- Use TypeScript for all new code\n- Follow ESLint configuration in the project\n- Include unit tests for all new functions\n- Use descriptive variable names (no single letters except loops)\n## Documentation\n- Add JSDoc comments to all public functions\n- Update README.md if adding new features\n- Include examples in code comments\n## Security\n- Never suggest hardcoding secrets or API keys\n- Always validate user input\n- Use parameterized queries for database operations\n- Flag potential security issues immediately Best practices for AGENTS.md Be specific : Include concrete examples from your project. Keep it concise : Focus on what's unique to your project. Version control : Commit to your repository and track changes. Team alignment : Discuss with your team before finalizing. Update regularly : Refine as your project evolves. Document repository structure : Help agents understand your codebase organization. Requirements GitLab 18.8 or later For VS Code: GitLab Workflow extension 6.60 or later For JetBrains: GitLab plugin 3.26.0 or later For flows: Update flow configuration to access the user_rule context Learn more about AGENTS.md . Custom review instructions Custom review instructions provide specific guidelines for the Code Review foundational flow . The instructions ensure consistent code review standards, and can be tailored to specific file types in your project. Create the file .gitlab/duo/mr-review-instructions.yaml in your project root. Example review instructions: instructions:\n  - name: Ruby Style Guide\n    fileFilters:\n      - \"*.rb\"           # Ruby files in the root directory\n      - \"lib/**/*.rb\"    # Ruby files in lib and its subdirectories\n      - \"!spec/**/*.rb\"  # Exclude test files\n    instructions: |\n      1. Ensure all methods have proper documentation\n      2. Follow Ruby style guide conventions\n      3. Prefer symbols over strings for hash keys\n\n  - name: TypeScript Source Files\n    fileFilters:\n      - \"**/*.ts\"        # TypeScript files in any directory\n      - \"!**/*.test.ts\"  # Exclude test files\n    instructions: |\n      1. Ensure proper TypeScript types (avoid 'any')\n      2. Follow naming conventions\n      3. Document complex functions Best practices for custom review instructions: Be specific and actionable : Clear, numbered instructions work best. Use glob patterns : Target specific file types with fileFilters . Focus on important standards : Prioritize the most critical review points. Explain the \"why\" : Help reviewers understand the reasoning. Test patterns : Ensure glob patterns match the intended files. Tip: Use Code Owners to protect changes to .gitlab/duo/mr-review-instructions.yaml . For detailed setup instructions and examples, see the Custom Review Instructions documentation . Part 2: Extend capabilities with MCP Model Context Protocol (MCP) enables agents to access external systems like Jira, Slack, AWS, and more. This section covers MCP configuration for extending agent capabilities. üéØ Try it now: Interactive demo of MCP - Explore how to use Model Context Protocol. MCP configuration for external integrations Model Context Protocol (MCP) enables agents to access external systems like Jira, Slack, AWS, and more. Scope: User-level (applies to all workspaces) or Workspace-level (project-specific, overrides user config) Create user configuration: macOS/Linux : ~/.gitlab/duo/mcp.json Windows : C:\\Users\\<username>\\AppData\\Roaming\\GitLab\\duo\\mcp.json VS Code : Run command GitLab MCP: Open User Settings (JSON) Create workspace configuration: Create file : .gitlab/duo/mcp.json in your project root Best practices: Security first : Use MCP servers that require OAuth and not plain-text password tokens. Minimal scope : Only enable MCP servers you actually use and trust. Test locally : Verify MCP connections and authorization work before sharing across teams. Document integrations : Explain what each MCP server provides. Version control : Store configuration in .gitlab/duo/mcp.json with Code Owners' approval. For detailed setup instructions and configuration examples, see Part 7: Model Context Protocol (MCP) Integration . Part 3: Create custom agents and flows Custom agents and flows allow you to automate your team's specific workflows. Before diving into customization, it's helpful to understand what they are and how they work. Here are parts of the Getting started with GitLab Duo Agent Platform guide that can help. Part 3: Understanding agents ‚Äî Learn about foundational, custom, and external agents, and when to use each type. Part 4: Understanding flows ‚Äî Discover how flows orchestrate multiple agents to solve complex problems. Part 5: AI Catalog ‚Äî Learn how to discover, create, and share agents and flows across your organization.\nOnce you understand the basics, this section provides an overview of customization options with links to detailed guides. System prompts for custom agents System prompts define an agent's personality, expertise, and behavior. A well-crafted prompt makes agents more effective and aligned with your team's needs. What are system prompts? System prompts are instructions that tell an agent how to behave, what expertise it has, and how to respond to requests. They're the foundation of custom agent behavior. Key elements of a strong system prompt: Role definition : What the agent is and what it does Expertise areas : Specific domains or technologies Behavior guidelines : How it should interact and respond Output format : Structure of responses Constraints : What it should avoid Best practices: Be detailed : More specific prompts produce better results. Use examples : Show the agent what good output looks like. Define scope : Clearly state what the agent should and shouldn't do. Test iteratively : Refine prompts based on agent behavior. Version control : Track prompt changes in your repository. For detailed guidance on crafting system prompts and creating custom agents, see Part 3: Understanding agents . Custom agents and flows There is a lot to learn, and for easier reading, the tutorials are split: Custom agents: Learn how to create agents with custom system prompts, configure tools, and manage permissions. See Part 3: Understanding agents - Custom agents section . Custom flows: Learn how to create multi-step workflows, configure components, and set up event-driven automation. See Part 4: Understanding flows ‚Äî Custom flows section . Agent tools: Tools determine what actions agents can perform. Configure tools based on your agent's purpose and security requirements. See Part 3: Understanding agents for tool configuration details. Quick reference: When to use customizations Tool Best For Location Custom Rules Guiding Chat responses in IDE (tone, style, behavior) ~/.gitlab/duo/chat-rules.md (user) or .gitlab/duo/chat-rules.md (workspace) AGENTS.md Enforcing standards across chat, flows, and other AI tools ~/.gitlab/duo/AGENTS.md (user) or AGENTS.md (workspace root) Custom Review Instructions Guiding code review standards for specific file types .gitlab/duo/mr-review-instructions.yaml (workspace only) System Prompts Customizing individual agent behavior AI Catalog when creating an agent MCP Configuration Connecting agents to external tools ~/.gitlab/duo/mcp.json (user) or .gitlab/duo/mcp.json (workspace) Custom Agents Creating specialized agents for team-specific tasks Automate ‚Üí Agents or AI Catalog Custom Flows Orchestrating multiple agents in workflows Automate ‚Üí Flows or AI Catalog What's next? Congratulations! You've completed the entire GitLab Duo Agent Platform series. You now understand: How to use agents and flows across the entire SDLC, tailored to your use cases How to discover and share solutions in the AI Catalog How to monitor and manage your AI workflows How to extend capabilities with MCP integrations How to customize every aspect of GitLab Duo Agent Platform for your team Return to complete series overview to review all parts and explore specific topics in depth. Resources Custom Rules documentation AGENTS.md documentation Custom Review Instructions documentation Custom Agents documentation Custom Flows documentation MCP Clients documentation Previous: Part 7: Model Context Protocol integration Back to start: Complete series overview",
      "published_ts": 1768348800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/monitor-manage-automate-ai-workflows/",
      "title": "Monitor, manage, and automate AI workflows",
      "summary": "Welcome to Part 6 of our eight-part guide, Getting started with GitLab Duo Agent Platform , where you'll master building and deploying AI agents and workflows within your development lifecycle. Follow tutorials that take you from your first interaction to production-ready automation workflows with full customization. In this article: Introduction to Automate capabilities Managing agents in your project Managing flows in your project Setting up event-driven triggers Monitoring flows activity with sessions üéØ Try GitLab Duo Agent Platform today! Introduction to the Automate capabilities The Automate capabilities are your central hub for managing AI workflows in GitLab. They provide visibility into agent and flow activity, and enable event-driven automation. Navigate to Project ‚Üí Automate . The Automate menu provides these main sections: Agents : View, create, and manage agents in your project Flows : View, create, and manage flows in your project Triggers : Configure event-based automation for flows Sessions : Monitor agent and flow execution with detailed logs Managing agents The Agents section allows you to view, create, and manage agents in your project. Navigate to Automate ‚Üí Agents . Both Agents and Flows sections provide two tabs for organizing your resources: Enabled : Agents/flows available to your project Managed : Agents/flows created and owned by your project To expand your available agents: Create new custom agents, enable at the top-level group, then enable them in your project. Browse the AI Catalog and enable existing agents in your top-level group first, then in your project. For details on creating custom agents, see Part 3: Understanding agents . Managing flows The Flows section allows you to view, create, and manage flows in your project. Navigate to Automate ‚Üí Flows . To expand your available flows: Create new custom flows, enable at the top level group, then enable them in your project. Browse the AI Catalog and enable existing flows in your top-level group first, then in your project. For details on creating custom flows, see Part 4: Understanding flows . Automating with triggers Overview of auto-created triggers Triggers enable event-driven automation by automatically executing agents or flows when specific GitLab SDLC events occur. Navigate to Automate ‚Üí Triggers . Available trigger event types: Mention : Mentioned in a comment, for example, @ci-cd-optimizer . Assign : Assigned to an issue or MR, for example, in the UI or quick action /assign @ci-cd-optimizer . Assign Reviewer : Assigned as MR reviewer, for example, in the UI or quick action /assign_reviewer @ci-cd-optimizer . How triggers work: Event occurs (e.g., @ci-cd-optimizer mentioned in MR comment) Trigger identifies the flow to execute Flow runs and starts a session Results posted back to the issue/MR For setup instructions, see the Triggers documentation . Monitoring with sessions Sessions provide transparency into agents and flows execution, including reasoning, executed tools, and outputs. Every run creates a session with an activity log. Sessions overview showing execution status and progress Navigate to Automate ‚Üí Sessions . Sessions show: Execution status (Created, Running, Finished, Failed, Input Required, and more) Step-by-step progress and actions taken Agent reasoning and decision-making process Link to Runner job logs (Details tab) Activity tab The Activity tab displays the step-by-step execution flow, showing each action the agent took, the tools it used, and the results of those actions. Session activity showing step-by-step execution and agent actions Details tab The Details tab provides access to the complete runner job logs, allowing you to see the full execution context and any system-level information about the flow run. Session details with runner job logs and execution context The job logs contain the full execution output, including all system messages, tool invocations, and detailed information about what the flow executed. Complete runner job logs showing detailed execution output For more details, see the Sessions documentation . What's next? You now understand how to monitor agent and flow activity through sessions, set up event-driven automation with triggers, and manage your AI workflows from the Automate capabilities. Next, learn how to extend GitLab Duo with external tools and data sources in Part 7: Model Context Protocol integration . Resources Sessions documentation Triggers documentation Custom Flows documentation Custom Agents documentation Next: Part 7: Model Context Protocol integration Previous: Part 5: AI Catalog",
      "published_ts": 1768348800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://engineering.salesforce.com/how-agentforce-enabled-conversational-recommendations-with-ai-driven-intent-on-data-360/",
      "title": "How Agentforce Enabled Conversational Recommendations with AI-Driven Intent on Data 360",
      "summary": "By Karunakar Komirishetty, Bhumika Sethi, and Shiva Rama Pranav Joolaganti. In our Engineering Energizers Q&A series, we highlight the engineering minds driving innovation across Salesforce. Today, we feature Bhumika Sethi, a software engineer on Data 360‚Äôs Personalization team, delivering real-time, large-scale personalization by unifying customer profiles, engagement signals, and metadata across Salesforce, including intent-based recommendations [‚Ä¶] The post How Agentforce Enabled Conversational Recommendations with AI-Driven Intent on Data 360 appeared first on Salesforce Engineering Blog .",
      "published_ts": 1768346413,
      "source_name": "Salesforce Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.youtube.com/watch?v=Lz9nU0l7sGg",
      "title": "How to start with Data Engineering in 2026 & my biggest regret",
      "summary": "Advice for Data Analysts, Data Scientists and beginners.\n\nCheck out LearnDataEngineering.com to get good :)",
      "published_ts": 1768337060,
      "source_name": "Andreas Kretz (YouTube)",
      "content_type": "technical"
    },
    {
      "url": "https://www.getdbt.com/blog/finding-your-people-in-data",
      "title": "Finding your people in data (and building a community that actually sticks)",
      "summary": "The View on Data explores how data leaders find community, rethink mentorship, and build connections.",
      "published_ts": 1768324680,
      "source_name": "dbt Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.cloudflare.com/iran-protests-internet-shutdown/",
      "title": "What we know about Iran‚Äôs Internet shutdown",
      "summary": "Cloudflare Radar data shows Internet traffic from Iran has effectively dropped to zero since January 8, signaling a complete shutdown in the country and disconnection from the global Internet.",
      "published_ts": 1768262400,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.dataengineeringweekly.com/p/data-engineering-weekly-252",
      "title": "Data Engineering Weekly #252",
      "summary": "The Weekly Data Engineering Newsletter",
      "published_ts": 1768185484,
      "source_name": "Data Engineering Weekly",
      "content_type": "technical"
    }
  ],
  "news_general": [],
  "python_analytics": [],
  "warehouses_engines": [
    {
      "url": "https://aws.amazon.com/blogs/big-data/unlock-granular-resource-control-with-queue-based-qmr-in-amazon-redshift-serverless/",
      "title": "Unlock granular resource control with queue-based QMR in Amazon Redshift Serverless",
      "summary": "With Amazon Redshift Serverless queue-based Query Monitoring Rules (QMR), administrators can define workload-aware thresholds and automated actions at the queue level‚Äîa significant improvement over previous workgroup-level monitoring. You can create dedicated queues for distinct workloads such as BI reporting, ad hoc analysis, or data engineering, then apply queue-specific rules to automatically abort, log, or restrict queries that exceed execution-time or resource-consumption limits. By isolating workloads and enforcing targeted controls, this approach protects mission-critical queries, improves performance predictability, and prevents resource monopolization‚Äîall while maintaining the flexibility of a serverless experience. In this post, we discuss how you can implement your workloads with query queues in Redshift Serverless.",
      "published_ts": 1768494587,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/building-your-ai-skillset-accelerate-your-career-databricks-certifications",
      "title": "Building your AI skillset: Accelerate your career with Databricks Certifications",
      "summary": "The data and AI landscape is moving at a breakneck pace. As organizations shift from...",
      "published_ts": 1768493767,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/algonomy-databricks-built-partnership-retailai",
      "title": "Algonomy + Databricks Built On Partnership for RetailAI",
      "summary": "Algonomy is a global leader in retail-centric marketing and planning solutions with...",
      "published_ts": 1768416300,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/open-sourcing-dicer-databricks-auto-sharder",
      "title": "Open Sourcing Dicer: Databricks‚Äô Auto-Sharder",
      "summary": "1. AnnouncementToday, we are excited to announce the open sourcing of one of our...",
      "published_ts": 1768333500,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://vutr.substack.com/p/why-single-node-engine-like-duckdb",
      "title": "Why single-node engines like DuckDB and Polars are getting a lot of attention?",
      "summary": "From cluster-based engines like MapReduce or Spark to the claim \"Big Data is dead\"",
      "published_ts": 1768281308,
      "source_name": "VuTrinh ¬∑ Data Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/navigating-architectural-choices-for-a-lakehouse-using-amazon-sagemaker/",
      "title": "Navigating architectural choices for a lakehouse using Amazon SageMaker",
      "summary": "Over time, several distinct lakehouse approaches have emerged. In this post, we show you how to evaluate and choose the right lakehouse pattern for your needs. A lakehouse architecture isn‚Äôt about choosing between a data lake and a data warehouse. Instead, it‚Äôs an approach to interoperability where both frameworks coexist and serve different purposes within a unified data architecture. By understanding fundamental storage patterns, implementing effective catalog strategies, and using native storage capabilities, you can build scalable, high-performance data architectures that support both your current analytics needs and future innovation.",
      "published_ts": 1768250787,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    }
  ]
}