{
  "ai_data_engineering": [
    {
      "url": "https://engineering.salesforce.com/4x-faster-how-ai-assisted-development-accelerated-building-new-sql-dialects-for-zero-copy-connectors/",
      "title": "4x Faster: How AI-Assisted Development Accelerated Building New SQL Dialects for Zero Copy Connectors",
      "summary": "by Per Fuchs, Steven Lockhart, and Gautam Varma. In our Engineering Energizers Q&A series, we highlight the engineering minds driving innovation across Salesforce. Today, we meet Per Fuchs, a senior software engineer with the Hyper Database team. In close collaboration with others, his team empowers Data 360 to execute analytical queries directly on 100+ external [‚Ä¶] The post 4x Faster: How AI-Assisted Development Accelerated Building New SQL Dialects for Zero Copy Connectors appeared first on Salesforce Engineering Blog .",
      "published_ts": 1765574754,
      "source_name": "Salesforce Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/chatgpt-langchain",
      "title": "Build a GitHub Support Bot with GPT3",
      "summary": "Create a GitHub support bot using GPT3, LangChain, and Python to automate answers and improve developer UX.",
      "published_ts": 1765554388,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/deepdive-recap-dagster-modal",
      "title": "ML Compute with Dagster + Modal",
      "summary": "Use Dagster and Modal to build ML pipelines that scale reliably from local experiments to cloud training with full observability.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://juhache.substack.com/p/building-a-boring-chat-bi-agent",
      "title": "Building a (boring) chat-BI Agent",
      "summary": "Ju Data Engineering Weekly - Ep 91",
      "published_ts": 1765531834,
      "source_name": "Julien Hurault ¬∑ Ju Data Engineering",
      "content_type": "rex"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/announcing-openai-snowflake-cortex-ai",
      "title": "Announcing OpenAI GPT-5.2 on Snowflake Cortex AI",
      "summary": "OpenAI now on Snowflake Cortex AI, enabling secure access to OpenAI‚Äôs latest models via LLM functions and REST APIs.",
      "published_ts": 1765479565,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://azure.microsoft.com/en-us/blog/introducing-gpt-5-2-in-microsoft-foundry-the-new-standard-for-enterprise-ai/",
      "title": "Introducing GPT-5.2 in Microsoft Foundry: The new standard for enterprise AI",
      "summary": "Discover GPT‚Äë5.2 in Microsoft Foundry‚Äîthe next standard for enterprise AI. Learn how advanced reasoning, agentic execution, and compliance-ready features empower developers and technical leaders. The post Introducing GPT-5.2 in Microsoft Foundry: The new standard for enterprise AI appeared first on Microsoft Azure Blog .",
      "published_ts": 1765477085,
      "source_name": "Azure Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/openai-gpt-52-and-responses-api-databricks-build-trusted-data-aware-agentic-systems",
      "title": "OpenAI GPT-5.2 and Responses API on Databricks: Build Trusted, Data-Aware Agentic Systems",
      "summary": "OpenAI GPT-5.2 is now available on Databricks, giving teams day one access to OpenAI‚Äôs...",
      "published_ts": 1765476025,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://huggingface.co/blog/ggml-org/model-management-in-llamacpp",
      "title": "New in llama.cpp: Model Management",
      "summary": "New in llama.cpp: Model Management\nllama.cpp server\nnow ships with\nrouter mode\n, which lets you dynamically load, unload, and switch between multiple models without restarting.\nReminder: llama.cpp server is a lightweight, OpenAI-compatible HTTP server for running LLMs locally.\nThis feature was a pop",
      "published_ts": 1765468064,
      "source_name": "Hugging Face Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.ovhcloud.com/postgresql-and-ai-the-pragmatic-path-to-smarter-data/",
      "title": "PostgreSQL and AI: The pragmatic path to smarter data",
      "summary": "Beyond the buzz: Building AI on solid foundations Artificial intelligence has quickly become the cornerstone of digital innovation. From text generation to image recognition and intelligent automation, AI is redefining how organisations extract value from data. At OVHcloud, we believe this transformation shouldn‚Äôt only belong to the tech elite ‚Äì it should be open, accessible, [‚Ä¶]",
      "published_ts": 1765465860,
      "source_name": "OVHcloud Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/ias-and-personas--vers-un-nouvel-extreme-persona",
      "title": "IAs  and  Personas : vers un nouvel extr√™me persona ?",
      "summary": "√Ä l‚Äôheure o√π l‚ÄôIA transforme nos usages, cet article explore son r√¥le dans nos m√©thodes de conception, ainsi que son potentiel d‚Äôinclusion et d‚Äôaccessibilit√©. Il invite √† consid√©rer les IA comme de nouveaux utilisateurs dans nos d√©marches de design et de d√©veloppement.",
      "published_ts": 1765459030,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://stripe.com/blog/agentic-commerce-suite",
      "title": "Introducing the Agentic Commerce Suite: A complete solution for selling on AI agents",
      "summary": "Today, we‚Äôre introducing the Agentic Commerce Suite: a new solution that gets your business agent-ready. It enables you to sell on AI agents more easily by making your products discoverable, simplifying your checkout, and allowing you to accept agentic payments via a single integration.",
      "published_ts": 1765411200,
      "source_name": "Stripe Engineering Blog",
      "content_type": "technical"
    },
    {
      "url": "https://airbyte.com/blog/layers-of-agentic-data-infrastructure",
      "title": "The 9 Layers of Agentic Data Infrastructure | Airbyte",
      "summary": "Discover the 9 essential layers of agentic data infrastructure‚Äîan integrated framework that empowers AI agents to autonomously collect, process, analyze, and act on data across modern ecosystems.",
      "published_ts": 1765411200,
      "source_name": "Airbyte Blog",
      "content_type": "technical"
    },
    {
      "url": "https://huggingface.co/blog/hf-skills-training-codex",
      "title": "Codex is Open Sourcing AI models",
      "summary": "Codex is Open Sourcing AI models\nBuilding on our work to get\nClaude Code\nto train open source models, we are now getting\nCodex\nto go further. We gave Codex access to the\nHugging Face Skills\nrepository, which contains skills for Machine Learning and AI tasks such as training or evaluating models. Wit",
      "published_ts": 1765411200,
      "source_name": "Hugging Face Blog",
      "content_type": "technical"
    },
    {
      "url": "https://medium.com/pinterest-engineering/llm-powered-relevance-assessment-for-pinterest-search-b846489e358d?source=rss----4c5a5f6279b6---4",
      "title": "LLM-Powered Relevance Assessment for Pinterest Search",
      "summary": "Han Wang | Machine Learning Engineer; Alex Whitworth | Staff Data Scientist; Pak Ming Cheung | Sr. Staff Machine Learning Engineer; Zhenjie Zhang | Sr. Staff Machine Learning¬†Engineer Introduction Search relevance measures how well search results align with a user‚Äôs search query. For personalized search systems, it‚Äôs important to ensure that displayed content is pertinent to the user‚Äôs information needs, rather than over-relying on the user‚Äôs past engagement. At Pinterest Search, we track whole-page relevance in online A/B experiments to evaluate new ranking models and ensure a high-quality user experience. Relevance measurement typically relies on human annotations, but is limited by the low availability of human labels and the high marginal cost of generating them. This led to measurement designs and sample sizes that could only detect significant topline metric movements, but were insufficient to measure heterogeneous treatment effects or small topline¬†effects. In this blog, we present our methodology at Pinterest Search to scale the labeling capabilities with LLMs and address these bottlenecks. We fine-tune open-source LLMs on relevance prediction tasks using human-annotated labels, then utilize the fine-tuned LLMs to evaluate the ranking results across experimental groups in online A/B experiments. This approach not only significantly reduces labeling costs and improves evaluation efficiency, but also unlocks opportunities to further improve metric quality by scaling up the query sets and refining the sampling¬†design. Methodology At Pinterest, we measure the semantic relevance between queries and Pins using a 5-level guideline: Highly Relevant (L5), Relevant (L4), Marginally Relevant (L3), Irrelevant (L2), and Highly Irrelevant (L1). We use this guideline to measure the whole-page relevance for our search¬†system. Fine-tuned LLMs as Relevance Model We use a cross-encoder model architecture to predict a Pin‚Äôs relevance to a given query, as illustrated in Figure 1. We fine-tune open-source LLMs on human-annotated data to optimize their performance on relevance prediction task. To support search queries and Pins across multiple languages, we leveraged multilingual LLMs to take advantage of their cross-lingual transfer capabilities. We formalize the relevance prediction as a multiclass classification problem based on the 5-scale relevance guideline, minimizing the point-wise cross-entropy loss during training. Figure 1 : The cross-encoder architecture for LLM-based search relevance model. Take the encoder language models (e.g., BERT -based models) for illustration. To effectively represent each Pin for relevance prediction, we leverage a comprehensive set of textual features, including Pin titles and descriptions, BLIP image captions, linked page titles and descriptions, user-curated board titles where the Pin has been saved, and highly-engaged query tokens associated with the Pin. These features together form a robust text representation crucial for accurate relevance assessment. We experiment with various language models, including multilingual BERT-base , T5-base , mDeBERTa-V3-base , XLM-RoBERTa-large , and Llama-3‚Äì8B . The comparative performance of various LLMs and ablation studies on Pin text features can be found in a previous blog . We then use this fine-tuned search relevance model to generate 5-dimensional relevance scores and use the label corresponding to the highest score (argmax) for relevance assessment. Stratified Sampling¬†Design LLM labeling significantly reduces relevance labeling costs as well as labeling time, which enables much larger sampling designs. Therefore, we propose a stratified query sampling design that enables measurement of heterogeneous treatment effects and reduces minimum detectable effects (MDEs) by an order of magnitude. Stratification plays an important role in sampling-based measurement. First, stratification ensures the sample population is representative of the whole population. In addition, if the strata are chosen such that each stratum is relatively homogeneous, variance reduction can be achieved. We adopted the in-house query-to-interest model based on DistilBERT combined with the popularity segment, a measure of how many users issue each specific query, to determine the strata. Prior to LLM labeling, stratified query sampling with human annotations was impractical, as it required a large number of queries to adequately represent each fine-grained stratum. We evaluate the impact of these changes on experiment sensitivity by evaluating the MDE for our experimentation system. The MDE is the smallest change in a metric that an experiment can reliably detect given the sample size, statistical power (Œ≤= 0.8), and significance level (Œ±=0.05) chosen for the test. It can be derived as¬†below Since the typical experiment for most online platforms has a small effect, achieving small MDEs is a critical factor in team velocity and shipping new features to our users. Before the introduction of LLM labeling, relevance measurement had large MDEs (e.g. 1.3%-1.5%). These large MDEs were primarily the result of the constraints on our sampling designs imposed by the high cost and time consumption of human labeling. The introduction of LLM labeling enabled us to redesign our sampling approach. We increased our sample sizes, moved from simple random sampling (SRS) to stratified sampling, and now use a stratified sampling estimator. Optimal allocation is used to allocate sample units to strata. These changes enabled us to reduce our MDEs to ‚â§¬†0.25%. The MDE reduction can be expressed in terms of reduction in variance and increased sample size. We present these results in Table 1. The vast majority of reduction comes from the variance reduction due to stratification. This is consistent with prior findings at Pinterest that most variance in relevance occurs across queries. Previous work has found substantial variation in relevance due to query interest and query popularity. Table 1: Improvement in metric sensitivity (MDE). Relevance Measurement with¬†LLMs To measure the relevance impact of an A/B experiment on search ranking, we take a stratified sample of paired search queries from control and treatment experiment groups, ensuring that the sample is representative of overall user usage. The use of paired samples blocks between-query differences, which is an important source of variation in experiment measurement. For each query in our paired sample, we retain the top K search results and generate LLM-based relevance labels. We then compute sDCG@K for each query and aggregate query-level metrics to derive topline experiment metrics. The sDCG@K metric is a variant of the standard nDCG@K, where we assume an infinite supply of highly relevant (L5) documents for sDCG@K computation (see Equation 2). We use K=25 throughout our evaluation. Lastly, we calculate heterogeneous effects by query popularity and query interest (e.g. beauty, women‚Äôs fashion, art, etc), utilizing a Benjamini-Hochberg procedure to control the false discovery rate. The LLM-based relevance measurement procedure at Pinterest Search is illustrated in Figure¬†2. Figure 2 : Components of LLM-based relevance measurement at Pinterest Search. Results We use XLM-RoBERTa-large as the LLM backbone for our relevance model. The model is lightweight yet delivers high-quality predictions. Inference runs on a single A10G GPU, allowing us to label 150,000 rows within 30 minutes. While the Llama-3‚Äì8B model offers slight improvement in accuracy, its inference time and cost increase 6 times. Therefore, we select XLM-RoBERTa-large as it offers a good balance between prediction quality and inference efficiency. The validation results are presented below. Alignment with Human¬†Labels We conducted a rigorous validation of the metrics derived from LLM labeling. On Pin-level evaluation, LLM-generated labels and human labels yield an exact match rate of 73.7%, with 91.7% of ratings deviating at most by 1 point. These results underscore the high alignment between the relevance labels produced by LLMs and those from human annotators. To measure alignment between LLMs and human labels, we also compute and report the rank-based correlation Kendall‚Äôs œÑ and Spearman‚Äôs œÅ to assess the correlation between the two rankings at query-level sDCG@K metric. To understand the performance on queries with different popularity, we also categorize the queries into 4 popularity segments based on search volume: head, torso, tail, and single. The results are summarized in Table 2. We achieve Kendall‚Äôs œÑ>0.5 and Spearman‚Äôs œÅ>0.65 for all query popularity segments, indicating a strong alignment across all segments. In addition to Kendall‚Äôs œÑ and Spearman‚Äôs œÅ, we also validate the query-level sDCG@K error distribution. Here, the error refers to the difference between the sDCG@K metric derived from LLM labels and human labels. According to Table 2, the overall error is below 0.01, with the 10-th and 90-th percentiles falling within the range of [-0.1, 0.1]. We also visualize the error distribution in Figure 3. The error is tightly centered around 0, indicating its negligible magnitude and that the average bias will approach 0 as the size of the query set¬†grows. For experimental evaluation, we need to calculate the metric difference between the control and treatment groups. Therefore, we also validate how well these metric differences align in paired comparison. As shown on the right-hand side of Figure 3, the errors in paired differences are even more centered around 0 with lighter tails, indicating that LLM-based labeling provides highly reliable estimates of paired differences for A/B experiment assessment. Table 2 : Query-level LLM vs human labels alignment for different query segments in US market relevance evaluation. Figure 3 : Query-level bias distribution for single group (left) and paired differences (right) in US market relevance evaluation. Performance on Non-English Queries We fine-tuned multilingual LLMs on human-annotated data, with the majority of query-Pin pairs in English. As a result, careful validation is required for non-English queries to extend LLM-based relevance assessment to those queries. For this analysis, we focus on France (FR) and Germany (DE)¬†markets. The query-level metric alignment is summarized in Table 3. The overall Kendall‚Äôs œÑ and Spearman‚Äôs œÅ are approximately 0.47 and 0.61, respectively. While these rank-based correlations are lower than those observed for English queries, they are still considered strong according to existing literature. The distribution of query-level metric errors is shown in Figure 4. Similar to the results of the US market, the errors are tightly concentrated around 0 for both countries, indicating a low average bias, with an even smaller bias for paired differences. These results provide confidence that the LLM-based relevance assessment is also suitable for non-English queries. Expanding relevance evaluation to countries beyond the US leads to further reductions in labeling costs and improvements in evaluation efficiency. Table 3 : Query-level LLM vs human labels alignment for different query segments in France (FR) and Germany (DE) markets relevance evaluation. Figure 4 : Query-level bias distribution for single group (left) and paired differences (right) in France (top) and Germany (bottom) markets relevance evaluation. Summary In this work, we explore the use of LLM-based relevance labeling to generate query-level relevance metrics for online A/B experiments evaluation. We demonstrate that fine-tuned LLMs achieve low bias on query-level ùë†ùê∑ùê∂ùê∫@ùêæ metrics and paired differences. Transition to LLM-based relevance assessment enables us to scale up the evaluation query set and redesign the sampling strategy to improve the quality of relevance metrics for online experiment evaluation. We have successfully deployed the LLM-based relevance assessment at Pinterest Search, significantly reducing the manual annotation costs and turnaround time, while achieving an order of magnitude reduction in MDEs for improved detection of relevance shifts. For more details, please refer to our full¬†paper . Future Work We will explore using Visual Language Models (VLMs) to better leverage raw images for relevance prediction. Additionally, the observed performance gap with non-English queries highlights opportunities to further improve the multilingual capabilities of our LLM-based relevance model. We leave it for future¬†work. Acknowledgement Search: Maggie Yang, Mukuntha Narayanan, Jinfeng Rao, Krishna Kamath, Kurchi Subhra¬†Hazra Relevance Measurements Tooling: Maria Alejandra Morales Gutierrez (former), Miguel Madera, Pedro Sanchez, Jorge Amigon, Francisco Navarrete LLM-Powered Relevance Assessment for Pinterest Search was originally published in Pinterest Engineering Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "published_ts": 1765396932,
      "source_name": "Pinterest Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://blog.langchain.com/debugging-deep-agents-with-langsmith/",
      "title": "Debugging Deep Agents with LangSmith",
      "summary": "Debugging is the process of finding and fixing errors. This is a critical step in software engineering, and even more critical in agent engineering . One of the key capabilities of LangSmith is tooling to debug LLM applications. Today we are doubling down on solving that problem for the new wave",
      "published_ts": 1765386499,
      "source_name": "LangChain Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.langchain.com/introducing-polly-your-ai-agent-engineer/",
      "title": "Introducing Polly: Your AI Agent Engineer",
      "summary": "Today, we're launching Polly: an AI-powered assistant built directly into LangSmith that helps you debug, analyze, and improve your agents. And yes, we see the irony: we're adding an agent to a product for building agents. We've spent a lot of time working with",
      "published_ts": 1765386468,
      "source_name": "LangChain Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/faire-confiance--reinventer-l'experience-utilisateur-a-l'ere-l'ia",
      "title": "Faire confiance : R√©inventer l'exp√©rience utilisateur √† l'√®re l‚ÄôIA",
      "summary": "√Ä l‚Äô√®re o√π l‚ÄôIA transforme la mani√®re d‚Äôappr√©hender les produits en instaurant une vraie relation homme‚Äìmachine, cet article montre pourquoi cr√©er une relation de confiance devient indispensable, et propose une grille de lecture et des leviers concrets pour concevoir et mesurer la confiance.",
      "published_ts": 1765381270,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://www.dataiku.com/stories/blog/wisr",
      "title": "How Wisr Uses AI Agents for Faster, Value-Driven Lending Decisions",
      "summary": "Wisr uses Dataiku-powered AI agents to classify cases, surface relevant precedent, and give BDMs clearer, faster, and more consistent value-driven decisions. 40%-50% reduction in manual review time for exception cases 20-30 hours saved per month for senior assessors",
      "published_ts": 1765380352,
      "source_name": "Dataiku Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/introducing-databricks-genai-partner-accelerators-data-engineering-migration",
      "title": "Introducing Databricks GenAI Partner Accelerators for Data Engineering & Migration",
      "summary": "Enterprises face increasing pressure to modernize their data stacks. Teams need to...",
      "published_ts": 1765317600,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://huggingface.co/blog/ServiceNow-AI/apriel-1p6-15b-thinker",
      "title": "Apriel-1.6-15b-Thinker: Cost-efficient Frontier Multimodal Performance",
      "summary": "Apriel-1.6-15b-Thinker: Cost-efficient Frontier Multimodal Performance\nWe release\nApriel-1.6-15b-Thinker\n, a 15-billion parameter multimodal reasoning model in ServiceNow‚Äôs Apriel SLM series which achieves SOTA performance against models 10 times it's size. Apriel-1.6 builds on top of\nApriel-1.5-15b",
      "published_ts": 1765310816,
      "source_name": "Hugging Face Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/training-llms",
      "title": "Train LLMs with Langchain and Dagster",
      "summary": "Combine Airbyte, Langchain, and Dagster to build robust, cost-efficient pipelines that support large language model training and iteration at scale.",
      "published_ts": 1765307461,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://seattledataguy.substack.com/p/how-i-run-system-design-interviews",
      "title": "How I Run System Design Interviews for Data Engineers",
      "summary": "Why System Design Still Matters",
      "published_ts": 1765302841,
      "source_name": "Seattle Data Guy",
      "content_type": "rex"
    },
    {
      "url": "https://blog.langchain.com/agent-engineering-a-new-discipline/",
      "title": "Agent Engineering: A New Discipline",
      "summary": "If you‚Äôve built an agent, you know that the delta between ‚Äúit works on my machine‚Äù and ‚Äúit works in production‚Äù can be huge. Traditional software assumes you mostly know the inputs and can define the outputs. Agents give you neither: users can say",
      "published_ts": 1765297235,
      "source_name": "LangChain Blog",
      "content_type": "technical"
    },
    {
      "url": "https://engineering.atspotify.com/2025/12/feedback-loops-background-coding-agents-part-3/",
      "title": "Background Coding Agents: Predictable Results Through Strong Feedback Loops (Part 3)",
      "summary": "The system we built to ensure our AI agents produce predictable, trustworthy code. The post Background Coding Agents: Predictable Results Through Strong Feedback Loops (Part 3) appeared first on Spotify Engineering .",
      "published_ts": 1765293259,
      "source_name": "Spotify Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.dataiku.com/stories/blog/stop-building-rag-chatbots",
      "title": "Why You Should Stop Building RAG Chatbots From Scratch",
      "summary": "Retrieval-augmented generation (RAG) chatbots fuse large language models (LLMs) with your actual data, so answers are smart and grounded. Instead of guessing, they retrieve real context, docs, logs, FAQs, and generate responses backed by facts with fewer hallucinations, faster iteration, and AI that behaves less like an experiment and more like a product.",
      "published_ts": 1765288980,
      "source_name": "Dataiku Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/powering-growth-how-data-and-ai-are-rewiring-productivity-banking-and-payments",
      "title": "Powering Growth: How Data and AI Are Rewiring Productivity in Banking and Payments",
      "summary": "Banks are being challenged to do more with less. What‚Äôs at stake?Today‚Äôs banks are...",
      "published_ts": 1765239300,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://airbyte.com/blog/ephemeral-testing-with-generative-ai",
      "title": "Unlocking Ephemeral Testing with Generative AI: Part One | Airbyte",
      "summary": "Unlock ephemeral testing with generative AI in Part One: learn how on-demand environments cut flakiness, speed CI, and improve reliability with practical strategies, workflows, and real-world examples.",
      "published_ts": 1765238400,
      "source_name": "Airbyte Blog",
      "content_type": "technical"
    },
    {
      "url": "https://engineering.salesforce.com/how-ai-driven-testing-enabled-sub-second-latency-for-agentforce-voice/",
      "title": "How AI-Powered Testing Enabled Sub-Second Latency for Agentforce Voice",
      "summary": "In our Engineering Energizers Q&A series, we highlight the engineering minds driving innovation across Salesforce. Today, meet Angie Howard, Senior Manager of Software Engineering, who leads the team behind the Flash Reasoning Engine powering Agentforce Voice. This engine delivers natural, human-fast responses striving for sub-second Time to First Audio (TTFA) across a real-time voice pipeline. [‚Ä¶] The post How AI-Powered Testing Enabled Sub-Second Latency for Agentforce Voice appeared first on Salesforce Engineering Blog .",
      "published_ts": 1765237906,
      "source_name": "Salesforce Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://medium.com/pinterest-engineering/how-pinterest-built-a-real-time-radar-for-violative-content-using-ai-d5a108e02ac2?source=rss----4c5a5f6279b6---4",
      "title": "How Pinterest Built a Real‚ÄëTime Radar for Violative Content using AI",
      "summary": "Faisal Farooq | Sr. Director Trust Engineering; Aravindh Manickavasagam | Staff Technical Program Manager; Attila Dobi | Sr. Staff Data Scientist People come to Pinterest to find ideas they feel good about. To keep that experience safe, we need to know not just what gets reported, but what people actually saw. That‚Äôs what we call prevalence: the percentage of all views, on a given day, that went to content that violates a policy. Prevalence complements reporting by covering its blind spots, helping us spot under‚Äëreported harms, track trends, and tell whether interventions work. Why Prevalence Matters Historically, our Trust & Safety teams leveraged multiple indicators to understand the extent of policy violating content on the platform. ‚ÄúIn-app user reports‚Äù confirmed by human reviewers served as a key indicator alongside other measures of potential harm. While user reports are invaluable because they come directly from our community, a report‚Äëonly metric is incomplete. What a Reports‚Äëonly View Can‚Äôt Tell¬†Us Some harms are under‚Äëreported (for example, self‚Äëharm) due to stigma or sensitivity. Users who seek harmful content don‚Äôt report what they‚Äôre¬†seeking. Rare categories generate few reports, so we lack statistical power to track progress or detect emerging¬†threats. Scaling report handling with human review adds cost and¬†latency. Prevalence fills those gaps. Instead of waiting for reports, we measure what people actually saw each day by sampling based on user impressions and labeling them at scale. This gives us a stable, statistically powered view across a broader spectrum of policies, independent of enforcement thresholds, so that we can monitor risks, set goals, track progress, and act¬†sooner. Addressing Historical Challenges with Prevalence Measurement Historically, measuring prevalence was expensive because it relied on human review. We could only run large, platform‚Äërepresentative studies infrequently (roughly every six months and not always on a fixed cadence), so pre/post comparisons after interventions were slow and often hard to trust. Secondly, human review can oftentimes be unstable. In order to reach reliable and stable decisions, we required at least two independent reviewers per item, plus adjudication on disagreements, which further increased cost and¬†latency. To address these cost and latency constraints while enabling more frequent and reliable measurement, we built an AI-assisted workflow that allows us to focus on measuring the daily user experience. What We¬†Measure We estimate how often violating content is seen vs. how much is posted on the platform because ‚Äúimpact comes from exposure.‚Äù A single violating Pin might be posted once but seen a million times, or not seen at all. Measuring the share of views that went to policy‚Äëviolating content better reflects what people actually experienced on Pinterest. We report this daily, with 95% confidence intervals to show precision. Metric : prevalence on a given day is: ( # views of content that violates a given policy ) / ( # total¬†views ). For example, if 10 out of 100,000 views in a sample are policy‚Äëviolating, the estimated prevalence is 0.01% for that policy area that¬†day. Policies and¬†segments The measurement can be further broken down so that the team can act on¬†it. Policy area, e.g. Adult Content, Self‚Äëharm, Graphic Violence. Sub‚Äëpolicy, e.g. within Adult Content we separate nudity from explicit sexual¬†content. Surface, e.g. Homefeed vs. Search vs. Related¬†Pins. Other segments, where appropriate (such as content age, geography or user age¬†buckets) Figure 1: Illustrative Example [not a real production chart] ‚Äî‚ÄäMonthly average of adult content prevalence throughout 2024 and 2025. The tool emoji (üõ†Ô∏è) highlights enforcement updates. The metric is responsive to product interventions. Methods at a¬†Glance Sampling We sample images from the daily user impressions stream, using risk scores from our production enforcement models to improve sampling efficiency, not as labels or inclusion criteria (the same models that remove policy‚Äëviolating content) . What if some content is missing scores? As a failsafe, missing scores are imputed with the day‚Äôs median so fresh content stays in¬†frame. Inclusion probabilities: For each content unit i we assign a sample probability Equation 1: where by default Œ≥ = 1, ŒΩ = 1 but both are tunable. Setting Œ≥ = 0 yields impression weighted sampling; Œ≥ = ŒΩ = 0 yields random sampling. The corresponding, normalized sampling probably is œÄ·µ¢¬†‚àù w ·µ¢ Implementation detail : We implement this with weighted reservoir sampling using an index defined¬†by: Equation 2: w ·µ¢ is the sample probability for content_i from equation 1. U·µ¢ represents a uniform random number from (0,1]. The parameters Œ≥ , ŒΩ are tunable, set to¬†1. Why ML-assisted sampling, and why it stays unbiased: ‚Ä¢ Scores as a lens, not the ruler: Production risk scores focus label budget on high‚Äërisk, high‚Äëexposure candidates; the estimator then re‚Äëweights to remove that lensing so the prevalence statistic reflects impressions, not the model‚Äôs threshold. This decouples measurement from enforcement. ‚Ä¢ Design Consistent Estimator: We use inverse‚Äëprobability weighting to keep daily impression‚Äëweighted prevalence design‚Äëconsistent and comparable over time. In practice we use the Hansen‚ÄìHurwitz ratio for PPS‚Äëwith‚Äëreplacement and the Horvitz‚ÄìThompson ratio for without‚Äëreplacement, which remain unbiased even if thresholds or calibration drift. Labeling at¬†Scale We bulk‚Äëlabel the sample with a multimodal LLM (vision + text) using prompts reviewed by policy subject matter experts (SMEs). The system logs decisions, brief rationales, and full lineage (policy version, prompt, and model IDs) for auditability. Calibration and de-biasing are critical to maintaining measurement accuracy at scale. We employ human validation of strategically sampled subsets immediately after launch as part of post-launch metric evaluation. These calibration samples are designed to capture edge cases and potential AI blind spots that could introduce systematic bias into our prevalence estimates. Before launching to production the LLM must meet a minimum decision quality requirement relative to human review. Additionally, LLM + prompt quality is periodically checked against Subject Matter Expert‚Äëlabeled gold sets (ground truth) to detect model drift and ensure the labeler/classifier remains accurate and aligned with current violations policy. This continuous monitoring process allows us to maintain measurement conviction as content patterns and policy interpretations evolve. LLM‚Äëassisted labeling lets us run large, daily probability samples across more policy areas at a fraction of the latency (15x faster) and orders of magnitude lower operational cost than a human‚Äëonly workflow at comparable decision quality-while also preserving statistical validity and governance. System Overview Figure 2: Illustration of the prevalence measurement workflow. Implementation Notes Inputs: Engagement at the entity √ó day level (e.g., impressions, Pin clicks, hides, reports) plus the latest production risk scores, used only as auxiliary signals. Missing scores are imputed with the day‚Äôs¬†median. Sampling: We use a weighted reservoir sampler that gives more chances to items with higher impressions and higher risk scores, while still preserving an unbiased estimate when we reweight the sample [ 1 ]. This emulates probability proportional‚Äëto‚Äësize with replacement (PPSWR) and yields unbiased estimators when paired with the right weights [ 2 ]. A toggle also supports pure random sampling for validation studies. Labeling: The LLM returns any policy‚Äëdefined label hierarchy (e.g., {safe, not_safe, unsure}). The workflow records token usage and per‚Äërun cost for budgeting and is model‚Äëagnostic for future flexibility. Figure 3: Examples of how the LLM labels an image according to the Adult Content¬†policy. Estimation: We compute overall prevalence and pivots, persist estimates, weights, and labels to production stores, and write diagnostics/lineage for audits. The dashboard surfaces the point estimate, 95% CI, CI width, and effective sample¬†size. Dashboard and¬†Alerting Cards: Daily prevalence with 95% CI, sample positive rate (for monitoring sampling efficiency), auxiliary score distributions for context, and run health/lineage (prompt/model/taxonomy/metric versions). Pivots : The dashboard owners can slice prevalence by policy area, surface (Homefeed, Search, etc.), and selected sub‚Äëpolicies. Validation: A random subsample of labels routes to an internal human validation queue for continual checks of the AI‚Äôs decision quality; a config switch enables pure random sampling to sanity‚Äëcheck assumptions. Impact AI-assisted prevalence measurement has transformed how we understand and respond to platform safety challenges: Proactive Risk Detection and Response: We now have continuous measurement without historical blind spots. Dramatically faster labeling turnaround enables real-time monitoring, providing clearer understanding of platform risk and user experience. This leads to faster root cause analysis when issues emerge and more proactive identification of emerging trends before they scale. ‚Ä¢ Faster Product Iteration and Data Driven Policy: Prevalence measurement provides immediate insight into how product launches impact platform trust and safety, enabling us to course-correct quickly and build more effective enforcements and interventions. The system also creates a valuable feedback loop for policy development and prompt tuning, helping us understand how clear and enforceable our policies are in practice. ‚Ä¢ Strategic Decision Making Beyond Monitoring: ‚Äî‚ÄäBenchmarking and goal setting : establishing measurable targets for platform health and tracking progress ‚Äî Cross-team alignment : providing shared metrics that unite product, policy, and enforcement teams around common objectives ‚Äî Data-driven resource allocation: directing enforcement efforts where they‚Äôll have the greatest impact ‚Äî Precise intervention measurement: with reliable prevalence baselines established, we can now A/B test enforcement strategies with statistical confidence to optimize policy interventions based on measurable outcomes Constraints and Trade‚Äëoffs Rare categories can have wide daily CIs: we adapt Œ≥ [Equation 1], stratify, or pool to weekly as needed; the dashboard exposes CI width so owners can budget¬†labels. Policy/prompt drift: Prompt and data versioning + selective time period based label backfills keep the series interpretable. LLM decision quality stability: LLM decision quality stability is required for metric conviction. We regularly run random‚Äësampling validations and monitor LLM outputs to detect and address potential decision quality¬†drift. Cost guardrails: Token usage and per‚Äërun cost per model/metric variant are tracked and periodically evaluated for cost efficiency. Future Focus Pivots : Expand pivoting ability to viewer country, age,¬†etc. Cost optimization: ‚Äî‚ÄäMulti step LLM labeling process : A first layer decides if labels are safe/unsafe using a short prompt. The second layer labels the unsafe items against a longer, comprehensive policy-prompt. ‚Äî LLM Fine Tuning: LLM‚Äôs fine tuned with SME labeled data have yielded improved performance during evaluations. Human-in-the-loop denoising/debiasing : Create an active denoising/debiasing system leveraging human review and SME labeling in the loop (prompt tuning, fine‚Äëtuning, and label correction). The objective is to minimize LLM-human bias and reduce variance introduced by suboptimal decision¬†quality. Further generalizing the pipeline for company‚Äëwide measurement applications, further refining metric versioning and validation, developing prevalence based A/B testing guardrails. Acknowledgements Standing up a Trust and Safety prevalence radar has required sustained cross‚Äëfunctional work across Trust & Safety teams including engineering, product and operations. Here‚Äôs an incomplete list of folks and teams who helped us design, ship, and operationalize daily prevalence: Data Science: Xiaohan Yang, Zehao Xu, Yuqi Tian, Minli Zang, Huan Yu, Robert Paine, Kevin O‚ÄôSullivan, Wenjun Wang, Benjamin¬†Thompson Risk Intelligence: Jenny Bi, Mairead O‚ÄôDoherty, Antons Tocilins-Ruberts Product: Monica Bhide, Prachi Wadekar, Dan¬†Towne TPM: Nayan Patel, Helene Labriet-Gross Operations: Abby Beckman, Jessica Flora, Aaron Stein-Chester, Carol¬†Davis Policy: Stanley Washington, Francesca Anzola Engineering: Vikram Deshpande, Ahmed Fayez, Naman¬†Makhija Leadership: Faisal Farooq, Andrey Gusev, Sriram Subramanian References: [Reservoir sampling trick] Weighted Random Sampling (2005; Efraimidis, Spirakis) [Hansen Hurwitiz 1943] On the theory of sampling from finite populations.pdf How Pinterest Built a Real‚ÄëTime Radar for Violative Content using AI was originally published in Pinterest Engineering Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "published_ts": 1765213377,
      "source_name": "Pinterest Engineering",
      "content_type": "rex"
    }
  ],
  "cloud_infra_observability": [
    {
      "url": "https://aws.amazon.com/blogs/big-data/how-bayer-transforms-pharma-rd-with-a-cloud-based-data-science-ecosystem-using-amazon-sagemaker/",
      "title": "How Bayer transforms Pharma R&D with a cloud-based data science ecosystem using Amazon SageMaker",
      "summary": "In this post, we discuss how Bayer AG used the next generation of Amazon SageMaker to build a cloud-based Pharma R&D Data Science Ecosystem (DSE) that unified data ingestion, storage, analytics, and AI/ML workflows.",
      "published_ts": 1765580785,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://blog.ovhcloud.com/industrial-excellence-meets-artificial-intelligence-behind-the-scenes-with-smart-datacenter/",
      "title": "Industrial Excellence meets Artificial Intelligence: Behind the Scenes with Smart Datacenter",
      "summary": "At OVHcloud, we are constantly looking for ways to improve our operations and reduce our impact on the environment. This has been a defining part of the company since 1999 and is a key part of our organisational DNA and our commercial model. We are very proud to present the new Smart Datacenter cooling system, [‚Ä¶]",
      "published_ts": 1765550142,
      "source_name": "OVHcloud Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.cloudflare.com/react2shell-rsc-vulnerabilities-exploitation-threat-brief/",
      "title": "React2Shell and related RSC vulnerabilities threat brief: early exploitation activity and threat actor techniques",
      "summary": "Early activity indicates that threat actors quickly integrated this vulnerability into their scanning and reconnaissance routines and targeted critical infrastructure including nuclear fuel, uranium and rare earth elements. We outline the tactics they appear to be using and how Cloudflare is protecting customers.",
      "published_ts": 1765470000,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://azure.microsoft.com/en-us/blog/azure-storage-innovations-unlocking-the-future-of-data/",
      "title": "Azure Storage innovations: Unlocking the future of data",
      "summary": "Whether you are improving the resilience of mission-critical workloads or modernizing legacy systems; Azure Storage has a solution for you. The post Azure Storage innovations: Unlocking the future of data appeared first on Microsoft Azure Blog .",
      "published_ts": 1765468800,
      "source_name": "Azure Blog",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/how-we-built-and-automated-our-new-japanese-gitlab-docs-site/",
      "title": "How we built and automated our new Japanese GitLab Docs site",
      "summary": "Today we are thrilled to announce the release of GitLab product documentation in Japanese at docs.gitlab.com/ja-jp . This major step marks our first move toward making GitLab's extensive documentation accessible to our users worldwide. The unique challenge of the Japanese market Japan represents one of the world's largest economies and is a critical market for enterprise software. However, it also presents a distinctive challenge: despite its technological sophistication and massive developer community, English proficiency remains a significant barrier for many users. Japan's developers and DevSecOps teams often face challenges with English-only documentation, as indicated by the country's ranking on the EF English Proficiency Index . This language barrier can significantly impact the speed of learning and ultimately influence the decision to evaluate, adopt, and champion a platform within Japanese organizations. We've heard directly from our Japanese customers and partners that English-only documentation wasn't merely an inconvenience, it was a barrier preventing them from getting the most out of GitLab. The impact rippled through every stage of the user journey: From initial evaluation where teams struggled to assess GitLab's capabilities, to daily operations where finding solutions took longer than necessary, to staying current with new features and best practices. In a market as competitive and mature as in Japan, this language barrier directly affected GitLab's market penetration. When Japanese companies evaluate enterprise software, the availability of comprehensive Japanese documentation signals long-term commitment to the market. It demonstrates that a provider isn't just making a token effort, but is genuinely invested in supporting Japanese users throughout their entire journey. To address this challenge and demonstrate our commitment to the Japanese market, we built localization infrastructure from the ground up, integrating with how we create and maintain documentation at GitLab. Localization built on docs-as-code principles GitLab's documentation is treated like any other code contribution, residing alongside product code in GitLab projects and managed via merge requests. This system ensures documentation is version-controlled, collaboratively reviewed, and automatically tested through CI/CD pipelines, which includes checks for issues with language, formatting, and links. Both the English and Japanese documentation sites are dynamically generated using the Hugo static site generator and deployed after merging changes, guaranteeing users always access the latest information. The documentation is extensive and comprehensive, drawing content from various source projects, including GitLab, GitLab Runner, Omnibus GitLab, GitLab Charts, GitLab Operator, and GitLab CLI (glab) ( see architecture for details ). This sheer scale and rapid update velocity presented a significant localization challenge. To keep pace with the continuous evolution of these source English projects, we had to design a localization infrastructure for our GitLab product documentation that could handle these unique complexities and provide an enterprise-grade solution for a fully localized site, all while adhering to our CI/CD pipeline requirements. How we localized GitLab Documentation For our initial Japanese localization, we adopted a strategy of integrating new folders within our existing English content structure. Specifically, we introduced doc-locale/ja-jp folders within each project that stores source Markdown files. This architecture keeps the translations right alongside their source content while maintaining a clear organizational separation. Not only that, but it also enables us to apply the same robust version control, established review and collaboration workflows, and even some of the automated quality checks used for our English documentation to the translated content. This internationalization infrastructure built for Japanese documentation provides a scalable foundation for future language expansion. With the architecture, tooling, and processes now in place, we are well-positioned to support additional languages as we continue our commitment to making GitLab accessible to users worldwide. An AI-assisted  translation workflow that balances speed and quality We adopted a strategic, phased approach to processing the content through translation, prioritizing pages based on their English-language page views. The highest-traffic pages underwent AI translation first, followed by comprehensive human linguistic review, and we intentionally paused subsequent phases until these priority pages completed the full human review cycle. This deliberate sequencing allowed us to build a robust, curated translation memory and termbase from our most important content. These linguistic assets accelerated and improved quality across all remaining content. In parallel, this initial phase served as our testing ground on the technical infrastructure on the GitLab side. We used it to iterate and reinforce our CI/CD pipelines, refine our translation and post-editing AI scripts, and solidify our Translation MR review process. To provide our international users with the most current documentation while guaranteeing high-quality translated content, we implemented an AI-assisted translation workflow with human post-editing , consisting of: Phase 1: AI-powered translation. We built a custom AI translation system enriched with GitLab-specific context including style guides, GitLab UI content translations, terminology databases, and original file context. This system intelligently handles GitLab's specialized markdown syntax (GLFM) and protects elements like placeholder variables, alert boxes, Hugo shortcodes, and GitLab-specific references that standard translation tools can't process out of the box. Phase 2: Human linguistic review. Professional Japanese translators specialized in technical content then review and refine the AI translations. They work with GitLab's Japanese style guide, translation memory, and terminology database to ensure accuracy, natural language flow, and cultural appropriateness. These human-reviewed translations progressively replace the AI versions on the site. Technical challenges and solutions Localizing GitLab's extensive documentation, while maintaining our docs-as-code principles and CI/CD-driven publishing workflow, required significant technical innovation. The challenges extended beyond translation itself: we needed to preserve complex markdown syntax, maintain automated testing standards, ensure seamless content fallbacks, and create sustainable processes for continuous updates across multiple source projects. The English markdown file syntax complexity led us to developing custom code and regex in our Translation Management System (TMS) to protect codeblocks, URLs, and other functional elements that should not be exposed for translation. Due to the dynamics of how the English content is generated, we established an English fallback mechanism. Essentially, when the Japanese translation is not ready yet, the localized site seamlessly displays English content with translated navigation and UI, preventing 404s and maintaining language context via Hugo‚Äôs rendering system. We enhanced the localized navigation and linking so that it adjusts dynamically and would persist the locale. We added anchor IDs in the translated files by pre-processing the English file before it‚Äôs sent for translation. That improves the experience for people navigating to a docs page from a link. The consistent anchor ID means they can change to either language and still land in the correct place in the page. We also extended CI/CD pipelines to test localized content in Translation MRs following the same quality standards as the English docs. It allows us to catch invalid Hugo shortcodes, spaces inside links, or bare URLs. It also identifies orphaned files and redirects files with no target files. You can see the jobs that run on the MRs containing translated documentation on the GitLab project .gitlab/ci/docs.gitlab-ci.yml file . A centralized translation request system orchestrates the workflow, monitors the English files, identifies new and updated content, routes files for translation, automatically creates translation merge requests, tracks file status in translation requests and maintains an audit trail. To get docs translated we processed 430 Translation MRs with files ranging from 1-10 in each Translation MR. The result is a Japanese documentation experience that stays synchronized with English content updates, giving users faster access to critical information. Users can discover and navigate content fully in their language, with English appearing only for content that‚Äôs still in translation. They can trust GitLab‚Äôs quality standards while accessing the latest features quickly. All of this creates a sustainable, scalable foundation for future languages and documentation growth. Learn more about all the technical details in our GitLab Product Documentation Handbook page . Visit our Japanese docs site Whether you're a longtime GitLab user or just getting started, we hope this localized documentation makes your DevSecOps journey smoother and more accessible. This is just the beginning of our localization efforts, and your feedback is invaluable in helping us improve. If you notice any translation issues, have suggestions for improvement, or simply want to share your experience using the Japanese documentation, please don't hesitate to reach out. You can provide comments in our feedback issue . As we continue evolving this localization infrastructure, our immediate priorities include enhancing the search experience for Japanese users, and accelerating our continuous localization workflow to minimize the time gap between English updates and their Japanese translations. Thank you to our Japanese community for your continued support and patience as we work to serve you better. We're committed to making GitLab the best DevSecOps platform for Japanese teams, and comprehensive Japanese documentation is a crucial step in that journey. Start exploring today at docs.gitlab.com/ja-jp !",
      "published_ts": 1765411200,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/artois-university-elevates-curriculum-with-gitlab-ultimate-for-education/",
      "title": "Artois University elevates research and curriculum with GitLab Ultimate for Education",
      "summary": "Leading academic institutions face a critical challenge: how to provide thousands of students and researchers with industry-standard, full-featured DevSecOps tools without compromising institutional control. Many start with basic version control, but the modern curriculum demands integrated capabilities for planning, security, and advanced CI/CD. The GitLab for Education program is designed to solve this by providing access to GitLab Ultimate for qualifying institutions, allowing them to scale their operations and elevate their academic offerings. This article showcases a powerful success story from the Centre de Recherche en Informatique de Lens (CRIL) , a joint laboratory of Artois University and CNRS in France. After years of relying solely on GitLab Community Edition (CE), the university's move to GitLab Ultimate through the GitLab for Education program immediately unlocked advanced capabilities, transforming their teaching, research, and contribution workflows virtually overnight. This story demonstrates why GitLab Ultimate is essential for institutions seeking to deliver advanced computer science and research curricula. GitLab Ultimate unlocked: Managing scale and driving academic value Artois University's self-managed GitLab instance is a large-scale operation, supporting nearly 3,000 users across approximately 19,000 projects , primarily serving computer science students and researchers. While GitLab Community Edition was robust, the upgrade to GitLab Ultimate provided the sophisticated tooling necessary for managing this scale and facilitating advanced university-level work. \"We can see the difference,\" says Daniel Le Berre, head of research at CRIL and the instance maintainer. \"It's a completely different product. Each week reveals new features that directly enhance our productivity and teaching.\" The institution joined the GitLab for Education program specifically because it covers both instructional and non-commercial research use cases and offers full access to Ultimate's features, removing significant cost barriers. Key GitLab Ultimate benefits for students and researchers Advanced project management at scale: Master's students now benefit from GitLab Ultimate's project planning features . This enables them to structure, track, and manage complex, long-term research projects using professional methodologies like portfolio management and advanced issue tracking that seamlessly roll up across their thousands of projects. Enhanced visibility: Features like improved dashboards and code previews directly in Markdown files dramatically streamline tracking and documentation review, reducing administrative friction for both instructors and students managing large project loads. Comprehensive curriculum: From concepts to continuous delivery GitLab Ultimate is deeply integrated into the computer science curriculum, moving students beyond simple git commands to practical DevSecOps implementation . Git fundamentals: Students begin by visualizing concepts using open-source tools to master Git concepts. Full CI/CD implementation: Students use GitLab CI for rigorous Test-Driven Development (TDD) in their software projects. They learn to build, test, and perform quality assurance using unit and integration testing pipelines‚Äîcore competency made seamless by the integrated platform. DevSecOps for research and documentation: The university teaches students that DevSecOps principles are vital for all collaborative work. Inspired by earlier work in Delft, students manage and produce critical research documentation (PDFs from Markdown files) using GitLab, incorporating quality checks like linters and spell checks directly in the CI pipeline. This ensures high-quality, reproducible research output. Future-proofing security skills: The GitLab Ultimate platform immediately positions the institution to incorporate advanced DevSecOps features like SAST and DAST scanning as their research and development code projects grow, ensuring students are prepared for industry security standards. Accelerating open source contributions with GitLab Duo Access to the full GitLab platform, including our AI capabilities, has empowered students to make impactful contributions to the wider open source community faster than ever before. Two Master's students recently completed direct contributions to the GitLab product, adding the ORCID identifier into user profiles. Working on GitLab.com, they leveraged GitLab Duo's AI chat and code suggestions to navigate the codebase efficiently. \"This would not have been possible without GitLab Duo,\" Daniel Le Berre notes. \"The AI features helped students, who might have lacked deep codebase knowledge, deliver meaningful contributions in just two weeks.\" This demonstrates how providing students with cutting-edge tools accelerates their learning and impact , allowing them to translate classroom knowledge into real-world contributions immediately. Empowering open research and institutional control The stability of the self-managed instance at Artois University is key to its success. This model guarantees institutional control and stability ‚Äî a critical factor for long-term research preservation. The institution's expertise in this area was recently highlighted in a major 2024 study led by CRIL, titled: \" Higher Education and Research Forges in France - Definition, uses, limitations encountered and needs analysis \" ( Project on GitLab ). The research found that the vast majority of public forges in French Higher Education and Research relied on GitLab . This finding underscores the consensus among academic leaders that self-hosted solutions are essential for data control and longevity , especially when compared to relying on external, commercial forges. Unlock GitLab Ultimate for your institution today The success story of Artois University's CRIL proves the transformative power of the GitLab for Education program. By providing free access to GitLab Ultimate , we enable large-scale institutions to: Deliver a modern, integrated DevSecOps curriculum. Support advanced, collaborative research projects with Ultimate planning features. Empower students to make AI-assisted open source contributions. Maintain institutional control and data longevity. If your academic institution is ready to equip its students and researchers with the complete DevSecOps platform and its most advanced features, we invite you to join the program. The program provides free access to GitLab Ultimate for qualifying instructional and non-commercial research use cases. Apply now online .",
      "published_ts": 1765324800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/introducing-aws-glue-5-1-for-apache-spark/",
      "title": "Introducing AWS Glue 5.1 for Apache Spark",
      "summary": "AWS recently announced Glue 5.1, a new version of AWS Glue that accelerates data integration workloads in AWS. AWS Glue 5.1 upgrades the Spark engines to Apache Spark 3.5.6, giving you newer Spark release¬†along with the newer dependent libraries so you can develop, run, and scale your data integration workloads and get insights faster. In this post, we describe what‚Äôs new in AWS Glue 5.1, key highlights on Spark and related libraries, and how to get started on AWS Glue 5.1.",
      "published_ts": 1765315755,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://azure.microsoft.com/en-us/blog/microsofts-commitment-to-supporting-cloud-infrastructure-demand-in-the-united-states/",
      "title": "Microsoft‚Äôs¬†commitment¬†to supporting cloud infrastructure demand in¬†the United States",
      "summary": "Today, we are sharing progress on our infrastructure expansions across the United States that are supporting the tremendous growth in customer demand for cloud and AI services. The post Microsoft‚Äôs¬†commitment¬†to supporting cloud infrastructure demand in¬†the United States appeared first on Microsoft Azure Blog .",
      "published_ts": 1765296000,
      "source_name": "Azure Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.cloudflare.com/shift-left-enterprise-scale/",
      "title": "Shifting left at enterprise scale: how we manage Cloudflare with Infrastructure as Code",
      "summary": "Cloudflare has shifted to Infrastructure as Code and policy enforcement to manage internal Cloudflare accounts. This new architecture uses Terraform, custom tooling, and Open Policy Agent to enforce security baselines and increase engineering velocity.",
      "published_ts": 1765260000,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/auto-optimize-your-amazon-opensearch-service-vector-database/",
      "title": "Auto-optimize your Amazon OpenSearch Service vector database",
      "summary": "AWS recently announced the general availability of auto-optimize for the Amazon OpenSearch Service vector engine. This feature streamlines vector index optimization by automatically evaluating configuration trade-offs across search quality, speed, and cost savings. You can then run a vector ingestion pipeline to build an optimized index on your desired collection or domain. Previously, optimizing index [‚Ä¶]",
      "published_ts": 1765238304,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/build-billion-scale-vector-databases-in-under-an-hour-with-gpu-acceleration-on-amazon-opensearch-service/",
      "title": "Build billion-scale vector databases in under an hour with GPU acceleration on Amazon OpenSearch Service",
      "summary": "AWS recently announced the general availability of GPU-accelerated vector (k-NN) indexing on Amazon OpenSearch Service. You can now build billion-scale vector databases in under an hour and index vectors up to 10 times faster at a quarter of the cost. This feature dynamically attaches serverless GPUs to boost domains and collections running CPU-based instances. With [‚Ä¶]",
      "published_ts": 1765238239,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-reinvent-keynote-recap-on-demand-videos-and-more-december-8-2025/",
      "title": "AWS Weekly Roundup: AWS re:Invent keynote recap, on-demand videos, and more (December 8, 2025)",
      "summary": "The week after AWS re:Invent builds on the excitement and energy of the event and is a good time to learn more and understand how the recent announcements can help you solve your challenges and unlock new opportunities. As usual, we have you covered with our top announcements of AWS re:Invent 2025 that you can [‚Ä¶]",
      "published_ts": 1765213529,
      "source_name": "AWS Blog",
      "content_type": "technical"
    }
  ],
  "data_modeling_governance": [
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/disparate-impacts-require-deliberate-solutions",
      "title": "Disparate Impacts Require Deliberate Solutions",
      "summary": "A practical look at mapping and analytics to understand where impacts differ across communities and to design more effective programs with Snowflake and Marketplace data.",
      "published_ts": 1765576800,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.getdbt.com/blog/bring-structured-context-to-agentic-data-development-with-dbt",
      "title": "Bring structured context to agentic data development with dbt",
      "summary": "Make data development with agents safe, cost-efficient, and scalable with dbt structured context and MCP server.",
      "published_ts": 1765402080,
      "source_name": "dbt Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/data-visibility-primer",
      "title": "What Does Data Visibility Really Mean?",
      "summary": "Hidden data causes issues. Learn how to improve visibility and reduce surprises in your analytics and engineering pipelines.",
      "published_ts": 1765305678,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/ataccama-for-trusted-ai-ready-data",
      "title": "Snowflake Ventures Backs Ataccama to Advance Trusted, AI-Ready Data",
      "summary": "Snowflake Ventures expands its partnership with Ataccama to bring native data quality and governance capabilities to Snowflake helping teams deliver AI-ready data.",
      "published_ts": 1765299600,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://vutr.substack.com/p/9-lessons-that-will-put-you-3-years",
      "title": "9 lessons that will put you 3 years ahead as a data engineer",
      "summary": "It took me six years to distill these insights, but you can read them in just 10 minutes.",
      "published_ts": 1765250132,
      "source_name": "VuTrinh ¬∑ Data Engineering",
      "content_type": "rex"
    },
    {
      "url": "https://dlthub.com/blog/data-contracts-agreement-vs-enforcement",
      "title": "Data contract agreement vs enforcement",
      "summary": "Data contracts keep systems predictable by pairing clear rules with checks that catch bad data before it flows downstream.",
      "published_ts": 1765152000,
      "source_name": "dlt Blog",
      "content_type": "technical"
    }
  ],
  "etl_orchestration": [
    {
      "url": "https://dagster.io/blog/deepdive-recap-data-reliability",
      "title": "Building Reliable Data Platforms with Dagster",
      "summary": "Use Dagster to enforce data quality rules at every step of the pipeline, improving platform reliability and reducing downstream data issues.",
      "published_ts": 1765554388,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/balancing-the-data-scales-centralization-vs-decentralization",
      "title": "Data Centralization vs Decentralization",
      "summary": "Explore when to centralize vs decentralize data‚Äîand how to strike the right balance in modern data architectures.",
      "published_ts": 1765551083,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/impedance-mismatch-in-data-orchestration",
      "title": "Fixing the Data Engineering Mismatch",
      "summary": "Why asset-oriented orchestration leads to better developer experience and less brittle pipelines than traditional workflow-centric systems.",
      "published_ts": 1765550380,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/scale-and-standardize-data-pipelines-with-dsl",
      "title": "Use DSLs to Standardize Your Pipelines",
      "summary": "Domain-Specific Languages help scale data platforms by allowing more users to contribute without sacrificing standardization or governance.",
      "published_ts": 1765550380,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-pipes",
      "title": "Introducing Dagster Pipes",
      "summary": "Dagster Pipes lets you securely trigger and manage external compute processes, making remote execution environments first-class citizens in your DAGs.",
      "published_ts": 1765550380,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/outbound-reporting-pipeline",
      "title": "Build an Email Reporting Pipeline",
      "summary": "Use Dagster and dynamic partitioning to build a robust outbound report delivery pipeline.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/deepdive-recap-building-a-true-data-platform",
      "title": "How to Build a True Data Platform",
      "summary": "Skip the noise of the modern data stack and build a unified, observable, and cost-effective data platform powered by Dagster orchestration.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/introducing-dagster-labs",
      "title": "Introducing Dagster Labs",
      "summary": "Elementl has rebranded as Dagster Labs to reflect its focus on empowering data teams through world-class orchestration tools and open-source innovation.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/see-the-forest-and-trees-dagster-plus",
      "title": "See Big Picture + Details with Dagster+ Insights",
      "summary": "Use Dagster+ Insights to monitor costs, asset health, and gain observability across both macro and micro data pipeline metrics.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-ml-pipelines",
      "title": "ML Pipeline Orchestration with Dagster",
      "summary": "Orchestrate machine learning pipelines from start to finish with Dagster, training models, validating results, and monitoring outputs all in one place.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-crash-course-oct-2022",
      "title": "Dagster Crash Course: Get Started Fast",
      "summary": "Learn the basics of Dagster in under 10 minutes. This quick crash course will get your data pipelines up and running fast.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/what-is-dagster",
      "title": "What Is Dagster? Learn the Basics",
      "summary": "Dagster is a modern orchestrator for data platforms. Learn what makes it different and how it improves workflows.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.rudderstack.com/blog/ibm-confluent-real-time-streaming-ai",
      "title": "IBM √ó Confluent: Is real-time streaming cool again?",
      "summary": "IBM‚Äôs Confluent acquisition shows real-time data is now essential for AI agents. Learn why customer context and streaming pipelines matter more than ever.",
      "published_ts": 1765483091,
      "source_name": "Rudderstack Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/python-ci-cd-automation",
      "title": "CI/CD for Data Pipelines with Git",
      "summary": "Learn how to automate data pipeline deployment using CI/CD practices integrated with Git.",
      "published_ts": 1765478078,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/open-core-business-model-dagster",
      "title": "How Dagster Balances Open Source and SaaS",
      "summary": "Understand how Dagster separates its open-source offering from Dagster Cloud‚Äôs hosted SaaS features in a sustainable business model.",
      "published_ts": 1765478078,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-atlan-integration",
      "title": "Dagster Plus + Atlan Integration: Real-Time Event Sync",
      "summary": "Stream asset materializations, run status, and lineage from Dagster plus to Atlan in real-time. Keep your data catalog in sync with pipeline reality.",
      "published_ts": 1765470510,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.uber.com/blog/from-batch-to-streaming-accelerating-data-freshness-in-ubers-data-lake/",
      "title": "From Batch to Streaming: Accelerating Data Freshness in Uber‚Äôs Data Lake",
      "summary": "Learn how Uber moved from batch to streaming ingestion with IngestionNext, reducing data latency and unlocking real-time analytics across its petabyte-scale data lake.",
      "published_ts": 1765461600,
      "source_name": "Uber Engineering Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/deepdive-recap-evolution-data-platform",
      "title": "Evolution of the Data Platform with Dagster",
      "summary": "Dagster and SDF connect local dev environments with production pipelines, enabling full lifecycle orchestration with clear asset lineage.",
      "published_ts": 1765461515,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/orchestrating-nanochat-training-the-models",
      "title": "Training NanoChat in Dagster: Multi-Stage Model Training with RunPod GPUs",
      "summary": "Learn how to orchestrate and train each layer of your NanoChat-based model using Dagster, RunPod GPU instances, and repeatable machine-learning pipelines.",
      "published_ts": 1765389096,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-1-1-thank-u-next",
      "title": "Dagster 1.1: Declarative Scheduling",
      "summary": "Dagster 1.1 adds declarative scheduling, secrets management, and major improvements to multi-asset workflows.",
      "published_ts": 1765387457,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-1-2-formation",
      "title": "Dagster 1.2: New Config & Integrations",
      "summary": "Dagster 1.2 introduces Pythonic config, stronger partitioned asset support, and updated integrations.",
      "published_ts": 1765305678,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.rudderstack.com/blog/data-integration-trends",
      "title": "Data integration trends shaping 2025 and beyond",
      "summary": "Discover 2025's data integration trends, from real-time pipelines to privacy-first design.",
      "published_ts": 1765293231,
      "source_name": "Rudderstack Blog",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/sap-data-ingestion-and-replication-with-aws-glue-zero-etl/",
      "title": "SAP data ingestion and replication with AWS Glue zero-ETL",
      "summary": "AWS Glue zero-ETL with SAP now supports data ingestion and replication from SAP data sources such as Operational Data Provisioning (ODP) managed SAP Business Warehouse (BW) extractors, Advanced Business Application Programming (ABAP), Core Data Services (CDS) views, and other non-ODP data sources. Zero-ETL data replication and schema synchronization writes extracted data to AWS services like Amazon Redshift, Amazon SageMaker lakehouse, and Amazon S3 Tables, alleviating the need for manual pipeline development. In this post, we show how to create and monitor a zero-ETL integration with various ODP and non-ODP SAP sources.",
      "published_ts": 1765235515,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    }
  ],
  "hors_sujet": [
    {
      "url": "https://blog.octo.com/octoune-vie-ponctuee-par-la-resilience-et-la-performance--la-school-of-product-2025-cr-de-clarisse-agbegnenou",
      "title": "Une vie ponctu√©e par la r√©silience et la performance  : La School of Product 2025 - CR de Clarisse Agbegnenou",
      "summary": "Clarisse Agbegnenou, multiple championne olympique, nous invite √† repenser l'√©quilibre fondamental entre performance et bien-√™tre. √Ä travers le partage de son exp√©rience personnelle, elle √©tablit des parall√®les √©clairants avec les d√©fis du monde de la gestion de produit.",
      "published_ts": 1765184726,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    }
  ],
  "lake_storage_formats": [],
  "news": [
    {
      "url": "https://azure.microsoft.com/en-us/blog/actioning-agentic-ai-5-ways-to-build-with-news-from-microsoft-ignite-2025/",
      "title": "Actioning agentic AI: 5 ways to build with news from Microsoft Ignite 2025",
      "summary": "Energy at Microsoft Ignite was electric. Over 20,000 attendees gathered in San Francisco, with 200,000 digital participants joining us to explore the future of cloud and AI. The post Actioning agentic AI: 5 ways to build with news from Microsoft Ignite 2025 appeared first on Microsoft Azure Blog .",
      "published_ts": 1765386000,
      "source_name": "Azure Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/du-design-a-la-strategie-produit--detourner-la-discovery-pour-decider-autrement-ce-que-j'ai-retenu-du-talk-de-laura-crispain-(school-of-product-2025)",
      "title": "School of Product 2025‚Äî  Du design √† la strat√©gie produit ‚Äî Ce que j‚Äôai retenu du talk de Laura Krispin",
      "summary": "On pr√©sente souvent la Product Discovery comme un filet de s√©curit√© : un moyen d‚Äô√©viter de sortir un produit qui ne sera ni utilis√©, ni achet√©. Cependant √† la School of Product, Laura Krispin nous a montr√© autre chose : une discovery qui sert √† d√©cider, pas seulement √† valider.",
      "published_ts": 1765354630,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/snowflake-joins-aaif",
      "title": "Snowflake Joins AAIF as a Gold Member",
      "summary": "Snowflake joins the Agentic AIFoundation (AAIF) to help advance open, interoperable agent standards for enterprise AI.",
      "published_ts": 1765345380,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/new-wave-of-fake-job-scams-impersonating-recruiters/",
      "title": "New wave of fake job scams impersonating recruiters",
      "summary": "Job seekers are being targeted by scammers impersonating recruiters at tech companies, including GitLab, through email, LinkedIn, and video conferencing platforms. These scams misuse GitLab‚Äôs name, logo, and team member identities to create the illusion of legitimate hiring activity. Victims have reported receiving fake interview invitations, employment offers, and onboarding documents, often followed by requests for payment or personal information. These campaigns are not affiliated with GitLab in any way. What‚Äôs new with this wave Recent incidents differ from earlier scams by introducing new domains and tactics, including: Use of unauthorized domains such as gitlab[.]careers and careers-gitlab[.]com References to fake certifications like ‚ÄúCPD USA Certification‚Äù Fake recruiter profiles on LinkedIn and Teams impersonating GitLab HR staff Requests for sensitive information or upfront ‚Äúequipment‚Äù payments after fake interviews These impersonators are becoming more sophisticated, using corporate-style emails, authentic-looking offer letters, and realistic video interview invitations to gain trust. Common warning signs Candidates should be cautious if they encounter any of the following: The email domain is not @gitlab.com (e.g., Gmail, Outlook, or lookalike domains). The recruiter requests you to pay for equipment, certification, or background checks. The communication happens only through chat, without verified GitLab calendar invites. The job listing does not appear on the official GitLab careers page. The recruiter refuses to verify their identity via a GitLab.com address or directs you to external URLs unrelated to GitLab. GitLab‚Äôs official recruiting process GitLab‚Äôs hiring process is fully remote but transparent and verifiable. All communications come from official @gitlab.com email addresses. Interviews are conducted via Zoom, not Microsoft Teams or WhatsApp. GitLab never requests payment, purchases, or certification fees during recruitment. Legitimate offers and onboarding steps are handled securely through GitLab systems. For details on how we hire, please refer to our Candidate Handbook . What GitLab is doing GitLab‚Äôs Security and People teams are actively investigating and reporting fake recruiting domains and profiles to hosting providers and social networks. We continue to collaborate with legal, communications, and platform partners to remove fraudulent content and notify affected individuals. If you see something suspicious, let us know at security@gitlab.com . Anyone can report suspicious recruiting activity for review by our Security Incident Response Team. How to protect yourself If you receive suspicious communication that claims to be from GitLab: Verify the sender‚Äôs email domain ‚Äî it should always end in @gitlab.com . Confirm job postings directly on about.gitlab.com/jobs. Avoid sending personal or financial information to unverified recruiters. Report any suspicious domains or messages to security@gitlab.com . For additional information on avoiding job scams, see these trusted resources: Candidate Handbook Online employment scam resources ‚Äì FTC If you believe you‚Äôve been targeted by a fake GitLab recruiter, please **report it immediately to security@gitlab.com so our team can investigate.",
      "published_ts": 1765324800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/pete-hunt-path-to-elementl-part2",
      "title": "Leadership Shift at Dagster Labs",
      "summary": "Dagster Labs announces a leadership transition as Pete Hunt takes over as CEO and Nick Schrock shifts focus to product innovation as CTO.",
      "published_ts": 1765306777,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/ia--risque-d'asservissement-et-d'erosion-des-competences-comment-preserver-la-maitrise-du-geste",
      "title": "IA : risque d‚Äôasservissement et d‚Äô√©rosion des comp√©tences - comment pr√©server la ma√Ætrise du geste ?",
      "summary": "l‚ÄôIA n‚Äôest qu‚Äôun outil, √† ma√Ætriser en gardant nos capacit√©s d‚Äôapprentissage et nos comp√©tences de pratique. Repassons ‚Äúen mode manuel‚Äù de temps √† autre pour rester en alerte et √©viter l'asservissement. C‚Äôest ce qui permet de garder la ma√Ætrise, la cr√©ativit√©, nos r√©flexes ainsi que nos motivations. Inspirons nous de l'aviation ou de l'automobile.",
      "published_ts": 1765300810,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/cr-school-of-product-2025-moi-emmanuelle--sourde-malvoyante...-et-utilisatrice-de-vos-produits",
      "title": "CR School of Product 2025 - Moi, Emmanuelle : sourde, malvoyante‚Ä¶ et utilisatrice de vos produits",
      "summary": "Lors de l‚Äô√©dition 2025 de la School of Product, un talk m‚Äôa particuli√®rement marqu√© : celui d‚ÄôEmmanuelle, d√©veloppeuse depuis treize ans, experte en accessibilit√© et sourde de naissance. √Ä travers son parcours, elle offre un √©clairage pr√©cieux sur la mani√®re dont la technologie a transform√© sa vie quotidienne ‚Äî mais aussi sur ses limites et sur la",
      "published_ts": 1765287237,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/school-of-product-2025-compte-rendu-l'humanite-a-t-elle-les-moyens-de-s'offrir-l'ia",
      "title": "School Of Product 2025 - Compte Rendu - L‚Äôhumanit√© a-t-elle les moyens de s‚Äôoffrir l‚ÄôIA ?",
      "summary": "Ce que nous retenons du talk de Tristan Nitot √† la School of Product\nLors de l‚Äô√©dition r√©cente de la School of Product, Tristan Nitot a pris la parole autour d‚Äôune question percutante :\n>\n‚ÄúL‚Äôhumanit√© a-t-elle les moyens de s‚Äôoffrir l‚ÄôIA ?‚Äù\nCe talk n‚Äô√©tait ni alarmiste ni b√©atement techno-enthousiast",
      "published_ts": 1765205890,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://www.dataengineeringweekly.com/p/data-engineering-weekly-247",
      "title": "Data Engineering Weekly #247",
      "summary": "The Weekly Data Engineering Newsletter",
      "published_ts": 1765157129,
      "source_name": "Data Engineering Weekly",
      "content_type": "rex"
    }
  ],
  "news_general": [],
  "python_analytics": [
    {
      "url": "https://duckdb.org/2025/12/09/announcing-duckdb-143.html",
      "title": "Announcing DuckDB 1.4.3 LTS",
      "summary": "Today we are releasing DuckDB 1.4.3. Along with bugfixes, we are shipping native extensions and Python support for Windows Arm64.",
      "published_ts": 1765238400,
      "source_name": "DuckDB Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.cloudflare.com/python-workers-advancements/",
      "title": "Python Workers redux: fast cold starts, packages, and a uv-first workflow",
      "summary": "Recent advancements in Cloudflare Python Workers means fast cold starts, comprehensive package support, and a great developer experience. We explain how they were achieved and show how Python can be used to build serverless applications on Cloudflare.",
      "published_ts": 1765173600,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    }
  ],
  "warehouses_engines": [
    {
      "url": "https://seattledataguy.substack.com/p/snowflake-vs-databricks-is-the-wrong",
      "title": "Snowflake vs Databricks Is the Wrong Debate",
      "summary": "Winning the Data Stack Role by Role",
      "published_ts": 1765554569,
      "source_name": "Seattle Data Guy",
      "content_type": "rex"
    },
    {
      "url": "https://www.getdbt.com/blog/reliable-analytics-dbt-databricks",
      "title": "Scale reliable analytics in the AI era with dbt and Databricks",
      "summary": "Here‚Äôs why standards don‚Äôt matter when it comes to unlocking data siloes and fueling the agentic AI future.",
      "published_ts": 1765486680,
      "source_name": "dbt Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/relationalai-drives-intelligence-forward",
      "title": "RelationalAI Drives Decision Intelligence Forward with Snowflake Ventures‚Äô Investment",
      "summary": "Snowflake Ventures invests in RelationalAI, a decision-intelligence platform that runs natively in Snowflake via Snowpark Container Services",
      "published_ts": 1765472400,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/startup-spotlight-prettydamnquick",
      "title": "Startup Spotlight: PrettyDamnQuick",
      "summary": "Learn how PrettyDamnQuick uses Snowflake to turn static checkout into personalized flows, reducing cart abandonment and boosting conversions.",
      "published_ts": 1765402368,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/open-lakehouse-interoperability-microsoft-onelake",
      "title": "Unlock Open Lakehouse with Microsoft OneLake and Snowflake",
      "summary": "Address data fragmentation with an open lakehouse, using Apache Iceberg to unify data silos and enable governed interoperability with Microsoft OneLake.",
      "published_ts": 1765328760,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/introducing-apache-iceberg-materialized-views-in-aws-glue-data-catalog/",
      "title": "Introducing Apache Iceberg materialized views in AWS Glue Data Catalog",
      "summary": "Hundreds of thousands of customers build artificial intelligence and machine learning (AI/ML) and analytics applications on AWS, frequently transforming data through multiple stages for improved query performance‚Äîfrom raw data to processed datasets to final analytical tables. Data engineers must solve complex problems, including detecting what data has changed in base tables, writing and maintaining transformation [‚Ä¶]",
      "published_ts": 1765316211,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/skip-kafka-use-postgres-message-queue",
      "title": "Postgres vs Kafka for Event Queues",
      "summary": "Explore how Postgres can outperform Kafka in storing and indexing event logs, especially when flexibility and familiarity matter.",
      "published_ts": 1765306777,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.uber.com/blog/blazing-fast-olap-on-ubers-inventory-and-catalog-data-with-apache-pinot/",
      "title": "Blazing Fast OLAP on Uber‚Äôs Inventory and Catalog Data with Apache Pinot‚Ñ¢",
      "summary": "Discover how Uber used Apache Pinot‚Ñ¢ to build a real-time index on its massive inventory of billions of items to power search use cases, internal tools, and operational workflows.",
      "published_ts": 1765288800,
      "source_name": "Uber Engineering Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/pricing-calculator-guide",
      "title": "5 Things You Can Do with the Snowflake Pricing Calculator",
      "summary": "Learn about the Snowflake Pricing Calculator, designed to help you understand how Snowflake‚Äôs consumption-based pricing works.",
      "published_ts": 1765233230,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/cutting-data-engineering-costs",
      "title": "Do More for Less: Announcing New Snowpipe Pricing ‚Äî and 9 Other Ways to Save on Data Engineering Costs",
      "summary": "From ingestion to pipelines, learn 10 ways to cut data engineering costs. We also outline the new Snowpipe pricing model and how it supports cost predictability.",
      "published_ts": 1765221148,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.snowflake.com/content/snowflake-site/global/en/blog/cutting-data-engineering-costs",
      "title": "Announcing New Snowpipe Pricing and 9 Other Ways to Save on Data Engineering Costs",
      "summary": "From ingestion to pipelines, learn 10 ways to cut data engineering costs. We also outline the new Snowpipe pricing model and how it supports cost predictability.",
      "published_ts": 1765221148,
      "source_name": "Snowflake Blog",
      "content_type": "technical"
    }
  ]
}