# Roadmap d'Am√©lioration Personnalis√©e - Veille Tech Crawling

**Date :** 2025-12-20
**Bas√© sur vos r√©ponses et contraintes**
**Strat√©gie :** Excellence UX ‚Üí Engagement Utilisateurs ‚Üí Mon√©tisation (Optionnelle)

---

## üéØ Votre Contexte & Contraintes

**Objectif #1 (PRIORIT√â ABSOLUE) :**
> **"Faire un site utile avec une vraie bonne exp√©rience pour mes utilisateurs"**

**Cela signifie 2 piliers indissociables :**
1. üé® **Exp√©rience utilisateur (UX)** - Site rapide, agr√©able, accessible
2. üìä **Qualit√© du contenu & Pertinence** - Articles vraiment utiles, moins de bruit, meilleur scoring

**Sans pertinence du contenu, l'UX ne sert √† rien.**
**Sans bonne UX, m√™me le meilleur contenu ne sera pas utilis√©.**

Tout le reste est secondaire. La mon√©tisation viendra naturellement si l'exp√©rience ET le contenu sont excellents.

**D√©cisions Strat√©giques :**
- **Timeline :** Flexible, pas de deadline mon√©tisation
- **Temps disponible :** 20% (1 jour/semaine) = ~5-8 SP/sprint (2 semaines)
- **Strat√©gie :** UX First - Perfectionner l'exp√©rience utilisateur avant tout
- **Scope :** Complet, focus qualit√© et utilit√© r√©elle
- **Objectif final :** Site que les utilisateurs adorent utiliser chaque semaine

**√âtat Actuel :**
- Phase : Production avec users r√©els
- Priorit√© #1 : **Exp√©rience utilisateur excellente**
- Priorit√© #2 : Stabilit√© + qualit√© technique
- Dette tech : Ralentit tout (critique)
- Risque #1 : D√©pendance Groq 100%

**Crit√®res Succ√®s (UX + Contenu) :**
- ‚úÖ **Pertinence articles > 90%** (feedback users - crit√®re #1)
- ‚úÖ **Ratio signal/bruit √©lev√©** (articles vraiment utiles vs fluff)
- ‚úÖ Users trouvent la veille utile chaque semaine
- ‚úÖ Z√©ro bugs signal√©s users
- ‚úÖ Performance > 90 Lighthouse (desktop + mobile)
- ‚úÖ Temps de recherche < 2 secondes
- ‚úÖ Cat√©gorisation pr√©cise (> 95%)

---

## üìÖ Planning Adapt√© : Approche "UX Excellence First"

### Phase 1 : FONDATIONS (UX + CONTENU) & QUALIT√â TECHNIQUE (Mois 1-3)

**Objectif :** Site fiable, rapide, agr√©able + Articles pertinents - Fondations solides

**Focus :** Dette technique + Performance + Stabilit√© + Quick wins UX + Am√©lioration pertinence

**Timeline :** 12 semaines (si 20% temps = 5-8 SP/sprint)
**Total SP :** ~52 SP (47 SP dette + 5 SP pertinence)

---

#### Mois 1 (Semaines 1-4) : Quick Wins + Fondations

**Sprint 1 (Sem 1-2) : Mitigation Risques - 8 SP**

**Semaine 1-2 :**
- [P0] **Abstraction LLM Provider** (3 SP) ‚ö†Ô∏è **CRITIQUE**
  - Cr√©er interface `LLMProvider` (ABC)
  - Impl√©menter `GroqProvider`, `OpenAIProvider`, `OllamaProvider`
  - Config YAML : `llm.provider: groq` (switchable)
  - Tests : switch provider en config
  - **Deliverable :** Risque Groq mitig√©, projet survivable

- [P1] **Setup Monitoring Sentry** (5 SP)
  - Int√©grer Sentry backend (`main.py`, `veille_tech.py`)
  - Int√©grer Sentry frontend (`main.tsx`)
  - Configurer alertes Slack (si > 10 erreurs/run)
  - Variables GitHub Secrets (`SENTRY_DSN_BACKEND`, `SENTRY_DSN_FRONTEND`)
  - **Deliverable :** Bugs d√©tect√©s automatiquement

**Sprint 2 (Sem 3-4) : Tests Frontend Critiques - 5 SP**

**Semaine 3-4 :**
- [P1] **Tests Frontend Vitest** (5 SP)
  - Setup Vitest + @testing-library/react
  - Tests `App.tsx` : filtrage multi-couches (3 tests)
  - Tests `CategoryFilter.tsx` : s√©lection cat√©gorie (2 tests)
  - Tests `lib/parse.ts` : parsing digest.json (2 tests)
  - **Deliverable :** Coverage frontend 40-50%

---

#### Mois 2 (Semaines 5-8) : CI/CD + Performance + Pertinence

**Sprint 2.5 (Sem 5-6, Partie 1) : üéØ Am√©lioration Pertinence & Scoring - 5 SP**

**B√©n√©fice Utilisateur :** Moins de bruit, plus d'articles vraiment utiles, meilleure s√©lection

**Semaine 5 (2-3 jours d√©di√©s pertinence) :**
- [CONTENU] **Optimisation Scoring & Filtrage** (5 SP)
  - **Audit pertinence actuelle** (1 SP)
    - Analyser 100 derniers articles s√©lectionn√©s
    - Identifier faux positifs (bruit, marketing, beginner)
    - Identifier faux n√©gatifs (bons articles rat√©s)

  - **Am√©liorer anti-bruit filtering** (2 SP)
    - Affiner seuils `tech_level` (beginner detection)
    - Am√©liorer `marketing_score` (promo content)
    - Blacklist keywords marketing ("sponsored", "partner", etc.)
    - Test sur 1000 articles crawl√©s

  - **Optimiser seuils par cat√©gorie** (1 SP)
    - Analyser distribution scores par cat√©gorie
    - Ajuster `category_thresholds` (config.yaml)
    - Ex: News 60 ‚Üí 65, Warehouses 45 ‚Üí 50

  - **Ajouter sources pertinentes** (1 SP)
    - Research 5-10 nouvelles sources qualit√© (blogs experts) comme reddit ou X ou l'on peut trouver des bon artciles/Rex / explication
    - Configurer RSS feeds (config.yaml)
    - Pond√©ration source (`source_weight`)

  - **Deliverable :** Ratio signal/bruit am√©lior√© de 20-30%

---

**Sprint 3 (Sem 6-7) : CI/CD Tests Automatiques - 5 SP**

**Semaine 6-7 :**
- [P1] **CI/CD Tests** (5 SP)
  - GitHub Actions : step pytest (backend-weekly.yml)
  - GitHub Actions : step vitest (deploy-frontend.yml)
  - Fail workflow si tests √©chouent
  - Coverage report (Codecov ou artifact)
  - Badge coverage README.md
  - **Deliverable :** Tests automatiques en CI

**Sprint 4 (Sem 8) : Cache Redis Embeddings - 8 SP**

**Semaine 8 :**
- [P1] **Cache Redis** (8 SP)
  - Setup Redis (Upstash free tier ou Docker local)
  - Cache embeddings par `hash(content)`, TTL 30 jours
  - Fallback : calcul si cache miss
  - Config YAML : `cache.redis_url` (optionnel)
  - Monitoring cache hit rate (logs)
  - **Deliverable :** -50% temps scoring (5 min ‚Üí 2.5 min)

---

#### Mois 3 (Semaines 9-12) : Polish Qualit√© + Tests E2E

**Sprint 5 (Sem 9-10) : Tests E2E Playwright - 8 SP**

**Semaine 9-10 :**
- [P1] **Tests E2E Playwright** (8 SP)
  - Setup Playwright
  - Test flow : Navigation semaines (1 test)
  - Test flow : Recherche + r√©sultats (1 test)
  - Test flow : Filtres cat√©gories (1 test)
  - Test flow : Onglets type contenu (1 test)
  - Test flow : Click article ‚Üí open new tab (1 test)
  - **Deliverable :** Flows critiques couverts

**Sprint 6 (Sem 11-12) : Polish UX & Optimisations - 13 SP**

**Semaine 11-12 :**
- [UX] **Mobile UX Audit & Fixes** (3 SP)
  - Audit responsive design (iPhone, iPad, Android)
  - Fix touch targets < 48px
  - Am√©liorer navigation mobile (burger menu si n√©cessaire)
  - Test scroll performance
  - **Deliverable :** Mobile Lighthouse score > 85

- [UX] **Accessibilit√© (a11y) Basics** (2 SP)
  - Audit WAVE (WebAIM)
  - Contraste couleurs (WCAG AA)
  - Labels ARIA manquants
  - Navigation clavier (Tab order)
  - **Deliverable :** Z√©ro erreurs a11y critiques

- [P2] **Infrastructure & Perf** (8 SP)
  - Activer Dependabot (1 SP)
  - Cr√©er branche staging + deploy auto (5 SP)
  - Audit Lighthouse + fixes (atteindre > 90) (2 SP)
  - **Deliverable :** Perf Desktop > 90, Mobile > 85

---

### üèÅ Fin Phase 1 (Mois 3) : Checkpoint (UX + Contenu) & Qualit√©

**R√©sultats Attendus (Technique) :**
- ‚úÖ Abstraction LLM (risque Groq mitig√©)
- ‚úÖ Monitoring Sentry actif (z√©ro bugs silencieux)
- ‚úÖ Tests frontend 40-50% + E2E flows
- ‚úÖ CI/CD tests automatiques
- ‚úÖ Cache Redis (-50% temps scoring)
- ‚úÖ Staging environment
- ‚úÖ Dependabot CVE scanning

**R√©sultats Attendus (UX) :**
- ‚úÖ Performance Desktop > 90 Lighthouse
- ‚úÖ Performance Mobile > 85 Lighthouse
- ‚úÖ Mobile UX fluide (touch, scroll, responsive)
- ‚úÖ Accessibilit√© basics (z√©ro erreurs critiques)
- ‚úÖ Temps recherche < 2 secondes
- ‚úÖ Z√©ro bugs utilisateurs signal√©s

**R√©sultats Attendus (Contenu & Pertinence) :**
- ‚úÖ **Ratio signal/bruit am√©lior√© de 20-30%** (vs baseline)
- ‚úÖ Seuils scoring optimis√©s par cat√©gorie (moins de faux positifs)
- ‚úÖ Anti-bruit filtering affin√© (marketing, beginner)
- ‚úÖ 5-10 nouvelles sources pertinentes ajout√©es
- ‚úÖ Audit pertinence 100 articles (documentation faux positifs/n√©gatifs)

**Score Sant√© Projet√© :** 73/100 ‚Üí **87/100** ‚úÖ (gain +2 points gr√¢ce pertinence)

**D√©cision Go/No-Go :**
- [ ] UX, contenu et qualit√© satisfaisants ‚Üí Passer Phase 2 (Features Avanc√©es)
- [ ] Pertinence insuffisante ‚Üí +1 sprint am√©lioration scoring
- [ ] Besoin polish UX suppl√©mentaire ‚Üí +1 mois
- [ ] Feedback users n√©gatif ‚Üí It√©rer avant Phase 2

---

### Phase 2 : EXP√âRIENCE UTILISATEUR AVANC√âE (Mois 4-7)

**Objectif :** Personnaliser l'exp√©rience, comprendre les besoins users, rendre le site indispensable

**Focus :** Personnalisation, Engagement, User Insights, Feedback loops

**Pourquoi ces features :**
- **Auth/Accounts** ‚Üí Sauvegarder pr√©f√©rences utilisateur, synchroniser entre devices
- **Personnalisation** ‚Üí Veille adapt√©e aux int√©r√™ts de chacun (vs g√©n√©rique)
- **Analytics** ‚Üí Comprendre ce qui marche, am√©liorer continuellement
- *(Bonus: infrastructure billing pr√©par√©e mais optionnelle, non activ√©e)*

**Timeline :** 16 semaines (si 20% temps)
**Total SP :** ~68 SP

---

#### Mois 4 (Semaines 13-16) : Comptes Utilisateurs & Pr√©f√©rences Sauvegard√©es

**Sprint 7-8 (Sem 13-16) : User Accounts (UX Benefit: Sync pr√©f√©rences) - 21 SP**

**B√©n√©fice Utilisateur :** Sauvegarder ses pr√©f√©rences (cat√©gories favorites, filtres), synchroniser entre devices (mobile/desktop)

**Semaine 13-16 (4 semaines) :**
- [UX] **NextAuth.js Integration** (21 SP)
  - Setup NextAuth.js (providers : Email, Google, GitHub)
  - User model (id, email, name, image, pr√©f√©rences)
  - Session management (JWT)
  - Sauvegarde pr√©f√©rences par user (cat√©gories, filtres)
  - Synchronisation automatique entre devices
  - *(Bonus: Workspace/Team support pr√©par√© pour futur partage)*
  - **Deliverable :** Users peuvent cr√©er compte, sauvegarder pr√©f√©rences, sync entre devices

---

#### Mois 5 (Semaines 17-20) : Veille Personnalis√©e √† Vos Int√©r√™ts

**Sprint 9-10 (Sem 17-20) : Personnalisation Avanc√©e (UX Benefit: Pertinence 100%) - 13 SP**

**B√©n√©fice Utilisateur :** Articles adapt√©s √† VOS int√©r√™ts, pas une veille g√©n√©rique. Gain de temps maximum.

**Semaine 17-20 (4 semaines) :**
- [CONTENU + UX] **Personnalisation Intelligente** (13 SP)
  - **Profil utilisateur** : topics pr√©f√©r√©s (ML, Orchestration, Cloud, etc.)
  - **Sources custom** (ajouter vos propres feeds RSS)
  - **Scoring personnalis√©** : boost topics pr√©f√©r√©s dans calcul `final_score`
    - Exemple: Si user pr√©f√®re "ML", articles ML re√ßoivent bonus +10 points
    - Seuils adaptatifs par user (vs seuils globaux)
  - **Filtres sauvegard√©s** ("Mes recherches") - acc√®s rapide
  - **Digest email optionnel** (r√©sum√© hebdo personnalis√© dans inbox)
  - **Mode "Focus"** : uniquement vos cat√©gories favorites
  - **Blacklist keywords** : masquer sujets non pertinents pour vous
  - **Deliverable :** Chaque user voit SA veille, pertinence 100% personnalis√©e

---

#### Mois 6 (Semaines 21-24) : Comprendre les Utilisateurs & Am√©liorer

**Sprint 11-12 (Sem 21-24) : User Insights & Feedback (UX Benefit: Am√©lioration Continue) - 13 SP**

**B√©n√©fice Utilisateur :** Site qui s'am√©liore chaque semaine bas√© sur ce que VOUS utilisez r√©ellement.

**Semaine 21-24 (4 semaines) :**
- [CONTENU + UX] **User Insights & Feedback Loops** (13 SP)
  - **Feedback pertinence** : bouton "Article utile ?" (üëç/üëé) sur chaque article
    - Stockage feedback par article_id
    - Analyse articles mal not√©s (faux positifs √† √©liminer)
    - R√©ajustement scoring bas√© sur feedback r√©el
  - **Tracking anonyme** : articles populaires, recherches fr√©quentes
  - **Dashboard insights** : quels topics/sources int√©ressent le plus
  - **Sondages optionnels** ("Trop de bruit ?", "Cat√©gories manquantes ?")
  - **Changelog public** (voir les am√©liorations scoring/sources chaque semaine)
  - **Privacy-first** : opt-out tracking, z√©ro data vendue
  - **Am√©lioration ML scoring** : utiliser feedback pour fine-tuner embeddings
  - **Deliverable :** Boucle feedback ‚Üí am√©lioration pertinence continue bas√©e sur usage r√©el

---

#### Mois 7 (Semaines 25-28) : ‚öôÔ∏è Infrastructure Optionnelle (Billing - Optionnel)

**Sprint 13-14 (Sem 25-28) : [OPTIONNEL] Pr√©paration Mon√©tisation Future - 21 SP**

**Note :** Cette √©tape est **100% optionnelle** et peut √™tre **skipp√©e** ou **report√©e apr√®s M9**.
Elle pr√©pare l'infrastructure pour mon√©tiser un jour, SI vous d√©cidez de le faire. Pas obligatoire pour excellente UX.

**Alternative recommand√©e si pas prioritaire :**
- **Skip** et passer directement √† Phase 3 (Polish UX Continu)
- Ou investir ces 21 SP dans **plus de features UX** (mode sombre, export PDF, notifications, mobile app, etc.)

**Si vous voulez quand m√™me pr√©parer billing (pour future optionnalit√©) :**
- [INFRA] **Stripe Integration (Code Ready, OFF)** (21 SP)
  - Stripe integration (Checkout, Customer Portal)
  - Plans conceptuels : Free, Pro, Team (pricing √† d√©finir plus tard)
  - Paywalls code (dormants, jamais activ√©s)
  - **CRITIQUE :** Code ready MAIS billing **100% disabled** (env var `BILLING_ENABLED=false`)
  - **Deliverable :** Infrastructure dormante, activation possible en 1 ligne (si besoin un jour)

---

### üèÅ Fin Phase 2 (Mois 7) : Checkpoint (UX + Contenu) Avanc√©e

**R√©sultats Attendus (UX) :**
- ‚úÖ Comptes utilisateurs fonctionnels (sync pr√©f√©rences)
- ‚úÖ Personnalisation compl√®te (filtres, sauvegardes, mode focus)
- ‚úÖ Feedback loops actifs (users peuvent am√©liorer le site)
- ‚úÖ Insights sur usage r√©el (am√©liorations data-driven)
- ‚úÖ Changelog public (transparence sur am√©liorations)
- (Optionnel) Billing infrastructure pr√©par√©e (dormante)

**R√©sultats Attendus (Contenu & Pertinence) :**
- ‚úÖ **Scoring personnalis√©** par user (boost topics pr√©f√©r√©s)
- ‚úÖ **Sources custom** par user (ajout RSS personnels)
- ‚úÖ **Feedback pertinence** actif (üëç/üëé sur articles)
- ‚úÖ **Am√©lioration ML scoring** bas√©e sur feedback r√©el
- ‚úÖ Blacklist keywords par user (masquer sujets non pertinents)
- ‚úÖ **Pertinence per√ßue > 90%** (mesure via feedback)

**√âtat Produit :** üéØ **Site Indispensable pour Users** - Personnalis√© (UX + Contenu), am√©lioration continue

**Crit√®res Succ√®s :**
- ‚úÖ Users reviennent chaque semaine (r√©tention > 70%)
- ‚úÖ **"Veille utile cette semaine" > 80%** (sondage hebdo)
- ‚úÖ Feedback positif global (NPS > 50)
- ‚úÖ **Feedback pertinence articles > 90%** (ratio üëç/üëé)
- ‚úÖ Temps pass√© par session en hausse
- ‚úÖ Articles ouverts/affich√©s > 30%

**D√©cision Phase 3 :**
- [ ] UX + Contenu excellents, users adorent ‚Üí Polish continu (Phase 3)
- [ ] Pertinence insuffisante ‚Üí +1 sprint am√©lioration scoring/sources
- [ ] Users veulent plus features ‚Üí Backlog features (UX + Contenu) additionnelles
- [ ] Opportunit√© mon√©tisation √©vidente ‚Üí Optionnellement activer billing (pas obligatoire)

---

### Phase 3 : POLISH CONTINU & FEATURES UX BONUS (Mois 8-9+)

**Objectif :** Am√©liorer l'exp√©rience continuellement, ajouter features demand√©es par users

**Focus :** UX polish, Features bonus, Am√©lioration continue bas√©e feedback users

**Timeline :** Flexible, continu
**Total SP :** D√©pend des priorit√©s users

**Options pour Phase 3 (choisir selon feedback Phase 2) :**

---

#### Option A : Features UX Bonus (Recommand√©)

**Focus :** Ajouter features que les users demandent le plus (bas√© sur feedback Phase 2)

**Exemples Features (UX + Contenu) - Choisir 3-4 selon demande users :**

**Sprint 15-16 (Sem 29-32) : Features Bonus Populaires - 18-23 SP**

**Cat√©gorie UX :**
- **Mode Sombre** (3 SP)
  - Toggle dark/light mode
  - Pr√©f√©rence sauvegard√©e par user
  - Design moderne et accessible

- **Export PDF Digest Hebdo** (5 SP)
  - G√©n√©rer PDF du digest hebdo
  - Partage facile avec √©quipe
  - Branding configurable

- **Notifications Slack/Discord** (5 SP)
  - Webhook r√©sum√© hebdo dans Slack
  - Configur√© par user (optionnel)
  - R√©sum√© top articles de la semaine

- **Bookmarks & Collections** (5 SP)
  - Sauvegarder articles favoris
  - Organiser en collections ("√Ä lire", "R√©f√©rences", etc.)
  - Synchronis√© entre devices

- **Mobile PWA** (8 SP)
  - Progressive Web App (installable)
  - Offline support (service worker)
  - Notifications push (optionnel)

- **Partage Social Optimis√©** (3 SP)
  - Open Graph tags
  - Twitter Cards
  - Copy link with preview

**Cat√©gorie Contenu & Pertinence :**
- **üéØ Am√©lioration R√©sum√©s LLM** (5 SP)
  - R√©sum√©s plus concis et structur√©s
  - Extraction points cl√©s (bullets)
  - D√©tection code snippets importants
  - A/B test diff√©rents prompts LLM

- **üéØ Expansion Sources Automatique** (5 SP)
  - Crawler GitHub trending repos (data engineering)
  - Int√©grer Reddit r/dataengineering hot posts
  - Hacker News (tag: data/databases)
  - Auto-d√©couverte RSS via OPML import

- **üéØ D√©tection Tendances** (8 SP)
  - Identifier topics montants (spike mentions)
  - Section "Trending This Week"
  - Alertes sur technologies √©mergentes
  - Graph √©volution popularit√© tools

- **üéØ Am√©lioration Classification LLM** (3 SP)
  - Fine-tuning prompts bas√© sur feedback users
  - Multi-label categories (vs single)
  - Confidence score affich√©
  - Permettre recat√©gorisation manuelle

**Deliverable :** Features bonus (UX + Contenu) demand√©es par users

---

#### Option B : Mon√©tisation (100% Optionnel)

**‚ö†Ô∏è IMPORTANT :** Cette option n'est recommand√©e QUE SI :
- Users demandent explicitement des features payantes
- Vous avez besoin de financer infrastructure (co√ªts serveur √©lev√©s)
- Opportunit√© commerciale √©vidente

**Sinon, pr√©f√©rer Option A (Features UX) ou continuer gratuitement.**

**Si vous choisissez quand m√™me de mon√©tiser :**

**Sprint 15 (Sem 29-30) : Activation Billing (si billing pr√©par√© en M7) - 5 SP**
- Activer `BILLING_ENABLED=true`
- Onboarding flow payant
- Pricing page simple
- FAQ billing

**Sprint 16 (Sem 31-32) : Marketing Soft Launch - 3 SP**
- Annonce communaut√© existante
- Post Reddit/LinkedIn
- Outreach beta users

---

#### Mois 9+ : Am√©lioration Continue (Permanent)

**Sprint 17-18+ (Sem 33-36+) : It√©ration Bas√©e Feedback Users**

**Mode permanent : Am√©lioration continue chaque semaine**

**Boucle hebdomadaire recommand√©e :**
1. **Lundi** : Review feedback users semaine pr√©c√©dente
2. **Mardi-Jeudi** : Impl√©menter 1-2 quick wins UX
3. **Vendredi** : Test + deploy am√©liorations
4. **Samedi-Dimanche** : Repos (ou monitoring passif)

**Exemples it√©rations continues :**
- **Quick Fixes UX** (bas√© feedback)
  - Am√©liorer contraste couleurs (a11y)
  - Optimiser recherche (pertinence)
  - Fixer bugs signal√©s
  - Am√©liorer onboarding

- **Optimisations Contenu & Pertinence** (prioritaire chaque semaine)
  - Analyser feedback pertinence articles (üëç/üëé)
  - Ajuster seuils scoring bas√© sur faux positifs/n√©gatifs
  - Ajouter/retirer sources selon qualit√© r√©elle
  - Am√©liorer prompts LLM (classification + r√©sum√©s)
  - Tester nouveaux feeds RSS d√©couverts
  - Affiner anti-bruit filtering (marketing, beginner)

- **Optimisations Performance Technique**
  - R√©duire temps chargement
  - Optimiser crawling (parall√©lisation)
  - Cache warming

- **Nouvelles Features L√©g√®res** (demandes users)
  - Nouveaux filtres
  - Export formats additionnels
  - Int√©grations (Notion, Obsidian, etc.)

**M√©triques Suivi (UX + Contenu) :**
- **Pertinence** : Ratio üëç/üëé sur articles (> 90%)
- **Pertinence** : % articles ouverts vs affich√©s (> 30%)
- **R√©tention** : Hebdomadaire (> 70%)
- **Satisfaction** : NPS (Net Promoter Score > 50)
- **Engagement** : Temps pass√© par session
- **Qualit√© s√©lection** : Feedback "veille utile cette semaine" (> 80%)

---

### üèÅ Fin Phase 3 (Mois 9+) : Site d'Excellence UX

**R√©sultats Attendus (UX Excellence) :**
- ‚úÖ Site fiable, rapide, agr√©able √† utiliser
- ‚úÖ Personnalisation compl√®te par user
- ‚úÖ Feedback loops actifs (am√©lioration continue)
- ‚úÖ Features bonus demand√©es impl√©ment√©es
- ‚úÖ Communaut√© active et satisfaite
- (Optionnel) Mon√©tisation activ√©e si pertinent

**M√©triques Succ√®s (UX + Contenu) :**
- üéØ **Pertinence articles > 90%** (ratio üëç/üëé feedback users)
- üéØ **"Veille utile cette semaine" > 80%** (sondage hebdo)
- üéØ R√©tention hebdomadaire > 70%
- üéØ NPS (Net Promoter Score) > 50
- üéØ Performance Lighthouse > 90 (desktop + mobile)
- üéØ Temps pass√© par visite en hausse
- üéØ % articles ouverts vs affich√©s > 30%
- üéØ Bouche-√†-oreille positif (partages, recommandations)
- üéØ Z√©ro bugs critiques signal√©s

**√âtat Final :** üåü **Site Indispensable** - Les utilisateurs ne peuvent plus s'en passer
- **Contenu pertinent** : Articles vraiment utiles, z√©ro bruit
- **Exp√©rience excellente** : Rapide, agr√©able, accessible

---

## üìä Vue d'Ensemble Timeline (Flexible, UX + Contenu First)

```
Mois 1-3 : FONDATIONS (UX + CONTENU) & QUALIT√â üèóÔ∏è
‚îú‚îÄ M1 : Abstraction LLM + Monitoring + Tests frontend
‚îú‚îÄ M2 : üéØ Am√©lioration Pertinence + CI/CD + Cache Redis
‚îÇ       ‚Ä¢ Audit scoring, anti-bruit, seuils, sources
‚îî‚îÄ M3 : Tests E2E + Staging + Mobile UX + Accessibilit√©
R√©sultat : Site fiable, rapide, accessible + Articles pertinents ‚úÖ

Mois 4-7 : EXP√âRIENCE UTILISATEUR AVANC√âE (UX + CONTENU) üéØ
‚îú‚îÄ M4 : Comptes utilisateurs (sync pr√©f√©rences)
‚îú‚îÄ M5 : Personnalisation (scoring adapt√©, sources custom)
‚îú‚îÄ M6 : Feedback loops (üëç/üëé pertinence, am√©lioration ML)
‚îî‚îÄ M7 : [OPTIONNEL] Billing infrastructure (dormante)
R√©sultat : Site personnalis√©, pertinence 100%, indispensable ‚úÖ

Mois 8-9+ : POLISH CONTINU & FEATURES BONUS üåü
‚îú‚îÄ M8-9 : Option A (Recommand√©) - Features UX + Contenu
‚îÇ         ‚Ä¢ UX: Mode sombre, Export PDF, PWA, Bookmarks
‚îÇ         ‚Ä¢ Contenu: R√©sum√©s am√©lior√©s, D√©tection tendances, Sources auto
‚îÇ
‚îî‚îÄ M8-9 : Option B (Optionnel) - Mon√©tisation si pertinent
          ‚Ä¢ Activation billing, Marketing soft launch

R√©sultat : Site d'excellence (UX + Contenu), users adorent ‚úÖ
```

**Timeline : Flexible** - Pas de deadline mon√©tisation
**Objectif #1 :** Faire un site utile avec une vraie bonne exp√©rience pour les utilisateurs

**2 Piliers Indissociables :**
1. üé® **Exp√©rience Utilisateur** - Site rapide, agr√©able, accessible
2. üìä **Qualit√© Contenu & Pertinence** - Articles vraiment utiles, z√©ro bruit

---

## üéØ Actions Imm√©diates (Cette Semaine)

### Semaine 1 : Abstraction LLM (P0 CRITIQUE) ‚ö†Ô∏è

**Pourquoi maintenant :**
- Risque mortel (Groq discontinu√© = projet mort)
- Quick Win (3 SP = 1-2 jours)
- Bloque rien d'autre (peut parall√©liser apr√®s)

**√âtapes :**

**Jour 1 : Design + Interface**
1. Cr√©er `backend/llm_provider.py` :
```python
from abc import ABC, abstractmethod
from typing import Dict, Any

class LLMProvider(ABC):
    """Interface pour providers LLM interchangeables."""

    @abstractmethod
    def classify(self, title: str, summary: str, categories: list) -> Dict[str, Any]:
        """Classifie un article.

        Returns:
            {
                "category_key": str,
                "confidence": float,
                "reasoning": str
            }
        """
        pass

    @abstractmethod
    def summarize(self, context: str, instructions: str) -> str:
        """G√©n√®re un r√©sum√©.

        Returns:
            str: R√©sum√© markdown format√©
        """
        pass


class GroqProvider(LLMProvider):
    """Provider Groq (actuel)."""

    def __init__(self, api_key: str, model: str = "llama-3.1-8b-instant"):
        import openai
        self.client = openai.OpenAI(
            base_url="https://api.groq.com/openai/v1",
            api_key=api_key
        )
        self.model = model

    def classify(self, title, summary, categories):
        # Code existant classify_llm.py
        ...

    def summarize(self, context, instructions):
        # Code existant summarize_week_llm.py
        ...


class OpenAIProvider(LLMProvider):
    """Provider OpenAI (fallback si Groq down)."""

    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        import openai
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model

    def classify(self, title, summary, categories):
        # M√™me logique que Groq
        ...

    def summarize(self, context, instructions):
        # M√™me logique que Groq
        ...


class OllamaProvider(LLMProvider):
    """Provider Ollama (local, z√©ro co√ªt)."""

    def __init__(self, base_url: str = "http://localhost:11434", model: str = "llama3.1"):
        import openai
        self.client = openai.OpenAI(
            base_url=f"{base_url}/v1",
            api_key="ollama"  # Dummy key
        )
        self.model = model

    def classify(self, title, summary, categories):
        # M√™me logique
        ...

    def summarize(self, context, instructions):
        # M√™me logique
        ...


def get_provider(config: dict) -> LLMProvider:
    """Factory pour cr√©er le bon provider depuis config.

    Args:
        config: config.yaml pars√© (section llm)

    Returns:
        LLMProvider instance

    Example config.yaml:
        llm:
          provider: groq  # ou openai, ou ollama
          groq:
            api_key_env: GROQ_API_KEY
            model: llama-3.1-8b-instant
          openai:
            api_key_env: OPENAI_API_KEY
            model: gpt-4o-mini
          ollama:
            base_url: http://localhost:11434
            model: llama3.1
    """
    provider_name = config.get("provider", "groq")

    if provider_name == "groq":
        import os
        api_key = os.getenv(config["groq"]["api_key_env"])
        model = config["groq"].get("model", "llama-3.1-8b-instant")
        return GroqProvider(api_key, model)

    elif provider_name == "openai":
        import os
        api_key = os.getenv(config["openai"]["api_key_env"])
        model = config["openai"].get("model", "gpt-4o-mini")
        return OpenAIProvider(api_key, model)

    elif provider_name == "ollama":
        base_url = config["ollama"].get("base_url", "http://localhost:11434")
        model = config["ollama"].get("model", "llama3.1")
        return OllamaProvider(base_url, model)

    else:
        raise ValueError(f"Unknown LLM provider: {provider_name}")
```

**Jour 2 : Refactor + Config + Tests**

2. Refactor `classify_llm.py` :
```python
from llm_provider import get_provider

# Load config
with open("config.yaml") as f:
    config = yaml.safe_load(f)

# Get provider
provider = get_provider(config["llm"])

# Use provider
result = provider.classify(title, summary, categories)
```

3. Refactor `summarize_week_llm.py` (m√™me pattern)

4. Update `config.yaml` :
```yaml
llm:
  provider: groq  # Switchable ici
  groq:
    api_key_env: GROQ_API_KEY
    model: llama-3.1-8b-instant
  openai:
    api_key_env: OPENAI_API_KEY
    model: gpt-4o-mini
  ollama:
    base_url: http://localhost:11434
    model: llama3.1
```

5. Tests :
```python
# test_llm_provider.py
def test_switch_provider_groq():
    config = {"provider": "groq", "groq": {...}}
    provider = get_provider(config)
    assert isinstance(provider, GroqProvider)

def test_switch_provider_openai():
    # ...

def test_fallback_if_groq_down():
    # Mock Groq failure ‚Üí switch OpenAI
    # ...
```

6. Documentation README :
```markdown
## LLM Provider Configuration

Le syst√®me supporte 3 providers LLM interchangeables :

**Groq (d√©faut, gratuit) :**
```yaml
llm:
  provider: groq
  groq:
    api_key_env: GROQ_API_KEY
```

**OpenAI (fallback si Groq down) :**
```yaml
llm:
  provider: openai
  openai:
    api_key_env: OPENAI_API_KEY
    model: gpt-4o-mini  # Moins cher que gpt-4
```

**Ollama (local, z√©ro co√ªt) :**
1. Install Ollama : https://ollama.com
2. Download model : `ollama pull llama3.1`
3. Config :
```yaml
llm:
  provider: ollama
  ollama:
    base_url: http://localhost:11434
    model: llama3.1
```

**Liverable Semaine 1 :**
- ‚úÖ Abstraction LLM provider
- ‚úÖ 3 providers (Groq, OpenAI, Ollama)
- ‚úÖ Config YAML switchable
- ‚úÖ Tests provider switching
- ‚úÖ Docs README
- ‚úÖ **Risque Groq mitig√©** ‚ö†Ô∏è ‚Üí ‚úÖ

---

## üìà Tracking & KPIs par Phase

### Phase 1 (Mois 1-3) : Qualit√©

**KPIs Techniques :**
- Score Sant√© : 73/100 ‚Üí 85/100
- Coverage tests : Backend 60% + Frontend 50% + E2E flows
- Performance Lighthouse : 70-80 ‚Üí 90+
- Monitoring : 0 erreurs silencieuses (Sentry actif)
- Temps scoring : 10 min ‚Üí 5 min (cache Redis)

**Deliverables :**
- [ ] Abstraction LLM (risque mitig√©)
- [ ] Monitoring Sentry actif
- [ ] Tests > 70% coverage
- [ ] CI/CD tests automatiques
- [ ] Cache Redis functional
- [ ] Perf > 90 Lighthouse
- [ ] Staging env d√©ploy√©

---

### Phase 2 (Mois 4-7) : Exp√©rience Utilisateur Avanc√©e

**KPIs UX :**
- Comptes cr√©√©s : 10+ users inscrits (opt-in)
- Personnalisation : 80%+ users configurent profil
- Feedback actif : 50%+ users donnent feedback
- R√©tention : 70%+ users reviennent chaque semaine
- Satisfaction : NPS > 50

**Deliverables :**
- [ ] Comptes utilisateurs (sync pr√©f√©rences)
- [ ] Personnalisation compl√®te
- [ ] Feedback loops actifs
- [ ] User insights dashboards
- (Optionnel) Billing infrastructure pr√©par√©e

---

### Phase 3 (Mois 8-9+) : Polish Continu & Features Bonus

**KPIs UX :**
- R√©tention hebdomadaire : > 70%
- NPS : > 50 (utilisateurs tr√®s satisfaits)
- Performance : Lighthouse > 90 maintenu
- Engagement : Temps par visite en hausse
- Bouche-√†-oreille : Partages/recommandations organiques
- Features utilis√©es : > 80% users utilisent personnalisation

**Deliverables (Option A - Recommand√©) :**
- [ ] Mode sombre impl√©ment√©
- [ ] Export PDF fonctionnel
- [ ] PWA installable
- [ ] Bookmarks & collections
- [ ] Notifications configurables
- [ ] Am√©liorations continues bas√©es feedback

**Deliverables (Option B - Optionnel) :**
- [ ] Billing activ√© (si pertinent)
- [ ] Marketing soft launch
- [ ] Support communaut√©

---

## üîÑ Revue & Ajustements

### Fr√©quence de Revue

**Hebdomadaire (Chaque Lundi) :**
- Review tasks semaine pr√©c√©dente
- Plan semaine suivante
- Ajuster si blocages

**Mensuelle (Fin de Mois) :**
- Review sprint/phase
- M√©triques KPIs
- D√©cision Go/No-Go phase suivante

**Prochaine revue majeure :** Fin Mois 3 (Phase 1 Qualit√©)
- D√©cider si qualit√© suffisante ‚Üí Go Phase 2
- Ou besoin +1 mois polish

---

## üéØ R√©sum√© Ex√©cutif

**Objectif #1 (PRIORIT√â ABSOLUE) :**
> **"Faire un site utile avec une vraie bonne exp√©rience pour mes utilisateurs"**

**Cela signifie 2 piliers indissociables :**
1. üé® **Exp√©rience Utilisateur (UX)** - Site rapide, agr√©able, accessible
2. üìä **Qualit√© Contenu & Pertinence** - Articles vraiment utiles, moins de bruit, meilleur scoring

**Strat√©gie :** Excellence (UX + Contenu) ‚Üí Engagement Utilisateurs ‚Üí (Optionnel) Mon√©tisation

**Timeline :** Flexible, pas de deadline mon√©tisation

**Phases :**
1. **Mois 1-3 :** Fondations (UX + Contenu) & Qualit√©
   - Dette tech, tests, perf, mobile, a11y
   - üéØ **Am√©lioration pertinence** (audit scoring, anti-bruit, seuils, sources)
2. **Mois 4-7 :** Exp√©rience Utilisateur Avanc√©e (UX + Contenu)
   - Personnalisation (scoring adapt√©, sources custom)
   - Feedback loops (üëç/üëé pertinence, am√©lioration ML)
3. **Mois 8-9+ :** Polish Continu & Features Bonus
   - UX: Mode sombre, Export PDF, PWA, Bookmarks
   - Contenu: R√©sum√©s am√©lior√©s, D√©tection tendances, Sources auto

**Quick Win Imm√©diat :** Abstraction LLM (Semaine 1, 3 SP) ‚ö†Ô∏è

**Effort Estim√© :**
- Phase 1 : ~65 SP (qualit√© + UX basics + pertinence)
- Phase 2 : ~47 SP (UX + Contenu avanc√©s, billing optionnel)
- Phase 3 : Variable (selon demandes users)

**Velocity :** 5-8 SP/sprint (20% temps)

**Date "Site d'Excellence" Projet√© :** 7-9 mois (flexible)

**Mon√©tisation :** Optionnelle, quand/si pertinent - Pas une priorit√©

---

**üöÄ Prochaine Action Imm√©diate : Abstraction LLM (Cette Semaine)**

Voir d√©tails "Actions Imm√©diates (Cette Semaine)" ci-dessus.

---

*Roadmap cr√©√©e le : 2025-12-20*
*Mise √† jour : 2025-12-20 (Alignement sur objectif UX-First)*
*Bas√©e sur : Vos 10 r√©ponses + 4 d√©cisions strat√©giques + clarification objectif #1*
*Revue prochaine : Fin Mois 3 (checkpoint UX & qualit√©)*

---

## üìù Note sur le Changement de Strat√©gie

**Version initiale (avant clarification) :**
- Focus : Produit commercial pr√™t en 9 mois
- Phases : Qualit√© ‚Üí Features Commerciales ‚Üí Mon√©tisation
- Deadline : Lancement commercial M9

**Version mise √† jour (apr√®s clarification objectif #1) :**
- **Focus : "Faire un site utile avec une vraie bonne exp√©rience pour mes utilisateurs"**
- **2 Piliers :** üé® UX (Site rapide, agr√©able) + üìä Contenu (Articles pertinents, z√©ro bruit)
- Phases : Excellence (UX + Contenu) ‚Üí Engagement Utilisateurs ‚Üí (Optionnel) Mon√©tisation
- Timeline : Flexible, pas de deadline mon√©tisation
- Mon√©tisation : Optionnelle, quand/si pertinent - Pas une priorit√©

**Changements cl√©s :**
1. ‚úÖ **Ajout pilier Contenu & Pertinence** (√©quivalent importance vs UX)
2. ‚úÖ Phase 1 enrichie : Ajout Mobile UX + Accessibilit√© + **Sprint Am√©lioration Pertinence (5 SP)**
3. ‚úÖ Phase 2 renomm√©e : "Features Commerciales" ‚Üí "Exp√©rience Utilisateur Avanc√©e (UX + Contenu)"
4. ‚úÖ Phase 2 reframed : Auth/Personnalisation/Analytics pr√©sent√©es comme features UX + Contenu
5. ‚úÖ Phase 2 M5 : Personnalisation inclut **scoring adapt√©** (boost topics pr√©f√©r√©s)
6. ‚úÖ Phase 2 M6 : Feedback loops incluent **feedback pertinence** (üëç/üëé articles)
7. ‚úÖ Phase 2 M7 : Billing infrastructure devenue 100% optionnelle (peut √™tre skipp√©e)
8. ‚úÖ Phase 3 compl√®tement revue : "Mon√©tisation" ‚Üí "Polish Continu & Features (UX + Contenu)"
9. ‚úÖ Phase 3 Options Contenu : R√©sum√©s am√©lior√©s, D√©tection tendances, Expansion sources auto
10. ‚úÖ KPIs chang√©s : MRR/Churn ‚Üí R√©tention/NPS/Engagement/**Pertinence articles > 90%**
11. ‚úÖ Crit√®res succ√®s : "Commercial-Ready" ‚Üí "Site Indispensable (UX + Contenu)"

**Philosophie :**
> Construire le meilleur site de veille tech pour Data Engineers.
> **Sans pertinence du contenu, l'UX ne sert √† rien.**
> **Sans bonne UX, m√™me le meilleur contenu ne sera pas utilis√©.**
> Si l'exp√©rience ET le contenu sont excellents, la mon√©tisation viendra naturellement (ou pas, et c'est ok).

**Vous gardez toute flexibilit√© :**
- Mon√©tiser plus tard si besoin de financer infrastructure
- Rester gratuit si vous pr√©f√©rez (open source, communaut√©)
- D√©cider au fil de l'eau selon feedback users
