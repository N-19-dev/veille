# ============================================
#               STORAGE
# ============================================
storage:
  sqlite_path: "veille.db"

# ============================================
#               CRAWL
# ============================================
crawl:
  lookback_days: 7
  concurrency: 12
  per_host_rps: 1.5
  timeout_sec: 25
  user_agent: "VeilleTechBot/1.0 (+https://github.com/nathansornet/veille_tech_crawling)"
  min_text_length: 300

  # On ne met pas de whitelist ‚Üí le filtrage se fait via regex + pertinence
  # whitelist_domains: []


  # URLs typiques d‚Äôarticles √©ditoriaux
  path_allow_regex: "(?i)(/blog|/posts?|/post|/articles?|/news|/p/|^/@|/tag/|/t/|/n/|/stories?)"
  path_deny_regex:  "(?i)(forum|community|jobs|careers|events|release[-_ ]?notes|whats[-_ ]?new|changelog|\\bdocs?\\b|/api/|/sdk/|buzz|people|marketing|podcast|social)"

# ============================================
#               EXPORT
# ============================================
export:
  out_dir: "export"
  make_markdown_digest: true      # utilis√© par veille_tech.py pour le digest brut
  max_items_per_cat: 60

# ============================================
#               NOTIFICATION (OPTIONNEL)
# ============================================
notify:
  slack_webhook_env: "SLACK_WEBHOOK_URL"

# ============================================
#          MONITORING & LOGGING
# ============================================
monitoring:
  # Niveau de log: DEBUG, INFO, WARNING, ERROR
  log_level: "INFO"

  # Export des m√©triques vers un fichier JSON
  export_metrics: true

  # Optionnel: Sentry pour tracking des erreurs en production
  # sentry_dsn_env: "SENTRY_DSN"

  # M√©triques collect√©es automatiquement:
  # - feeds_processed: nombre de feeds trait√©s
  # - feeds_failed: nombre de feeds en erreur
  # - articles_crawled: nombre d'articles r√©cup√©r√©s
  # - articles_filtered: nombre d'articles filtr√©s
  # - llm_calls: nombre d'appels LLM
  # - errors: liste des erreurs rencontr√©es

# ============================================
#               CATEGORIES (Data Engineer)
# ============================================
categories:
  - key: "warehouses_engines"
    title: "üèõÔ∏è Warehouses & Query Engines"
    keywords: ["snowflake","databricks","bigquery","redshift","athena","trino","duckdb","spark","starrocks","clickhouse","warehouse","lakehouse"]

  - key: "etl_orchestration"
    title: "üîÑ Orchestration, ETL & Data Movement"
    keywords: ["airflow","dagster","prefect","airbyte","meltano","dbt","sqlmesh","dataform","ingestion","pipeline","batch","elt","etl"]

  - key: "data_modeling_governance"
    title: "üìê Data Modeling, Governance & Quality"
    keywords: ["data modeling","star schema","data vault","governance","catalog","lineage","quality","expectations","datafold","great expectations","unity catalog","semantic layer"]

  - key: "lake_storage_formats"
    title: "üóÑÔ∏è Data Lakes, Storage & Formats"
    keywords: ["parquet","iceberg","delta lake","hudi","s3","gcs","adls","lake","compaction","partitions","object storage"]

  - key: "cloud_infra_observability"
    title: "‚òÅÔ∏è Cloud, Infra & Observability"
    keywords: ["aws","gcp","azure","ovh","terraform","kubernetes","k8s","cost","observability","monitoring","grafana","datadog","prometheus"]

  - key: "python_analytics"
    title: "üêç Python, Analytics & Tools"
    keywords: ["python","polars","pandas","duckdb","fastapi","sql","analytics engineering"]

  - key: "ai_data_engineering"
    title: "ü§ñ AI for Data Engineering"
    keywords: ["mlops","llm","rag","genai","embedding","vector db","feature store","ml","ai"]

  - key: "news"
    title: "üì∞ Tech / Cloud / IA News"
    keywords: ["ia","cloud","data","innovation","cybers√©curit√©","technologie"]

# ============================================
#          THRESHOLDS PAR CAT√âGORIE
# ============================================
# seuils sur final_score (0‚Äì100) pour la s√©lection par cat√©gorie
category_thresholds:
  warehouses_engines: 50
  etl_orchestration: 50
  data_modeling_governance: 50
  lake_storage_formats: 50
  cloud_infra_observability: 55
  python_analytics: 55
  ai_data_engineering: 50
  news: 60

# ============================================
#               SOURCES
# ============================================
sources:

  # --- DATA WAREHOUSE / ENGINES ---
  - name: "Snowflake Blog"
    url: "https://www.snowflake.com/blog/feed/"

  - name: "Databricks Blog"
    url: "https://databricks.com/feed"

  - name: "BigQuery Blog"
    url: "https://cloud.google.com/bigquery/rss.xml"

  - name: "Redshift / AWS Big Data"
    url: "https://aws.amazon.com/blogs/big-data/feed/"

  - name: "DuckDB Blog"
    url: "https://duckdb.org/news/index.xml"

  - name: "Polars Blog"
    url: "https://www.pola.rs/feed.xml"

  - name: "Trino Blog"
    url: "https://trino.io/feed.xml"

  - name: "ClickHouse Blog"
    url: "https://clickhouse.com/blog/rss"

  - name: "StarRocks Blog"
    url: "https://www.starrocks.io/blog/rss"


  # --- ETL / ORCHESTRATION / TRANSFORM ---
  - name: "Apache Airflow Blog"
    url: "https://airflow.apache.org/feeds/blog.xml"

  - name: "Astronomer Blog"
    url: "https://www.astronomer.io/blog/rss.xml"

  - name: "Dagster Blog"
    url: "https://dagster.io/blog/rss.xml"

  - name: "Prefect Blog"
    url: "https://www.prefect.io/blog/rss.xml"

  - name: "dbt Blog"
    url: "https://www.getdbt.com/rss.xml"

  - name: "SQLMesh Blog"
    url: "https://sqlmesh.com/blog/feed.xml"

  - name: "Airbyte Blog"
    url: "https://airbyte.com/blog/rss.xml"

  - name: "Meltano Blog"
    url: "https://meltano.com/blog/index.xml"

  - name: "dlt Blog"
    url: "https://dlthub.com/blog/rss.xml"

  - name: "Rudderstack Blog"
    url: "https://www.rudderstack.com/blog/rss.xml"


  # --- MODELING / GOVERNANCE / QUALITY ---
  - name: "Datafold Blog"
    url: "https://www.datafold.com/blog/rss.xml"

  - name: "Great Expectations Blog"
    url: "https://greatexpectations.io/blog/feed"

  - name: "Collibra Blog"
    url: "https://www.collibra.com/us/en/blog/rss"


  # --- STORAGE / FORMATS / LAKEHOUSE ---
  - name: "Apache Iceberg"
    url: "https://iceberg.apache.org/feed.xml"

  - name: "Delta Lake"
    url: "https://delta.io/blog/index.xml"

  - name: "Apache Hudi"
    url: "https://hudi.apache.org/blog/feed.xml"

  - name: "MinIO Blog"
    url: "https://blog.min.io/index.xml"


  # --- CLOUD / INFRA / OBSERVABILITY ---
  - name: "AWS Blog"
    url: "https://aws.amazon.com/blogs/aws/feed/"

  - name: "Google Cloud Blog"
    url: "https://cloud.google.com/blog/feeds/posts/default"

  - name: "Azure Blog"
    url: "https://azure.microsoft.com/en-us/blog/feed/"

  - name: "Cloudflare Engineering"
    url: "https://blog.cloudflare.com/rss/"

  - name: "Grafana Labs"
    url: "https://grafana.com/blog/rss/"

  - name: "Datadog Engineering"
    url: "https://www.datadoghq.com/blog/engineering/rss/"


  # --- PYTHON / TOOLS ---
  - name: "FastAPI Blog"
    url: "https://fastapi.tiangolo.com/feed.xml"

  - name: "Pydantic Blog"
    url: "https://docs.pydantic.dev/latest/blog/feed.xml"


  # --- AI FOR DATA ENGINEERS ---
  - name: "Google AI Blog"
    url: "https://ai.googleblog.com/feeds/posts/default"

  - name: "Hugging Face Blog"
    url: "https://huggingface.co/blog/feed.xml"

  - name: "LangChain Blog"
    url: "https://blog.langchain.dev/rss/"

  - name: "Pinecone Blog"
    url: "https://www.pinecone.io/learn/feed.xml"

  - name: "Weights & Biases"
    url: "https://wandb.ai/site/rss.xml"

  - name: "Lightning AI"
    url: "https://lightning.ai/pages/blog/rss/"


  # --- üá´üá∑ / üá™üá∫ BLOGS TECH & CLOUD ---
  - name: "OCTO Talks!"
    url: "https://blog.octo.com/feed/"

  - name: "Ippon Technologies Blog"
    url: "https://blog.ippon.fr/feed.xml"

  - name: "OVHcloud Blog"
    url: "https://blog.ovhcloud.com/feed/"

  - name: "Scaleway Blog"
    url: "https://www.scaleway.com/en/blog/rss/"

  - name: "Clever Cloud"
    url: "https://www.clever-cloud.com/blog/feed.xml"

  - name: "Dataiku Blog"
    url: "https://blog.dataiku.com/rss.xml"

  - name: "Artefact Blog"
    url: "https://blog.artefact.com/feed/"

  - name: "Zenika Tech Blog"
    url: "https://blog.zenika.com/feed/"

  - name: "Theodo Tech Blog"
    url: "https://blog.theodo.com/feed/"


  # --- NEWSLETTERS DATA ENGINEERING ---
  - name: "VuTrinh ¬∑ Data Engineering"
    url: "https://vutr.substack.com/feed"

  - name: "Data Engineering Weekly"
    url: "https://www.dataengineeringweekly.com/feed"

  - name: "Start Data Engineering"
    url: "https://www.startdataengineering.com/index.xml"

  - name: "Seattle Data Guy"
    url: "https://seattledataguy.substack.com/feed"

  - name: "DataEngineer.io"
    url: "https://blog.dataengineer.io/feed"

  - name: "Blef ¬∑ Data (FR)"
    url: "https://www.blef.fr/blog/rss"


  # --- MEDIUM / DEV.TO / HASHNODE (CIBL√â UNIQUEMENT) ---
  - name: "Medium ¬∑ Data Engineering"
    url: "https://medium.com/tag/data-engineering/rss"

  - name: "Medium ¬∑ Data"
    url: "https://medium.com/tag/data/rss"

  - name: "Medium ¬∑ Machine Learning"
    url: "https://medium.com/tag/machine-learning/rss"

  - name: "dev.to ¬∑ data"
    url: "https://dev.to/t/data/rss"

  - name: "dev.to ¬∑ datascience"
    url: "https://dev.to/t/datascience/rss"

  - name: "dev.to ¬∑ machinelearning"
    url: "https://dev.to/t/machinelearning/rss"

  - name: "dev.to ¬∑ dataengineering"
    url: "https://dev.to/t/dataengineering/rss"

  - name: "Hashnode ¬∑ data"
    url: "https://hashnode.com/n/data/rss"

  - name: "Hashnode ¬∑ machine-learning"
    url: "https://hashnode.com/n/machine-learning/rss"


  # --- AGR√âGATEUR (OPTIONNEL) ---
  - name: "daily.dev"
    url: "https://daily.dev"

# ============================================
#           CONFIG PERTINENCE (relevance)
# ============================================
relevance:
  # Score global = combinaison de ces 4 composantes (0‚Äì100 chacune)
  weights:
    semantic: 0.55
    source:   0.20
    quality:  0.15
    tech:     0.10

  # Score minimal par d√©faut pour consid√©rer un article "bon"
  score_threshold: 60

  # Profil de veille pour les embeddings
  profile_text: >
    data engineering, data platform, data warehouse, lakehouse, dbt, airflow,
    dagster, prefect, spark, snowflake, databricks, bigquery, redshift, duckdb,
    orchestration, ingestion, etl, elt, data modeling, governance, quality,
    monitoring, observability, data contracts, lakehouse, iceberg, delta lake.

  # Poids des sources (0‚Äì1). Le reste tombe √† 0.4 par d√©faut.
  source_weights:
    "Data Engineering Weekly": 1.0
    "VuTrinh ¬∑ Data Engineering": 1.0
    "Start Data Engineering": 0.95
    "Seattle Data Guy": 0.95
    "Blef ¬∑ Data (FR)": 0.90
    "Snowflake Blog": 0.70
    "Databricks Blog": 0.70
    "dbt Blog": 0.70
    "Dagster Blog": 0.70
    "Apache Airflow Blog": 0.70
    "Airbyte Blog": 0.70
    "Meltano Blog": 0.70
    "dlt Blog": 0.70
    "OCTO Talks!": 0.70
    "Ippon Technologies Blog": 0.70
    "Zenika Tech Blog": 0.70
    "Dataiku Blog": 0.70
    "daily.dev": 0.30

  quality:
    min_len_good: 1500        # >1500 caract√®res => vrai article
    bonus_good_len: 20
    bonus_has_code: 10        # blocs de code markdown / HTML

  tech:
    keywords:
      - "airflow"
      - "dagster"
      - "prefect"
      - "dbt"
      - "spark"
      - "lakehouse"
      - "iceberg"
      - "delta lake"
      - "hudi"
      - "warehouse"
      - "orchestration"
      - "etl"
      - "elt"
      - "kafka"
      - "data contract"
      - "feature store"
      - "rag"
      - "llm"
    max_points: 20

# ============================================
#        CONFIG LLM (pour le r√©sum√©)
# ============================================
llm:
  provider: "openai_compat"
  base_url: "https://api.groq.com/openai/v1"
  api_key_env: "GROQ_API_KEY"
  model: "llama-3.1-8b-instant"
  temperature: 0.2
  max_tokens: 1200

summary:
  enabled: true
  max_sections: 8
  links_per_section: 5
  min_score: 45   # score minimal pour qu‚Äôun article entre dans le r√©sum√©