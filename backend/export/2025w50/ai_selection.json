{
  "ai_data_engineering": [
    {
      "url": "https://seattledataguy.substack.com/p/how-i-run-system-design-interviews",
      "title": "How I Run System Design Interviews for Data Engineers",
      "summary": "Why System Design Still Matters",
      "published_ts": 1765302841,
      "source_name": "Seattle Data Guy",
      "score": 67.13117784261703,
      "content_type": "rex",
      "tech_level": "intermediate",
      "marketing_score": 0
    },
    {
      "url": "https://www.databricks.com/blog/introducing-databricks-genai-partner-accelerators-data-engineering-migration",
      "title": "Introducing Databricks GenAI Partner Accelerators for Data Engineering & Migration",
      "summary": "Enterprises face increasing pressure to modernize their data stacks. Teams need to...",
      "published_ts": 1765317600,
      "source_name": "Databricks Blog",
      "score": 63.41874518990517,
      "content_type": "technical",
      "tech_level": "intermediate",
      "marketing_score": 0
    }
  ],
  "cloud_infra_observability": [
    {
      "url": "https://aws.amazon.com/blogs/big-data/introducing-aws-glue-5-1-for-apache-spark/",
      "title": "Introducing AWS Glue 5.1 for Apache Spark",
      "summary": "AWS recently announced Glue 5.1, a new version of AWS Glue that accelerates data integration workloads in AWS. AWS Glue 5.1 upgrades the Spark engines to Apache Spark 3.5.6, giving you newer Spark release along with the newer dependent libraries so you can develop, run, and scale your data integration workloads and get insights faster. In this post, we describe what’s new in AWS Glue 5.1, key highlights on Spark and related libraries, and how to get started on AWS Glue 5.1.",
      "published_ts": 1765315755,
      "source_name": "Redshift / AWS Big Data",
      "score": 52.24005499482155,
      "content_type": "technical",
      "tech_level": "intermediate",
      "marketing_score": 20
    }
  ],
  "data_modeling_governance": [
    {
      "url": "https://www.getdbt.com/blog/bring-structured-context-to-agentic-data-development-with-dbt",
      "title": "Bring structured context to agentic data development with dbt",
      "summary": "Make data development with agents safe, cost-efficient, and scalable with dbt structured context and MCP server.",
      "published_ts": 1765402080,
      "source_name": "dbt Blog",
      "score": 61.114116579294205,
      "content_type": "technical",
      "tech_level": "intermediate",
      "marketing_score": 0
    },
    {
      "url": "https://vutr.substack.com/p/9-lessons-that-will-put-you-3-years",
      "title": "9 lessons that will put you 3 years ahead as a data engineer",
      "summary": "It took me six years to distill these insights, but you can read them in just 10 minutes.",
      "published_ts": 1765250132,
      "source_name": "VuTrinh · Data Engineering",
      "score": 58.765823505818844,
      "content_type": "rex",
      "tech_level": "intermediate",
      "marketing_score": 5
    }
  ],
  "etl_orchestration": [
    {
      "url": "https://dagster.io/blog/impedance-mismatch-in-data-orchestration",
      "title": "Fixing the Data Engineering Mismatch",
      "summary": "Why asset-oriented orchestration leads to better developer experience and less brittle pipelines than traditional workflow-centric systems.",
      "published_ts": 1765550380,
      "source_name": "Dagster Blog",
      "score": 66.21813440322876,
      "content_type": "technical",
      "tech_level": "intermediate",
      "marketing_score": 0
    },
    {
      "url": "https://dagster.io/blog/deepdive-recap-evolution-data-platform",
      "title": "Evolution of the Data Platform with Dagster",
      "summary": "Dagster and SDF connect local dev environments with production pipelines, enabling full lifecycle orchestration with clear asset lineage.",
      "published_ts": 1765461515,
      "source_name": "Dagster Blog",
      "score": 63.790422052145004,
      "content_type": "technical",
      "tech_level": "intermediate",
      "marketing_score": 0
    },
    {
      "url": "https://www.uber.com/blog/from-batch-to-streaming-accelerating-data-freshness-in-ubers-data-lake/",
      "title": "From Batch to Streaming: Accelerating Data Freshness in Uber’s Data Lake",
      "summary": "Learn how Uber moved from batch to streaming ingestion with IngestionNext, reducing data latency and unlocking real-time analytics across its petabyte-scale data lake.",
      "published_ts": 1765461600,
      "source_name": "Uber Engineering Blog",
      "score": 63.64556208252907,
      "content_type": "technical",
      "tech_level": "intermediate",
      "marketing_score": 5
    }
  ],
  "news": [
    {
      "url": "https://www.dataengineeringweekly.com/p/data-engineering-weekly-247",
      "title": "Data Engineering Weekly #247",
      "summary": "The Weekly Data Engineering Newsletter",
      "published_ts": 1765157129,
      "source_name": "Data Engineering Weekly",
      "score": 61.98143273591995,
      "content_type": "rex",
      "tech_level": "intermediate",
      "marketing_score": 5
    }
  ],
  "warehouses_engines": [
    {
      "url": "https://seattledataguy.substack.com/p/snowflake-vs-databricks-is-the-wrong",
      "title": "Snowflake vs Databricks Is the Wrong Debate",
      "summary": "Winning the Data Stack Role by Role",
      "published_ts": 1765554569,
      "source_name": "Seattle Data Guy",
      "score": 67.5558843165636,
      "content_type": "rex",
      "tech_level": "intermediate",
      "marketing_score": 0
    },
    {
      "url": "https://www.getdbt.com/blog/reliable-analytics-dbt-databricks",
      "title": "Scale reliable analytics in the AI era with dbt and Databricks",
      "summary": "Here’s why standards don’t matter when it comes to unlocking data siloes and fueling the agentic AI future.",
      "published_ts": 1765486680,
      "source_name": "dbt Blog",
      "score": 63.73365345597267,
      "content_type": "technical",
      "tech_level": "intermediate",
      "marketing_score": 0
    },
    {
      "url": "https://www.uber.com/blog/blazing-fast-olap-on-ubers-inventory-and-catalog-data-with-apache-pinot/",
      "title": "Blazing Fast OLAP on Uber’s Inventory and Catalog Data with Apache Pinot™",
      "summary": "Discover how Uber used Apache Pinot™ to build a real-time index on its massive inventory of billions of items to power search use cases, internal tools, and operational workflows.",
      "published_ts": 1765288800,
      "source_name": "Uber Engineering Blog",
      "score": 58.17758099734783,
      "content_type": "technical",
      "tech_level": "intermediate",
      "marketing_score": 0
    }
  ]
}